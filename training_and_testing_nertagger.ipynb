{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.taggers import Retagger\n",
    "from estnltk.taggers import CompoundTokenTagger\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenSplitter( Retagger ):\n",
    "    \"\"\"Splits tokens into smaller tokens based on regular expression patterns.\"\"\" \n",
    "    conf_param = ['patterns', 'break_group_name']\n",
    "    \n",
    "    def __init__(self, patterns, break_group_name:str='end'):\n",
    "        # Set input/output layers\n",
    "        self.input_layers = ['tokens']\n",
    "        self.output_layer = 'tokens'\n",
    "        self.output_attributes = ()\n",
    "        # Set other configuration parameters\n",
    "        if not (isinstance(break_group_name, str) and len(break_group_name) > 0):\n",
    "            raise TypeError('(!) break_group_name should be a non-empty string.')\n",
    "        self.break_group_name = break_group_name\n",
    "        # Assert that all patterns are regular expressions in the valid format\n",
    "        if not isinstance(patterns, list):\n",
    "            raise TypeError('(!) patterns should be a list of compiled regular expressions.')\n",
    "        # TODO: we use an adhoc way to verify that patterns are regular expressions \n",
    "        #       because there seems to be no common way of doing it both in py35 \n",
    "        #       and py36\n",
    "        for pat in patterns:\n",
    "            # Check for the existence of methods/attributes\n",
    "            has_match   = callable(getattr(pat, \"match\", None))\n",
    "            has_search  = callable(getattr(pat, \"search\", None))\n",
    "            has_pattern = getattr(pat, \"pattern\", None) is not None\n",
    "            for (k,v) in (('method match()',has_match),\\\n",
    "                          ('method search()',has_search),\\\n",
    "                          ('attribute pattern',has_pattern)):\n",
    "                if v is False:\n",
    "                    raise TypeError('(!) Unexpected regex pattern: {!r} is missing {}.'.format(pat, k))\n",
    "            symbolic_groups = pat.groupindex\n",
    "            if self.break_group_name not in symbolic_groups.keys():\n",
    "                raise TypeError('(!) Pattern {!r} is missing symbolic group named {!r}.'.format(pat, self.break_group_name))\n",
    "        self.patterns = patterns\n",
    "\n",
    "    def _change_layer(self, text, layers, status):\n",
    "        # Get changeble layer\n",
    "        changeble_layer = layers[self.output_layer]\n",
    "        # Iterate over tokens\n",
    "        add_spans    = []\n",
    "        remove_spans = []\n",
    "        for span in changeble_layer:\n",
    "            token_str = text.text[span.start:span.end]\n",
    "            for pat in self.patterns:\n",
    "                m = pat.search(token_str)\n",
    "                if m:\n",
    "                    break_group_end = m.end( self.break_group_name )\n",
    "                    if break_group_end > -1 and \\\n",
    "                       break_group_end > 0  and \\\n",
    "                       break_group_end < len(token_str):\n",
    "                        # Make the split\n",
    "                        add_spans.append( (span.start, span.start+break_group_end) )\n",
    "                        add_spans.append( (span.start+break_group_end, span.end) )\n",
    "                        remove_spans.append( span )\n",
    "                        # Once a token has been split, then break and move on to \n",
    "                        # the next token ...\n",
    "                        break\n",
    "        if add_spans:\n",
    "            assert len(remove_spans) > 0\n",
    "            for old_span in remove_spans:\n",
    "                changeble_layer.remove_span( old_span )\n",
    "            for new_span in add_spans:\n",
    "                changeble_layer.add_annotation( new_span )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = TokenSplitter(patterns=[re.compile(r'(?P<end>[A-ZÕÄÖÜ]{1}\\w+)[A-ZÕÄÖÜ]{1}\\w+'),\\\n",
    "                                         re.compile(r'(?P<end>Piebenomme)metsawaht'),\\\n",
    "                                         re.compile(r'(?P<end>maa)peal'),\\\n",
    "                                         re.compile(r'(?P<end>reppi)käest'),\\\n",
    "                                         re.compile(r'(?P<end>Kiidjerwelt)J'),\\\n",
    "                                         re.compile(r'(?P<end>Ameljanow)Persitski'),\\\n",
    "                                         re.compile(r'(?P<end>mõistmas)Mihkel'),\\\n",
    "                                         re.compile(r'(?P<end>tema)Käkk'),\\\n",
    "                                         re.compile(r'(?P<end>Ahjawalla)liikmed'),\\\n",
    "                                         re.compile(r'(?P<end>kohtumees)A'),\\\n",
    "                                         re.compile(r'(?P<end>Pechmann)x'),\\\n",
    "                                         re.compile(r'(?P<end>pölli)Anni'),\\\n",
    "                                         re.compile(r'(?P<end>külla)Rauba'),\\\n",
    "                                         re.compile(r'(?P<end>kohtowannem)Jaak'),\\\n",
    "                                         re.compile(r'(?P<end>rannast)Leno'),\\\n",
    "                                         re.compile(r'(?P<end>wallast)Kiiwita'),\\\n",
    "                                         re.compile(r'(?P<end>wallas)Kristjan'),\\\n",
    "                                         re.compile(r'(?P<end>Pedoson)rahul'),\\\n",
    "                                         re.compile(r'(?P<end>pere)Jaan'),\\\n",
    "                                         re.compile(r'(?P<end>kohtu)poolest'),\\\n",
    "                                         re.compile(r'(?P<end>Kurrista)kaudo'),\\\n",
    "                                         re.compile(r'(?P<end>mölder)Gottlieb'),\\\n",
    "                                         re.compile(r'(?P<end>wöörmündri)Jaan'),\\\n",
    "                                         re.compile(r'(?P<end>Oinas)ja'),\\\n",
    "                                         re.compile(r'(?P<end>ette)Leenu'),\\\n",
    "                                         re.compile(r'(?P<end>Tommingas)peab'),\\\n",
    "                                         re.compile(r'(?P<end>wäljaja)Kotlep'),\\\n",
    "                                         re.compile(r'(?P<end>pea)A'),\\\n",
    "                                         re.compile(r'(?P<end>talumees)Nikolai')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "\n",
    "with open('divided_corpus.txt', 'r', encoding = 'UTF-8') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "for fileName in txt:\n",
    "    file, subdistribution = fileName.split(\":\")\n",
    "    files[file] = subdistribution.rstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_not_working = ['J2rva_Tyri_V22tsa_id22177_1911a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id18538_1894a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id22155_1911a.json', \\\n",
    "                     'Saare_Kihelkonna_Kotlandi_id18845_1865a.json', \\\n",
    "                     'P2rnu_Halliste_Abja_id257_1844a.json', \\\n",
    "                     'Saare_Kaarma_Loona_id7575_1899a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id22266_1913a.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 3s, sys: 2.85 s, total: 2min 5s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_texts = []\n",
    "filenames = {key: value for key, value in files.items() if value in ('1', '2', '3', '4')}\n",
    "for filename in filenames:\n",
    "    with open('./vallakohtufailid_json/' + str(filename), 'r', encoding='UTF-8') as file:\n",
    "        if filename in files_not_working:\n",
    "            continue\n",
    "        else:\n",
    "            training_texts.append(json_to_text(file.read()).tag_layer(['sentences', 'morph_analysis']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers.estner.ner_trainer import NerTrainer\n",
    "from estnltk.taggers.estner.model_storage_util import ModelStorageUtil\n",
    "from estnltk.core import DEFAULT_PY3_NER_MODEL_DIR\n",
    "\n",
    "model_dir=DEFAULT_PY3_NER_MODEL_DIR\n",
    "modelUtil = ModelStorageUtil(model_dir)\n",
    "nersettings = modelUtil.load_settings()\n",
    "trainer = NerTrainer(nersettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 346163\n",
      "Seconds required: 2.987\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 1000\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 32455.512517\n",
      "Trial #1 (eta = 0.100000): 2799.600043\n",
      "Trial #2 (eta = 0.200000): 4119.565209\n",
      "Trial #3 (eta = 0.400000): 8561.548498\n",
      "Trial #4 (eta = 0.800000): 17339.056734\n",
      "Trial #5 (eta = 1.600000): 36579.034982 (worse)\n",
      "Trial #6 (eta = 0.050000): 2474.419152\n",
      "Trial #7 (eta = 0.025000): 2645.977417\n",
      "Trial #8 (eta = 0.012500): 3060.319073\n",
      "Trial #9 (eta = 0.006250): 3661.918528\n",
      "Trial #10 (eta = 0.003125): 4489.437405\n",
      "Trial #11 (eta = 0.001563): 5702.986127\n",
      "Trial #12 (eta = 0.000781): 7580.143885\n",
      "Trial #13 (eta = 0.000391): 10536.931654\n",
      "Trial #14 (eta = 0.000195): 14822.566673\n",
      "Trial #15 (eta = 0.000098): 20209.262469\n",
      "Best learning rate (eta): 0.050000\n",
      "Seconds required: 0.641\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 18454.398535\n",
      "Feature L2-norm: 33.073933\n",
      "Learning rate (eta): 0.049995\n",
      "Total number of feature updates: 15614\n",
      "Seconds required for this iteration: 0.616\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 8682.996537\n",
      "Feature L2-norm: 42.772257\n",
      "Learning rate (eta): 0.049990\n",
      "Total number of feature updates: 31228\n",
      "Seconds required for this iteration: 0.606\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 6058.884240\n",
      "Feature L2-norm: 49.644605\n",
      "Learning rate (eta): 0.049985\n",
      "Total number of feature updates: 46842\n",
      "Seconds required for this iteration: 0.603\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 4654.987210\n",
      "Feature L2-norm: 55.020189\n",
      "Learning rate (eta): 0.049980\n",
      "Total number of feature updates: 62456\n",
      "Seconds required for this iteration: 0.631\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 3721.646864\n",
      "Feature L2-norm: 59.409448\n",
      "Learning rate (eta): 0.049975\n",
      "Total number of feature updates: 78070\n",
      "Seconds required for this iteration: 0.609\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 3021.579140\n",
      "Feature L2-norm: 63.206314\n",
      "Learning rate (eta): 0.049970\n",
      "Total number of feature updates: 93684\n",
      "Seconds required for this iteration: 0.603\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 2647.289112\n",
      "Feature L2-norm: 66.555149\n",
      "Learning rate (eta): 0.049965\n",
      "Total number of feature updates: 109298\n",
      "Seconds required for this iteration: 0.615\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 2237.146319\n",
      "Feature L2-norm: 69.506522\n",
      "Learning rate (eta): 0.049960\n",
      "Total number of feature updates: 124912\n",
      "Seconds required for this iteration: 0.613\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 1983.603015\n",
      "Feature L2-norm: 72.158933\n",
      "Learning rate (eta): 0.049955\n",
      "Total number of feature updates: 140526\n",
      "Seconds required for this iteration: 0.612\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 1771.199999\n",
      "Feature L2-norm: 74.560562\n",
      "Learning rate (eta): 0.049950\n",
      "Total number of feature updates: 156140\n",
      "Seconds required for this iteration: 0.639\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 1579.457568\n",
      "Improvement ratio: 10.684010\n",
      "Feature L2-norm: 76.763716\n",
      "Learning rate (eta): 0.049945\n",
      "Total number of feature updates: 171754\n",
      "Seconds required for this iteration: 0.605\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 1442.959768\n",
      "Improvement ratio: 5.017490\n",
      "Feature L2-norm: 78.805156\n",
      "Learning rate (eta): 0.049940\n",
      "Total number of feature updates: 187368\n",
      "Seconds required for this iteration: 0.630\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 1308.813279\n",
      "Improvement ratio: 3.629296\n",
      "Feature L2-norm: 80.673817\n",
      "Learning rate (eta): 0.049935\n",
      "Total number of feature updates: 202982\n",
      "Seconds required for this iteration: 0.616\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 1205.148751\n",
      "Improvement ratio: 2.862583\n",
      "Feature L2-norm: 82.402324\n",
      "Learning rate (eta): 0.049930\n",
      "Total number of feature updates: 218596\n",
      "Seconds required for this iteration: 0.668\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 1126.831912\n",
      "Improvement ratio: 2.302752\n",
      "Feature L2-norm: 84.037667\n",
      "Learning rate (eta): 0.049925\n",
      "Total number of feature updates: 234210\n",
      "Seconds required for this iteration: 0.616\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 1067.114077\n",
      "Improvement ratio: 1.831543\n",
      "Feature L2-norm: 85.567157\n",
      "Learning rate (eta): 0.049920\n",
      "Total number of feature updates: 249824\n",
      "Seconds required for this iteration: 0.656\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 990.131487\n",
      "Improvement ratio: 1.673674\n",
      "Feature L2-norm: 87.017064\n",
      "Learning rate (eta): 0.049915\n",
      "Total number of feature updates: 265438\n",
      "Seconds required for this iteration: 0.626\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 952.949940\n",
      "Improvement ratio: 1.347601\n",
      "Feature L2-norm: 88.384492\n",
      "Learning rate (eta): 0.049910\n",
      "Total number of feature updates: 281052\n",
      "Seconds required for this iteration: 0.634\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 880.716682\n",
      "Improvement ratio: 1.252260\n",
      "Feature L2-norm: 89.676329\n",
      "Learning rate (eta): 0.049905\n",
      "Total number of feature updates: 296666\n",
      "Seconds required for this iteration: 0.606\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 839.827688\n",
      "Improvement ratio: 1.109004\n",
      "Feature L2-norm: 90.900139\n",
      "Learning rate (eta): 0.049900\n",
      "Total number of feature updates: 312280\n",
      "Seconds required for this iteration: 0.605\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 789.559469\n",
      "Improvement ratio: 1.000429\n",
      "Feature L2-norm: 92.074335\n",
      "Learning rate (eta): 0.049895\n",
      "Total number of feature updates: 327894\n",
      "Seconds required for this iteration: 0.614\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 764.914768\n",
      "Improvement ratio: 0.886432\n",
      "Feature L2-norm: 93.204637\n",
      "Learning rate (eta): 0.049890\n",
      "Total number of feature updates: 343508\n",
      "Seconds required for this iteration: 0.610\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 718.719395\n",
      "Improvement ratio: 0.821035\n",
      "Feature L2-norm: 94.273847\n",
      "Learning rate (eta): 0.049885\n",
      "Total number of feature updates: 359122\n",
      "Seconds required for this iteration: 0.611\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 700.222112\n",
      "Improvement ratio: 0.721095\n",
      "Feature L2-norm: 95.293379\n",
      "Learning rate (eta): 0.049880\n",
      "Total number of feature updates: 374736\n",
      "Seconds required for this iteration: 0.611\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 662.371528\n",
      "Improvement ratio: 0.701208\n",
      "Feature L2-norm: 96.279941\n",
      "Learning rate (eta): 0.049875\n",
      "Total number of feature updates: 390350\n",
      "Seconds required for this iteration: 0.605\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 645.214966\n",
      "Improvement ratio: 0.653889\n",
      "Feature L2-norm: 97.219585\n",
      "Learning rate (eta): 0.049870\n",
      "Total number of feature updates: 405964\n",
      "Seconds required for this iteration: 0.604\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 614.662765\n",
      "Improvement ratio: 0.610853\n",
      "Feature L2-norm: 98.133508\n",
      "Learning rate (eta): 0.049865\n",
      "Total number of feature updates: 421578\n",
      "Seconds required for this iteration: 0.614\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 594.412234\n",
      "Improvement ratio: 0.603180\n",
      "Feature L2-norm: 99.004667\n",
      "Learning rate (eta): 0.049860\n",
      "Total number of feature updates: 437192\n",
      "Seconds required for this iteration: 0.613\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 588.531942\n",
      "Improvement ratio: 0.496464\n",
      "Feature L2-norm: 99.840177\n",
      "Learning rate (eta): 0.049855\n",
      "Total number of feature updates: 452806\n",
      "Seconds required for this iteration: 0.614\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 567.739284\n",
      "Improvement ratio: 0.479249\n",
      "Feature L2-norm: 100.662426\n",
      "Learning rate (eta): 0.049850\n",
      "Total number of feature updates: 468420\n",
      "Seconds required for this iteration: 0.602\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 545.777561\n",
      "Improvement ratio: 0.446669\n",
      "Feature L2-norm: 101.449785\n",
      "Learning rate (eta): 0.049845\n",
      "Total number of feature updates: 484034\n",
      "Seconds required for this iteration: 0.603\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 533.879827\n",
      "Improvement ratio: 0.432747\n",
      "Feature L2-norm: 102.208381\n",
      "Learning rate (eta): 0.049841\n",
      "Total number of feature updates: 499648\n",
      "Seconds required for this iteration: 0.603\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 517.681601\n",
      "Improvement ratio: 0.388343\n",
      "Feature L2-norm: 102.951252\n",
      "Learning rate (eta): 0.049836\n",
      "Total number of feature updates: 515262\n",
      "Seconds required for this iteration: 0.619\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 494.965377\n",
      "Improvement ratio: 0.414689\n",
      "Feature L2-norm: 103.669606\n",
      "Learning rate (eta): 0.049831\n",
      "Total number of feature updates: 530876\n",
      "Seconds required for this iteration: 0.602\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 497.987597\n",
      "Improvement ratio: 0.330096\n",
      "Feature L2-norm: 104.370044\n",
      "Learning rate (eta): 0.049826\n",
      "Total number of feature updates: 546490\n",
      "Seconds required for this iteration: 0.604\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 473.591507\n",
      "Improvement ratio: 0.362387\n",
      "Feature L2-norm: 105.051097\n",
      "Learning rate (eta): 0.049821\n",
      "Total number of feature updates: 562104\n",
      "Seconds required for this iteration: 0.605\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 460.267682\n",
      "Improvement ratio: 0.335446\n",
      "Feature L2-norm: 105.707691\n",
      "Learning rate (eta): 0.049816\n",
      "Total number of feature updates: 577718\n",
      "Seconds required for this iteration: 0.613\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #38 *****\n",
      "Loss: 458.478717\n",
      "Improvement ratio: 0.296488\n",
      "Feature L2-norm: 106.345452\n",
      "Learning rate (eta): 0.049811\n",
      "Total number of feature updates: 593332\n",
      "Seconds required for this iteration: 0.607\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 436.858799\n",
      "Improvement ratio: 0.347190\n",
      "Feature L2-norm: 106.976032\n",
      "Learning rate (eta): 0.049806\n",
      "Total number of feature updates: 608946\n",
      "Seconds required for this iteration: 0.602\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 421.401630\n",
      "Improvement ratio: 0.347264\n",
      "Feature L2-norm: 107.579146\n",
      "Learning rate (eta): 0.049801\n",
      "Total number of feature updates: 624560\n",
      "Seconds required for this iteration: 0.618\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 428.935369\n",
      "Improvement ratio: 0.272400\n",
      "Feature L2-norm: 108.179763\n",
      "Learning rate (eta): 0.049796\n",
      "Total number of feature updates: 640174\n",
      "Seconds required for this iteration: 0.606\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 405.246311\n",
      "Improvement ratio: 0.317421\n",
      "Feature L2-norm: 108.758502\n",
      "Learning rate (eta): 0.049791\n",
      "Total number of feature updates: 655788\n",
      "Seconds required for this iteration: 0.603\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 403.379699\n",
      "Improvement ratio: 0.283361\n",
      "Feature L2-norm: 109.326371\n",
      "Learning rate (eta): 0.049786\n",
      "Total number of feature updates: 671402\n",
      "Seconds required for this iteration: 0.620\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 408.921424\n",
      "Improvement ratio: 0.210417\n",
      "Feature L2-norm: 109.879632\n",
      "Learning rate (eta): 0.049781\n",
      "Total number of feature updates: 687016\n",
      "Seconds required for this iteration: 0.602\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 381.289419\n",
      "Improvement ratio: 0.306062\n",
      "Feature L2-norm: 110.411128\n",
      "Learning rate (eta): 0.049776\n",
      "Total number of feature updates: 702630\n",
      "Seconds required for this iteration: 0.607\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 398.543436\n",
      "Improvement ratio: 0.188306\n",
      "Feature L2-norm: 110.944259\n",
      "Learning rate (eta): 0.049771\n",
      "Total number of feature updates: 718244\n",
      "Seconds required for this iteration: 0.613\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 385.450142\n",
      "Improvement ratio: 0.194104\n",
      "Feature L2-norm: 111.458136\n",
      "Learning rate (eta): 0.049766\n",
      "Total number of feature updates: 733858\n",
      "Seconds required for this iteration: 0.608\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 363.851823\n",
      "Improvement ratio: 0.260070\n",
      "Feature L2-norm: 111.966590\n",
      "Learning rate (eta): 0.049761\n",
      "Total number of feature updates: 749472\n",
      "Seconds required for this iteration: 0.610\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 367.940214\n",
      "Improvement ratio: 0.187309\n",
      "Feature L2-norm: 112.463700\n",
      "Learning rate (eta): 0.049756\n",
      "Total number of feature updates: 765086\n",
      "Seconds required for this iteration: 0.614\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 348.196305\n",
      "Improvement ratio: 0.210242\n",
      "Feature L2-norm: 112.941412\n",
      "Learning rate (eta): 0.049751\n",
      "Total number of feature updates: 780700\n",
      "Seconds required for this iteration: 0.600\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 355.931763\n",
      "Improvement ratio: 0.205106\n",
      "Feature L2-norm: 113.421399\n",
      "Learning rate (eta): 0.049746\n",
      "Total number of feature updates: 796314\n",
      "Seconds required for this iteration: 0.603\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 339.527006\n",
      "Improvement ratio: 0.193561\n",
      "Feature L2-norm: 113.892304\n",
      "Learning rate (eta): 0.049741\n",
      "Total number of feature updates: 811928\n",
      "Seconds required for this iteration: 0.611\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 331.470322\n",
      "Improvement ratio: 0.216941\n",
      "Feature L2-norm: 114.349755\n",
      "Learning rate (eta): 0.049736\n",
      "Total number of feature updates: 827542\n",
      "Seconds required for this iteration: 0.620\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 361.390267\n",
      "Improvement ratio: 0.131523\n",
      "Feature L2-norm: 114.802154\n",
      "Learning rate (eta): 0.049731\n",
      "Total number of feature updates: 843156\n",
      "Seconds required for this iteration: 0.606\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 342.476415\n",
      "Improvement ratio: 0.113330\n",
      "Feature L2-norm: 115.239100\n",
      "Learning rate (eta): 0.049727\n",
      "Total number of feature updates: 858770\n",
      "Seconds required for this iteration: 0.617\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 318.756949\n",
      "Improvement ratio: 0.250305\n",
      "Feature L2-norm: 115.676165\n",
      "Learning rate (eta): 0.049722\n",
      "Total number of feature updates: 874384\n",
      "Seconds required for this iteration: 0.604\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 321.484485\n",
      "Improvement ratio: 0.198970\n",
      "Feature L2-norm: 116.100077\n",
      "Learning rate (eta): 0.049717\n",
      "Total number of feature updates: 889998\n",
      "Seconds required for this iteration: 0.616\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 338.366768\n",
      "Improvement ratio: 0.075318\n",
      "Feature L2-norm: 116.521183\n",
      "Learning rate (eta): 0.049712\n",
      "Total number of feature updates: 905612\n",
      "Seconds required for this iteration: 0.611\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 317.368850\n",
      "Improvement ratio: 0.159346\n",
      "Feature L2-norm: 116.930742\n",
      "Learning rate (eta): 0.049707\n",
      "Total number of feature updates: 921226\n",
      "Seconds required for this iteration: 0.604\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 302.395993\n",
      "Improvement ratio: 0.151458\n",
      "Feature L2-norm: 117.333294\n",
      "Learning rate (eta): 0.049702\n",
      "Total number of feature updates: 936840\n",
      "Seconds required for this iteration: 0.628\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 328.188910\n",
      "Improvement ratio: 0.084533\n",
      "Feature L2-norm: 117.729081\n",
      "Learning rate (eta): 0.049697\n",
      "Total number of feature updates: 952454\n",
      "Seconds required for this iteration: 0.610\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 306.692365\n",
      "Improvement ratio: 0.107061\n",
      "Feature L2-norm: 118.117072\n",
      "Learning rate (eta): 0.049692\n",
      "Total number of feature updates: 968068\n",
      "Seconds required for this iteration: 0.608\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 306.508711\n",
      "Improvement ratio: 0.081439\n",
      "Feature L2-norm: 118.499993\n",
      "Learning rate (eta): 0.049687\n",
      "Total number of feature updates: 983682\n",
      "Seconds required for this iteration: 0.623\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 304.309161\n",
      "Improvement ratio: 0.187576\n",
      "Feature L2-norm: 118.878372\n",
      "Learning rate (eta): 0.049682\n",
      "Total number of feature updates: 999296\n",
      "Seconds required for this iteration: 0.608\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 301.952168\n",
      "Improvement ratio: 0.134208\n",
      "Feature L2-norm: 119.248606\n",
      "Learning rate (eta): 0.049677\n",
      "Total number of feature updates: 1014910\n",
      "Seconds required for this iteration: 0.614\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 296.115379\n",
      "Improvement ratio: 0.076462\n",
      "Feature L2-norm: 119.617238\n",
      "Learning rate (eta): 0.049672\n",
      "Total number of feature updates: 1030524\n",
      "Seconds required for this iteration: 0.618\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 276.818901\n",
      "Improvement ratio: 0.161353\n",
      "Feature L2-norm: 119.978535\n",
      "Learning rate (eta): 0.049667\n",
      "Total number of feature updates: 1046138\n",
      "Seconds required for this iteration: 0.613\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 305.057206\n",
      "Improvement ratio: 0.109191\n",
      "Feature L2-norm: 120.333150\n",
      "Learning rate (eta): 0.049662\n",
      "Total number of feature updates: 1061752\n",
      "Seconds required for this iteration: 0.642\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 268.062648\n",
      "Improvement ratio: 0.183935\n",
      "Feature L2-norm: 120.685712\n",
      "Learning rate (eta): 0.049657\n",
      "Total number of feature updates: 1077366\n",
      "Seconds required for this iteration: 0.763\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 304.623388\n",
      "Improvement ratio: -0.007312\n",
      "Feature L2-norm: 121.040626\n",
      "Learning rate (eta): 0.049652\n",
      "Total number of feature updates: 1092980\n",
      "Seconds required for this iteration: 0.750\n",
      "\n",
      "SGD terminated with the stopping criteria\n",
      "Loss: 268.062648\n",
      "Total seconds required for training: 43.893\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 346163 (346163)\n",
      "Number of active attributes: 313231 (313231)\n",
      "Number of active labels: 11 (11)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 1.970\n",
      "\n",
      "CPU times: user 14min 5s, sys: 5.57 s, total: 14min 11s\n",
      "Wall time: 14min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train( training_texts, layer='gold_wordner', model_dir='test' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

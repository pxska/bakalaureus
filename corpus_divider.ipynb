{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisanüanss: lõplik jaotus peaks olema selline, et seal leidub üks alamosa, kus ei ole ühtegi käsitsi morf ühestatud protokolli. Käsitsi morf ühestatud protokollide nimekiri on siin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_protocols_tagged_by_hand(file = \"k2sitsi_morfiga_protokollid.txt\"):\n",
    "    protocols_tagged_by_hand = []\n",
    "    with open(file, 'r', encoding=\"UTF-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line != \"\" and (line != \"k2sitsi_morfiga_protokollid2:\" and line != \"k2sitsi_morfiga_protokollid1:\"):\n",
    "            protocols_tagged_by_hand.append(line)\n",
    "    \n",
    "    return protocols_tagged_by_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ma arvan, et \"ideaalseks jaotuseks\" võibki esialgu võtta nimeüksuste jaotuse liikidesse kogu korpusel, mille annab skript \"check_ner_layers.ipynb\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_whole_corpus_distribution(filenames = os.listdir(\"vallakohtufailid_json/\")):\n",
    "    all_annotations = []\n",
    "    for file in filenames:\n",
    "        with open(\"vallakohtufailid_json/\" + file, 'r', encoding=\"UTF-8)\") as f:\n",
    "            data = json.load(f)\n",
    "            for dictionary in data.get('layers')[0].get('spans'):\n",
    "                all_annotations.append(dictionary.get('annotations')[0].get('nertag'))\n",
    "    per = all_annotations.count(\"PER\") / len(all_annotations) * 100\n",
    "    loc_org = all_annotations.count(\"LOC_ORG\") / len(all_annotations) * 100\n",
    "    loc = all_annotations.count(\"LOC\") / len(all_annotations) * 100\n",
    "    org = all_annotations.count(\"ORG\") / len(all_annotations) * 100\n",
    "    misc = all_annotations.count(\"MISC\") / len(all_annotations) * 100\n",
    "\n",
    "    ideal_distribution = {'PER': per, 'LOC_ORG' : loc_org, 'LOC' : loc, 'ORG' : org, 'MISC' : misc}\n",
    "    \n",
    "    return ideal_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kõigepealt tekita sõnastik, kus on iga json faili kohta nimeüksuste statistika liikide kaupa \"gold_ner\" kihist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_document_ne_statistics(filenames = os.listdir(\"vallakohtufailid_json/\")):\n",
    "    statistics = dict()\n",
    "    for file in filenames:\n",
    "        ner_annotations = []\n",
    "        with open(\"vallakohtufailid_json/\" + file, 'r', encoding=\"UTF-8)\") as f:\n",
    "            data = json.load(f)\n",
    "            for dictionary in data.get('layers')[0].get('spans'):\n",
    "                ner_annotations.append(dictionary.get('annotations')[0].get('nertag'))\n",
    "\n",
    "        statistics_for_file = dict()\n",
    "        for annotation in set(ner_annotations):\n",
    "            statistics_for_file[str(annotation)] = ner_annotations.count(annotation)\n",
    "        statistics[file] = statistics_for_file\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics, the ideal distribution and the protocols tagged by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = find_document_ne_statistics()\n",
    "ideal_distribution = calculate_whole_corpus_distribution()\n",
    "protocols_tagged_by_hand = read_protocols_tagged_by_hand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_items_in_lists(A, B, i, j):\n",
    "    temp_b = B[j]\n",
    "    B[j] = A[i]\n",
    "    A[i] = temp_b\n",
    "    return A, B\n",
    "\n",
    "def improve_scores(largest, second_largest):\n",
    "    score_largest_old = calculate_score(largest)\n",
    "    score_second_largest_old = calculate_score(second_largest)\n",
    "    for i in range(len(largest)):\n",
    "        for j in range(len(second_largest)):\n",
    "            largest, second_largest = swap_items_in_lists(largest, second_largest, i, j)\n",
    "            \n",
    "            score_largest_new = calculate_score(largest)\n",
    "            score_second_largest_new = calculate_score(second_largest)\n",
    "\n",
    "            if score_largest_old > score_largest_new and score_second_largest_old > score_second_largest_new:\n",
    "                print(f\"{i, j} Skoor paranes mõlema alamkorpuse lõikes.\")\n",
    "                score_largest_old = score_largest_new\n",
    "                score_second_largest_old = score_second_largest_new\n",
    "                i += 1\n",
    "            elif score_largest_old < score_largest_new and score_second_largest_old > score_second_largest_new:\n",
    "                print(f\"{i, j} Skoor paranes ainult esimeses massiivis.\")\n",
    "                swap_items_in_lists(largest, second_largest, i, j)\n",
    "                score_largest_old = score_largest_old\n",
    "                score_second_largest_old = score_second_largest_old\n",
    "            elif score_largest_old > score_largest_new and score_second_largest_old < score_second_largest_new:\n",
    "                print(f\"{i, j} Skoor paranes ainult teises massiivis.\")\n",
    "                swap_items_in_lists(largest, second_largest, i, j)\n",
    "                score_largest_old = score_largest_old\n",
    "                score_second_largest_old = score_second_largest_old\n",
    "            else:\n",
    "                print(f\"{i, j} Skoor ei paranenud kummaski massiivis.\")\n",
    "                swap_items_in_lists(largest, second_largest, i, j)\n",
    "                score_largest_old = score_largest_old\n",
    "                score_second_largest_old = score_second_largest_old\n",
    "    return largest, second_largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef calculate_score(filenames):\\n    proportions = calculate_proportions(filenames)\\n    score = 0\\n    penalty = 0\\n    for file in protocols_tagged_by_hand:\\n        if (file + \".json\") in filenames:\\n            penalty += 1\\n    for proportion in proportions:\\n        ideal_distribution_proportion = ideal_distribution[proportion]\\n        current_proportion = proportions[proportion]\\n        \\n        if current_proportion == ideal_distribution_proportion:\\n            score += 0\\n        else:\\n            score += abs(ideal_distribution_proportion - current_proportion)\\n    return score+penalty\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def calculate_score(filenames):\n",
    "    proportions = calculate_proportions(filenames)\n",
    "    score = 0\n",
    "    penalty = 0\n",
    "    for file in protocols_tagged_by_hand:\n",
    "        if (file + \".json\") in filenames:\n",
    "            penalty += 1\n",
    "    for proportion in proportions:\n",
    "        ideal_distribution_proportion = ideal_distribution[proportion]\n",
    "        current_proportion = proportions[proportion]\n",
    "        \n",
    "        if current_proportion == ideal_distribution_proportion:\n",
    "            score += 0\n",
    "        else:\n",
    "            score += abs(ideal_distribution_proportion - current_proportion)\n",
    "    return score+penalty\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seejärel loo funktsioon, mis leiab (eelmise sõnastiku abil) nimeüksuste proportsionaalse jaotuse etteantud alamkorpuses. Sisendiks on alamkorpus ehk järjend json failide nimedest ja tulemusena tagastatakse sõnastik, kus on iga nimeüksuse liigi kohta toodud selle osakaal alamkorpuses: { 'PER': x, 'LOC': y, ... }. Osakaal on siis jagatis: {nimeüksuseid antud liigist} / {kõik nimeüksused alamkorpuses} -- kas protsendina või arvuna vahemikust 0.0 kuni 1.0, kuidas järgnevatel etappidel mugavam tundub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proportions(filenames):\n",
    "    statistics_for_proportion = {}\n",
    "    \n",
    "    for file in filenames:\n",
    "        statistics_for_proportion[file] = statistics[file]\n",
    "\n",
    "    all_annotations = list()\n",
    "    for item in statistics_for_proportion.values():\n",
    "        for key in item:\n",
    "            for i in range(item[key] + 1):\n",
    "                all_annotations.append(key)\n",
    "                \n",
    "    proportions = dict()\n",
    "    for file in statistics_for_proportion:\n",
    "        for key in statistics_for_proportion[file].keys():\n",
    "            proportion = all_annotations.count(key) / len(all_annotations) * 100\n",
    "            proportions[key] = proportion\n",
    "        \n",
    "    return proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neljas funktsioon: juhujaotuse genereerimine. Jagab sisendiks antud korpuse dokumendid (järjend json failide nimedest) N juhuslikuks alamosaks -- nii, et iga alamosa koosneb sellistest dokumentidest, mida mujal alamosades ei ole ning kogu korpuse dokumendid on kaetud. Selleks: a) järjesta kõik dokumendid juhuslikult random.sample funktsiooni abil (et eksperiment oleks korratav, fikseeri enne iga juhuslikku järjestamist random.seed mingi kindla väärtusega). b) jaga järjestus N alamosaks nii, et igas alamosas on enam-vähem võrdne arv dokumente. Selleks on mitmeid viise (vt nt siit), aga oluline on, et viimane alamosa ei tuleks liiga väike. Tagasta tulemus (N liikmeline list, mille iga liige on omakorda dokumentide list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_even_chunks(filenames, n):\n",
    "    files = []\n",
    "    last = 0\n",
    "    for i in range(1, n+1):\n",
    "        current = int(round(i* (len(filenames) / n)))\n",
    "        files.append(filenames[last:current])\n",
    "        last = current\n",
    "    return files\n",
    "\n",
    "def generate_random_division(filenames, n):\n",
    "    random_distributions = []\n",
    "    for i in range(n):\n",
    "        filenames = random.sample(filenames, len(filenames))\n",
    "        random_distributions.append(filenames)\n",
    "    \n",
    "    return random_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolmas funktsioon: saab sisendiks alamkorpuse (järjendi json failide nimedest) ja arvutab sellele skoori, mis näitab seda, kui lähedal on nimeüksuste proportsionaalne jaotus nö ideaalsele jaotusele. Algoritm võib lihtsalt olla selline, et leiab iga nimeüksuste tüübi kohta, mitu protsendipunkti erineb osakaal antud alamkorpuses nimeüksuse liigi osakaalust selles nö ideaalses jaotuses, ja summeerib erinevused. Skoor töötab siis nii, et mida väiksem erinevuste summa, seda parem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(filenames):\n",
    "    proportions = calculate_proportions(filenames)\n",
    "    score = 0\n",
    "    for proportion in proportions:\n",
    "        ideal_distribution_proportion = ideal_distribution[proportion]\n",
    "        current_proportion = proportions[proportion]\n",
    "        \n",
    "        if current_proportion == ideal_distribution_proportion:\n",
    "            score += 0\n",
    "        else:\n",
    "            score += abs(ideal_distribution_proportion - current_proportion)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0\n",
      "7.217010759280128\n",
      "6.97244658028972\n",
      "9.121278140885995\n",
      "10.923169877640092\n",
      "7.724447992371964\n",
      "10.223489569323979\n",
      "Score of sub-corpus: 8.696973819965313\n",
      " \n",
      "7.754266552310438\n",
      "9.719299234720939\n",
      "12.424427655539489\n",
      "6.278466852474673\n",
      "6.4430444329659835\n",
      "8.783316869420872\n",
      "Score of sub-corpus: 8.567136932905399\n",
      " \n",
      "8.860460264550053\n",
      "6.564965579245409\n",
      "5.286362879817535\n",
      "14.602432044028337\n",
      "10.346528655721295\n",
      "5.901320113343106\n",
      "Score of sub-corpus: 8.593678256117622\n",
      " \n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "print(\"Seed:\", seed)\n",
    "\n",
    "subdistributions = list()\n",
    "random_distributions = generate_random_division(os.listdir(\"vallakohtufailid_json/\"), 3)\n",
    "for distribution in random_distributions:\n",
    "    distribution = n_even_chunks(distribution, 6)\n",
    "    subdistributions.append(distribution)\n",
    "    \n",
    "sums_of_distributions = list()\n",
    "list_of_scores = list()\n",
    "\n",
    "for distribution in subdistributions:\n",
    "    scores = dict()\n",
    "    for files in distribution:\n",
    "        score = calculate_score(files)\n",
    "        scores[score] = files\n",
    "        print(score)\n",
    "    list_of_scores.append(scores)\n",
    "    print(f\"Score of sub-corpus: {sum(scores.keys()) / len(scores.keys())}\")\n",
    "    print(\" \")\n",
    "\n",
    "for listofscores in list_of_scores:    \n",
    "    sums_of_distributions.append(sum(listofscores.keys()) / len(listofscores.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Kõigepealt genereeri mingi arv korpuse juhuslikke jaotuseid 6-ks alamosaks. Nt N=10 tükki.\n",
    "\n",
    "2. Leia iga jaotuse skoor. Jaotuse skoor = leia kõigi kuue alamosa skoorid skoorimise funktsiooni abil ning liida kokku. Kui peaks juhtuma, et mõnele jaotusele trehvabki kohe väga väike skoor (nt kogu-erinevus <= 5 protsendipunkti), siis tasub protsess seisma panna ja tulemustele peale vaadata, st äkki ongi sobiv jaotus käes. Aga kui nii ei lähe, siis edasi:\n",
    "\n",
    "3. Vali välja kõige kõrgema skoori saanud jaotus.\n",
    "\n",
    "4. Iteratiivselt: 4.1) Leia jaotusest kaks alamosa, mille erinevus nö ideaalsest jaotusest on kõige suurem, 4.2) paarita mõlema jaotuse kõiki dokumente omavahel (topelt-tsükkel) ja leia iga paari (x1, y1) puhul, milliseks muutub mõlema alamosa skoor, kui vahetada dokumendid alamosades. 4.3) Teosta ümberpaigutus, mis parandas skoori kõige rohkem. 4.4) Leia uuesti kogu jaotuse skoor; kui see on väga väike (nt kogu-erinevus <= 5 protsendipunkti), siis seiska protsess ja vaatame tulemustele peale. Vastasel juhul pöördu tagasi punkti 4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algsed skoorid on 12.424427655539489 ning 9.719299234720939.\n",
      "(0, 0) Skoor paranes ainult esimeses massiivis.\n",
      "(0, 1) Skoor paranes ainult esimeses massiivis.\n",
      "(0, 2) Skoor paranes ainult esimeses massiivis.\n",
      "(0, 3) Skoor paranes ainult esimeses massiivis.\n",
      "(0, 4) Skoor paranes ainult esimeses massiivis.\n",
      "(0, 5) Skoor paranes ainult esimeses massiivis.\n",
      "(0, 6) Skoor paranes ainult esimeses massiivis.\n",
      "(0, 7) Skoor paranes ainult esimeses massiivis.\n",
      "(0, 8) Skoor paranes ainult esimeses massiivis.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d1beb9104c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Algsed skoorid on {keys_list[-1]} ning {keys_list[-2]}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlargest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_largest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimprove_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlargest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_largest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mscore_after_improving_largest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlargest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mscore_after_improving_second_largest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond_largest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b5a53f6963ff>\u001b[0m in \u001b[0;36mimprove_scores\u001b[0;34m(largest, second_largest)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mscore_largest_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlargest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mscore_second_largest_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond_largest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore_largest_old\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mscore_largest_new\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscore_second_largest_old\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mscore_second_largest_new\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-58094ad847d3>\u001b[0m in \u001b[0;36mcalculate_score\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mproportions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_proportions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mproportion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproportions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mideal_distribution_proportion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mideal_distribution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproportion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-322c8378cfb3>\u001b[0m in \u001b[0;36mcalculate_proportions\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstatistics_for_proportion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstatistics_for_proportion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mproportion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_annotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_annotations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mproportions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "smallest_score = list_of_scores[sums_of_distributions.index(min(sums_of_distributions))]\n",
    "while (sum(smallest_score.keys()) / len(smallest_score.keys())) >= 5:\n",
    "    keys_list = sorted(smallest_score.keys())\n",
    "    largest_key = keys_list[-1]\n",
    "    second_largest_key = keys_list[-2]\n",
    "    \n",
    "    largest = smallest_score[largest_key]\n",
    "    second_largest = smallest_score[second_largest_key]\n",
    "    \n",
    "    print(f\"Algsed skoorid on {keys_list[-1]} ning {keys_list[-2]}.\")\n",
    "    largest, second_largest = improve_scores(largest, second_largest)\n",
    "    score_after_improving_largest = calculate_score(largest)\n",
    "    score_after_improving_second_largest = calculate_score(second_largest)\n",
    "    print(f\"Skoorid pärast parandamist on {score_after_improving_largest} ning {score_after_improving_second_largest}.\")\n",
    "    del smallest_score[largest_key]\n",
    "    del smallest_score[second_largest_key]\n",
    "    smallest_score[score_after_improving_largest] = largest\n",
    "    smallest_score[score_after_improving_second_largest] = second_largest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

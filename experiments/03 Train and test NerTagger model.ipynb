{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "from modules.preprocessing_protocols import preprocess_text\n",
    "from modules.results_extraction import extract_results, \\\n",
    "                                       results_by_subdistribution, \\\n",
    "                                       results_by_named_entity, \\\n",
    "                                       confusion_matrix\n",
    "from modules.tools import find\n",
    "\n",
    "from estnltk import Text\n",
    "from estnltk.taggers import NerTagger\n",
    "from estnltk.taggers import WordLevelNerTagger\n",
    "from estnltk.converters import text_to_json\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.layer_operations import flatten\n",
    "\n",
    "from estnltk.taggers.estner.ner_trainer import NerTrainer\n",
    "from estnltk.taggers.estner.model_storage_util import ModelStorageUtil\n",
    "\n",
    "from estnltk.taggers import VabamorfCorpusTagger\n",
    "vm_corpus_tagger = VabamorfCorpusTagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags & variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vabamorfcorpustagger = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_corpus = os.path.join('..', 'data', 'divided_corpus.txt')\n",
    "json_files_location = os.path.join('..', 'data', 'vallakohtufailid-json-flattened')\n",
    "vallakohtufailid_location = os.path.join('..', 'data', 'vallakohtufailid')\n",
    "no_goldstandard_tags_location = os.path.join('..', 'data', 'files_without_goldstandard_annotations.txt')\n",
    "testing_files_location = os.path.join('..', 'data', 'vallakohtufailid-json-flattened')\n",
    "\n",
    "removed_layers = ['sentences', 'morph_analysis', 'compound_tokens', 'ner', 'words', 'tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get files without goldstandard annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(no_goldstandard_tags_location, 'r', encoding='UTF-8') as in_f:\n",
    "    lines = in_f.readlines()\n",
    "\n",
    "no_goldstandard_annotations = [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all files for the first five subdistributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "\n",
    "with open(divided_corpus, 'r', encoding = 'UTF-8') as in_f:\n",
    "    txt = in_f.readlines()\n",
    "\n",
    "for filename in txt:\n",
    "    file, subdistribution = filename.split(\":\")\n",
    "    files[file] = subdistribution.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the subdistribution for testing and training\n",
    "(e.g. `1` to test, `2`;`3`;`4`;`5` to train or `2` to test, `1` and `3`;`4`;`5` to train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_and_training_subdistribution(subdistribution):\n",
    "    training = []\n",
    "    for y in sorted(set(files.values())):\n",
    "        if int(y) == subdistribution:\n",
    "            testing = int(y)\n",
    "        else:\n",
    "            training.append(int(y))\n",
    "    return testing, training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of Text objects from the files read in before (the subdistributions meant for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_texts(filenames):\n",
    "    print('(!) Preparing training texts')\n",
    "    \n",
    "    training_texts = []\n",
    "    \n",
    "    for filename in filenames:\n",
    "        if filename in no_goldstandard_annotations:\n",
    "            continue\n",
    "        else:\n",
    "            with open(os.path.join(json_files_location, filename), 'r', encoding='UTF-8') as in_f:\n",
    "                tagged_text = preprocess_text(json_to_text(in_f.read()))\n",
    "                \n",
    "            if use_vabamorfcorpustagger:\n",
    "                tagged_text.pop_layer('morph_analysis')\n",
    "                vm_corpus_tagger.tag([tagged_text])\n",
    "\n",
    "            training_texts.append(tagged_text)\n",
    "            \n",
    "    print('(!) Training texts done')\n",
    "    return training_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the NerTagger model using settings from the model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nertagger(training_texts, new_model_dir):\n",
    "    print('(!) Training NerTagger')\n",
    "    \n",
    "    modelUtil = ModelStorageUtil(new_model_dir)\n",
    "    nersettings = modelUtil.load_settings()\n",
    "    trainer = NerTrainer(nersettings)\n",
    "    trainer.train( training_texts, layer='gold_wordner', model_dir=new_model_dir )\n",
    "    print('(!) NerTagger training done\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag the files by finding the appropriate from vallakohtufailid_location,\n",
    "then preprocessing them, removing layers for optimal file sizes and\n",
    "saving them to a new directory in the model folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_files(model_dir, testing_files, use_vabamorfcorpustagger, tag_wordner):\n",
    "    nertagger = NerTagger(model_dir)\n",
    "    \n",
    "    print(\"(!) Tagging...\")\n",
    "    iterator = 1\n",
    "    for test_file in testing_files:\n",
    "        with open(find(test_file.replace(\".json\", \".txt\"), vallakohtufailid_location), 'r', encoding='UTF-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        if test_file == \"Tartu_V6nnu_Ahja_id3502_1882a.json\":\n",
    "            text = text.replace('..', '. .')\n",
    "        text = preprocess_text(Text(text))\n",
    "\n",
    "        if use_vabamorfcorpustagger or \"vabamorf\" in model_dir:\n",
    "            text.pop_layer('morph_analysis')\n",
    "            text = [text]\n",
    "            vm_corpus_tagger.tag( text )\n",
    "            text = text[0]\n",
    "        nertagger.tag(text)\n",
    "        text.add_layer(flatten(text['ner'], 'flat_ner'))\n",
    "        \n",
    "        if tag_wordner:\n",
    "            print('(!) Tagging Word Level NER')\n",
    "            wordnertagger = WordLevelNerTagger(model_dir)\n",
    "            wordnertagger.tag(text)\n",
    "            text.add_layer(flatten(text['wordner'], 'flat_wordner'))\n",
    "        \n",
    "        for x in removed_layers:\n",
    "            text.pop_layer(x)\n",
    "\n",
    "        path = os.path.join(model_dir, 'vallakohtufailid-trained-nertagger')\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "            \n",
    "        text_to_json(text, file=os.path.join(model_dir, 'vallakohtufailid-trained-nertagger', test_file))\n",
    "        \n",
    "        print(f'{iterator}. Tagged file {test_file}')\n",
    "        iterator += 1\n",
    "    print('(!) Files tagged')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model by applying all necessary \n",
    "def train_model(model_directory, tag_wordner):\n",
    "    for subdistribution in sorted(set(files.values())):\n",
    "        testing, training = get_testing_and_training_subdistribution(int(subdistribution))\n",
    "\n",
    "        # Get the filenames to be trained on from the files dictionary\n",
    "        filenames = [key for key, value in files.items() if int(value) in training]\n",
    "\n",
    "        # Create training_texts from the aforementioned filenames\n",
    "        training_texts = create_training_texts(filenames)\n",
    "\n",
    "        # Set up the trainer and training\n",
    "        new_model_dir = os.path.join('models', model_directory)\n",
    "        train_nertagger(training_texts, new_model_dir)\n",
    "\n",
    "        # Set up the new trained nertagger and defining layers to be removed later on\n",
    "        tagger = NerTagger(model_dir = new_model_dir)\n",
    "        #print(tagger.nersettings)\n",
    "        # Tag the files using the new nertagger\n",
    "        testing_files = [key for key, value in files.items() if int(value) == testing]\n",
    "        tag_files(new_model_dir, testing_files, use_vabamorfcorpustagger, tag_wordner)\n",
    "            \n",
    "    # Get results of model\n",
    "    extract_results(files,\n",
    "                    no_goldstandard_annotations,\n",
    "                    os.path.join('models', model_directory, 'vallakohtufailid-trained-nertagger'), #training files location\n",
    "                    testing_files_location,\n",
    "                    os.path.join('models', model_directory)) #results.txt location\n",
    "    \n",
    "    print(f\"(!) Model {model_directory} trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! Make sure the values (location of the training files and location of the `results.txt` file) in the `extract_results()` function are correct as these cannot be referenced before the model directory is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model the `model_directory` (given to the `train_model()` function) must contain a `settings.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    'model_default_with_vabamorftagger',\n",
    "    'model_local_features_without_morph',\n",
    "    'model_morph_without_lemmas',\n",
    "    'model_morph_with_lemmas',\n",
    "    'model_morph_with_lemmas_and_sentences',\n",
    "    'model_morph_with_lemmas_and_sentences_and_gazzetteer',\n",
    "    os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_initial'),\n",
    "    os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_vabamorf_gazetteer'),\n",
    "    os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_vabamorf_gazetteer2'),\n",
    "    os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_vabamorf_gazetteer1and2'),\n",
    "    os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_gaz_loc'),\n",
    "    os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_gaz_loc_variants')    \n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    train_model(model, tag_wordner = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Preparing training texts\n",
      "(!) Training texts done\n",
      "(!) Training NerTagger\n",
      "(!) Warning: Location of the new \"settings.py\" is the same one as the old one. Model's settings are not copied.\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 347546\n",
      "Seconds required: 2.086\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 1000\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 30474.851022\n",
      "Trial #1 (eta = 0.100000): 2509.798853\n",
      "Trial #2 (eta = 0.200000): 3571.168525\n",
      "Trial #3 (eta = 0.400000): 6982.558767\n",
      "Trial #4 (eta = 0.800000): 13567.187870\n",
      "Trial #5 (eta = 1.600000): 33517.948069 (worse)\n",
      "Trial #6 (eta = 0.050000): 2188.020241\n",
      "Trial #7 (eta = 0.025000): 2373.892858\n",
      "Trial #8 (eta = 0.012500): 2796.282357\n",
      "Trial #9 (eta = 0.006250): 3388.747438\n",
      "Trial #10 (eta = 0.003125): 4204.634551\n",
      "Trial #11 (eta = 0.001563): 5395.722750\n",
      "Trial #12 (eta = 0.000781): 7248.394045\n",
      "Trial #13 (eta = 0.000391): 10149.466859\n",
      "Trial #14 (eta = 0.000195): 14303.377192\n",
      "Trial #15 (eta = 0.000098): 19441.744027\n",
      "Best learning rate (eta): 0.050000\n",
      "Seconds required: 0.309\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 18245.876055\n",
      "Feature L2-norm: 33.440700\n",
      "Learning rate (eta): 0.049995\n",
      "Total number of feature updates: 16243\n",
      "Seconds required for this iteration: 0.344\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 8534.582052\n",
      "Feature L2-norm: 43.256176\n",
      "Learning rate (eta): 0.049990\n",
      "Total number of feature updates: 32486\n",
      "Seconds required for this iteration: 0.323\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 6337.564808\n",
      "Feature L2-norm: 50.307439\n",
      "Learning rate (eta): 0.049985\n",
      "Total number of feature updates: 48729\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 4481.220300\n",
      "Feature L2-norm: 55.408824\n",
      "Learning rate (eta): 0.049980\n",
      "Total number of feature updates: 64972\n",
      "Seconds required for this iteration: 0.347\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 3576.845765\n",
      "Feature L2-norm: 59.702033\n",
      "Learning rate (eta): 0.049975\n",
      "Total number of feature updates: 81215\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 2954.526710\n",
      "Feature L2-norm: 63.420436\n",
      "Learning rate (eta): 0.049970\n",
      "Total number of feature updates: 97458\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 2518.917685\n",
      "Feature L2-norm: 66.699329\n",
      "Learning rate (eta): 0.049965\n",
      "Total number of feature updates: 113701\n",
      "Seconds required for this iteration: 0.327\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 2172.898370\n",
      "Feature L2-norm: 69.569705\n",
      "Learning rate (eta): 0.049960\n",
      "Total number of feature updates: 129944\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 1913.714273\n",
      "Feature L2-norm: 72.158377\n",
      "Learning rate (eta): 0.049955\n",
      "Total number of feature updates: 146187\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 1686.039445\n",
      "Feature L2-norm: 74.516815\n",
      "Learning rate (eta): 0.049950\n",
      "Total number of feature updates: 162430\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 1517.040309\n",
      "Improvement ratio: 11.027285\n",
      "Feature L2-norm: 76.657061\n",
      "Learning rate (eta): 0.049945\n",
      "Total number of feature updates: 178673\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 1386.716051\n",
      "Improvement ratio: 5.154527\n",
      "Feature L2-norm: 78.622408\n",
      "Learning rate (eta): 0.049940\n",
      "Total number of feature updates: 194916\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 1271.625825\n",
      "Improvement ratio: 3.983828\n",
      "Feature L2-norm: 80.473763\n",
      "Learning rate (eta): 0.049935\n",
      "Total number of feature updates: 211159\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 1169.268041\n",
      "Improvement ratio: 2.832500\n",
      "Feature L2-norm: 82.176517\n",
      "Learning rate (eta): 0.049930\n",
      "Total number of feature updates: 227402\n",
      "Seconds required for this iteration: 0.328\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 1080.223101\n",
      "Improvement ratio: 2.311210\n",
      "Feature L2-norm: 83.786616\n",
      "Learning rate (eta): 0.049925\n",
      "Total number of feature updates: 243645\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 995.151244\n",
      "Improvement ratio: 1.968922\n",
      "Feature L2-norm: 85.280507\n",
      "Learning rate (eta): 0.049920\n",
      "Total number of feature updates: 259888\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 950.588742\n",
      "Improvement ratio: 1.649850\n",
      "Feature L2-norm: 86.689758\n",
      "Learning rate (eta): 0.049915\n",
      "Total number of feature updates: 276131\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 881.511564\n",
      "Improvement ratio: 1.464969\n",
      "Feature L2-norm: 88.020467\n",
      "Learning rate (eta): 0.049910\n",
      "Total number of feature updates: 292374\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 844.604399\n",
      "Improvement ratio: 1.265811\n",
      "Feature L2-norm: 89.307362\n",
      "Learning rate (eta): 0.049905\n",
      "Total number of feature updates: 308617\n",
      "Seconds required for this iteration: 0.347\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 808.953915\n",
      "Improvement ratio: 1.084222\n",
      "Feature L2-norm: 90.509465\n",
      "Learning rate (eta): 0.049900\n",
      "Total number of feature updates: 324860\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 760.030453\n",
      "Improvement ratio: 0.996026\n",
      "Feature L2-norm: 91.648299\n",
      "Learning rate (eta): 0.049895\n",
      "Total number of feature updates: 341103\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 721.024748\n",
      "Improvement ratio: 0.923257\n",
      "Feature L2-norm: 92.731953\n",
      "Learning rate (eta): 0.049890\n",
      "Total number of feature updates: 357346\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 692.610399\n",
      "Improvement ratio: 0.835990\n",
      "Feature L2-norm: 93.780412\n",
      "Learning rate (eta): 0.049885\n",
      "Total number of feature updates: 373589\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 676.954126\n",
      "Improvement ratio: 0.727249\n",
      "Feature L2-norm: 94.774335\n",
      "Learning rate (eta): 0.049880\n",
      "Total number of feature updates: 389832\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 631.367022\n",
      "Improvement ratio: 0.710927\n",
      "Feature L2-norm: 95.739465\n",
      "Learning rate (eta): 0.049875\n",
      "Total number of feature updates: 406075\n",
      "Seconds required for this iteration: 0.356\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 611.458344\n",
      "Improvement ratio: 0.627505\n",
      "Feature L2-norm: 96.665796\n",
      "Learning rate (eta): 0.049870\n",
      "Total number of feature updates: 422318\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 589.594656\n",
      "Improvement ratio: 0.612275\n",
      "Feature L2-norm: 97.549010\n",
      "Learning rate (eta): 0.049865\n",
      "Total number of feature updates: 438561\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 561.448494\n",
      "Improvement ratio: 0.570067\n",
      "Feature L2-norm: 98.405052\n",
      "Learning rate (eta): 0.049860\n",
      "Total number of feature updates: 454804\n",
      "Seconds required for this iteration: 0.328\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 552.270165\n",
      "Improvement ratio: 0.529332\n",
      "Feature L2-norm: 99.232765\n",
      "Learning rate (eta): 0.049855\n",
      "Total number of feature updates: 471047\n",
      "Seconds required for this iteration: 0.323\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 547.001965\n",
      "Improvement ratio: 0.478887\n",
      "Feature L2-norm: 100.037036\n",
      "Learning rate (eta): 0.049850\n",
      "Total number of feature updates: 487290\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 503.191503\n",
      "Improvement ratio: 0.510420\n",
      "Feature L2-norm: 100.813666\n",
      "Learning rate (eta): 0.049845\n",
      "Total number of feature updates: 503533\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 498.457475\n",
      "Improvement ratio: 0.446512\n",
      "Feature L2-norm: 101.573707\n",
      "Learning rate (eta): 0.049841\n",
      "Total number of feature updates: 519776\n",
      "Seconds required for this iteration: 0.321\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 497.068590\n",
      "Improvement ratio: 0.393390\n",
      "Feature L2-norm: 102.303732\n",
      "Learning rate (eta): 0.049836\n",
      "Total number of feature updates: 536019\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 467.694246\n",
      "Improvement ratio: 0.447429\n",
      "Feature L2-norm: 103.011625\n",
      "Learning rate (eta): 0.049831\n",
      "Total number of feature updates: 552262\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 468.379161\n",
      "Improvement ratio: 0.347983\n",
      "Feature L2-norm: 103.690209\n",
      "Learning rate (eta): 0.049826\n",
      "Total number of feature updates: 568505\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 439.976268\n",
      "Improvement ratio: 0.389753\n",
      "Feature L2-norm: 104.351069\n",
      "Learning rate (eta): 0.049821\n",
      "Total number of feature updates: 584748\n",
      "Seconds required for this iteration: 0.326\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #37 *****\n",
      "Loss: 451.173951\n",
      "Improvement ratio: 0.306801\n",
      "Feature L2-norm: 104.994102\n",
      "Learning rate (eta): 0.049816\n",
      "Total number of feature updates: 600991\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 436.505935\n",
      "Improvement ratio: 0.286233\n",
      "Feature L2-norm: 105.614194\n",
      "Learning rate (eta): 0.049811\n",
      "Total number of feature updates: 617234\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 427.891405\n",
      "Improvement ratio: 0.290678\n",
      "Feature L2-norm: 106.222061\n",
      "Learning rate (eta): 0.049806\n",
      "Total number of feature updates: 633477\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 413.717372\n",
      "Improvement ratio: 0.322163\n",
      "Feature L2-norm: 106.824378\n",
      "Learning rate (eta): 0.049801\n",
      "Total number of feature updates: 649720\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 416.581246\n",
      "Improvement ratio: 0.207907\n",
      "Feature L2-norm: 107.410644\n",
      "Learning rate (eta): 0.049796\n",
      "Total number of feature updates: 665963\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 382.988013\n",
      "Improvement ratio: 0.301496\n",
      "Feature L2-norm: 107.973078\n",
      "Learning rate (eta): 0.049791\n",
      "Total number of feature updates: 682206\n",
      "Seconds required for this iteration: 0.356\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 406.683952\n",
      "Improvement ratio: 0.222248\n",
      "Feature L2-norm: 108.536682\n",
      "Learning rate (eta): 0.049786\n",
      "Total number of feature updates: 698449\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 380.053776\n",
      "Improvement ratio: 0.230600\n",
      "Feature L2-norm: 109.093171\n",
      "Learning rate (eta): 0.049781\n",
      "Total number of feature updates: 714692\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 383.155178\n",
      "Improvement ratio: 0.222427\n",
      "Feature L2-norm: 109.628011\n",
      "Learning rate (eta): 0.049776\n",
      "Total number of feature updates: 730935\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 359.084958\n",
      "Improvement ratio: 0.225271\n",
      "Feature L2-norm: 110.151271\n",
      "Learning rate (eta): 0.049771\n",
      "Total number of feature updates: 747178\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 370.776572\n",
      "Improvement ratio: 0.216835\n",
      "Feature L2-norm: 110.653045\n",
      "Learning rate (eta): 0.049766\n",
      "Total number of feature updates: 763421\n",
      "Seconds required for this iteration: 0.328\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 361.454314\n",
      "Improvement ratio: 0.207638\n",
      "Feature L2-norm: 111.144452\n",
      "Learning rate (eta): 0.049761\n",
      "Total number of feature updates: 779664\n",
      "Seconds required for this iteration: 0.358\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 352.154204\n",
      "Improvement ratio: 0.215068\n",
      "Feature L2-norm: 111.624444\n",
      "Learning rate (eta): 0.049756\n",
      "Total number of feature updates: 795907\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 342.855489\n",
      "Improvement ratio: 0.206681\n",
      "Feature L2-norm: 112.104300\n",
      "Learning rate (eta): 0.049751\n",
      "Total number of feature updates: 812150\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 342.926746\n",
      "Improvement ratio: 0.214782\n",
      "Feature L2-norm: 112.568652\n",
      "Learning rate (eta): 0.049746\n",
      "Total number of feature updates: 828393\n",
      "Seconds required for this iteration: 0.320\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 340.947325\n",
      "Improvement ratio: 0.123306\n",
      "Feature L2-norm: 113.021558\n",
      "Learning rate (eta): 0.049741\n",
      "Total number of feature updates: 844636\n",
      "Seconds required for this iteration: 0.321\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 318.609407\n",
      "Improvement ratio: 0.276434\n",
      "Feature L2-norm: 113.472180\n",
      "Learning rate (eta): 0.049736\n",
      "Total number of feature updates: 860879\n",
      "Seconds required for this iteration: 0.328\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 336.272954\n",
      "Improvement ratio: 0.130194\n",
      "Feature L2-norm: 113.912605\n",
      "Learning rate (eta): 0.049731\n",
      "Total number of feature updates: 877122\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 321.802313\n",
      "Improvement ratio: 0.190654\n",
      "Feature L2-norm: 114.347470\n",
      "Learning rate (eta): 0.049727\n",
      "Total number of feature updates: 893365\n",
      "Seconds required for this iteration: 0.322\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 317.455855\n",
      "Improvement ratio: 0.131134\n",
      "Feature L2-norm: 114.782372\n",
      "Learning rate (eta): 0.049722\n",
      "Total number of feature updates: 909608\n",
      "Seconds required for this iteration: 0.327\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 316.185514\n",
      "Improvement ratio: 0.172655\n",
      "Feature L2-norm: 115.197644\n",
      "Learning rate (eta): 0.049717\n",
      "Total number of feature updates: 925851\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 301.681311\n",
      "Improvement ratio: 0.198133\n",
      "Feature L2-norm: 115.618951\n",
      "Learning rate (eta): 0.049712\n",
      "Total number of feature updates: 942094\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 304.932782\n",
      "Improvement ratio: 0.154858\n",
      "Feature L2-norm: 116.020916\n",
      "Learning rate (eta): 0.049707\n",
      "Total number of feature updates: 958337\n",
      "Seconds required for this iteration: 0.321\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 287.819460\n",
      "Improvement ratio: 0.191217\n",
      "Feature L2-norm: 116.414893\n",
      "Learning rate (eta): 0.049702\n",
      "Total number of feature updates: 974580\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 330.721604\n",
      "Improvement ratio: 0.036905\n",
      "Feature L2-norm: 116.823358\n",
      "Learning rate (eta): 0.049697\n",
      "Total number of feature updates: 990823\n",
      "Seconds required for this iteration: 0.321\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 300.292414\n",
      "Improvement ratio: 0.135384\n",
      "Feature L2-norm: 117.203955\n",
      "Learning rate (eta): 0.049692\n",
      "Total number of feature updates: 1007066\n",
      "Seconds required for this iteration: 0.322\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 282.961433\n",
      "Improvement ratio: 0.125982\n",
      "Feature L2-norm: 117.580920\n",
      "Learning rate (eta): 0.049687\n",
      "Total number of feature updates: 1023309\n",
      "Seconds required for this iteration: 0.319\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 292.157013\n",
      "Improvement ratio: 0.151001\n",
      "Feature L2-norm: 117.960885\n",
      "Learning rate (eta): 0.049682\n",
      "Total number of feature updates: 1039552\n",
      "Seconds required for this iteration: 0.318\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 291.538748\n",
      "Improvement ratio: 0.103806\n",
      "Feature L2-norm: 118.326285\n",
      "Learning rate (eta): 0.049677\n",
      "Total number of feature updates: 1055795\n",
      "Seconds required for this iteration: 0.375\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 284.901108\n",
      "Improvement ratio: 0.114267\n",
      "Feature L2-norm: 118.688079\n",
      "Learning rate (eta): 0.049672\n",
      "Total number of feature updates: 1072038\n",
      "Seconds required for this iteration: 0.384\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 284.061964\n",
      "Improvement ratio: 0.113086\n",
      "Feature L2-norm: 119.040464\n",
      "Learning rate (eta): 0.049667\n",
      "Total number of feature updates: 1088281\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 279.281832\n",
      "Improvement ratio: 0.080204\n",
      "Feature L2-norm: 119.396291\n",
      "Learning rate (eta): 0.049662\n",
      "Total number of feature updates: 1104524\n",
      "Seconds required for this iteration: 0.318\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 278.266933\n",
      "Improvement ratio: 0.095828\n",
      "Feature L2-norm: 119.736616\n",
      "Learning rate (eta): 0.049657\n",
      "Total number of feature updates: 1120767\n",
      "Seconds required for this iteration: 0.321\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 272.729281\n",
      "Improvement ratio: 0.055330\n",
      "Feature L2-norm: 120.072999\n",
      "Learning rate (eta): 0.049652\n",
      "Total number of feature updates: 1137010\n",
      "Seconds required for this iteration: 0.361\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 251.951790\n",
      "Improvement ratio: 0.312638\n",
      "Feature L2-norm: 120.405571\n",
      "Learning rate (eta): 0.049648\n",
      "Total number of feature updates: 1153253\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 287.989845\n",
      "Improvement ratio: 0.042719\n",
      "Feature L2-norm: 120.736528\n",
      "Learning rate (eta): 0.049643\n",
      "Total number of feature updates: 1169496\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 267.430555\n",
      "Improvement ratio: 0.058074\n",
      "Feature L2-norm: 121.057720\n",
      "Learning rate (eta): 0.049638\n",
      "Total number of feature updates: 1185739\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 264.449771\n",
      "Improvement ratio: 0.104773\n",
      "Feature L2-norm: 121.382970\n",
      "Learning rate (eta): 0.049633\n",
      "Total number of feature updates: 1201982\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 255.982864\n",
      "Improvement ratio: 0.138899\n",
      "Feature L2-norm: 121.702607\n",
      "Learning rate (eta): 0.049628\n",
      "Total number of feature updates: 1218225\n",
      "Seconds required for this iteration: 0.319\n",
      "\n",
      "***** Epoch #76 *****\n",
      "Loss: 262.699569\n",
      "Improvement ratio: 0.084513\n",
      "Feature L2-norm: 122.012864\n",
      "Learning rate (eta): 0.049623\n",
      "Total number of feature updates: 1234468\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 253.900668\n",
      "Improvement ratio: 0.118792\n",
      "Feature L2-norm: 122.324158\n",
      "Learning rate (eta): 0.049618\n",
      "Total number of feature updates: 1250711\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 255.813028\n",
      "Improvement ratio: 0.091742\n",
      "Feature L2-norm: 122.625886\n",
      "Learning rate (eta): 0.049613\n",
      "Total number of feature updates: 1266954\n",
      "Seconds required for this iteration: 0.324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #79 *****\n",
      "Loss: 248.877650\n",
      "Improvement ratio: 0.118087\n",
      "Feature L2-norm: 122.925089\n",
      "Learning rate (eta): 0.049608\n",
      "Total number of feature updates: 1283197\n",
      "Seconds required for this iteration: 0.317\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 251.542934\n",
      "Improvement ratio: 0.084226\n",
      "Feature L2-norm: 123.221516\n",
      "Learning rate (eta): 0.049603\n",
      "Total number of feature updates: 1299440\n",
      "Seconds required for this iteration: 0.315\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 235.989812\n",
      "Improvement ratio: 0.067638\n",
      "Feature L2-norm: 123.517995\n",
      "Learning rate (eta): 0.049598\n",
      "Total number of feature updates: 1315683\n",
      "Seconds required for this iteration: 0.358\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 244.563722\n",
      "Improvement ratio: 0.177566\n",
      "Feature L2-norm: 123.812238\n",
      "Learning rate (eta): 0.049593\n",
      "Total number of feature updates: 1331926\n",
      "Seconds required for this iteration: 0.645\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 243.362781\n",
      "Improvement ratio: 0.098897\n",
      "Feature L2-norm: 124.102649\n",
      "Learning rate (eta): 0.049588\n",
      "Total number of feature updates: 1348169\n",
      "Seconds required for this iteration: 0.402\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 240.611680\n",
      "Improvement ratio: 0.099073\n",
      "Feature L2-norm: 124.386704\n",
      "Learning rate (eta): 0.049583\n",
      "Total number of feature updates: 1364412\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 242.618408\n",
      "Improvement ratio: 0.055084\n",
      "Feature L2-norm: 124.664413\n",
      "Learning rate (eta): 0.049579\n",
      "Total number of feature updates: 1380655\n",
      "Seconds required for this iteration: 0.318\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 241.152119\n",
      "Improvement ratio: 0.089352\n",
      "Feature L2-norm: 124.938698\n",
      "Learning rate (eta): 0.049574\n",
      "Total number of feature updates: 1396898\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #87 *****\n",
      "Loss: 229.534478\n",
      "Improvement ratio: 0.106155\n",
      "Feature L2-norm: 125.215484\n",
      "Learning rate (eta): 0.049569\n",
      "Total number of feature updates: 1413141\n",
      "Seconds required for this iteration: 0.319\n",
      "\n",
      "***** Epoch #88 *****\n",
      "Loss: 235.768101\n",
      "Improvement ratio: 0.085020\n",
      "Feature L2-norm: 125.481588\n",
      "Learning rate (eta): 0.049564\n",
      "Total number of feature updates: 1429384\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #89 *****\n",
      "Loss: 234.303824\n",
      "Improvement ratio: 0.062201\n",
      "Feature L2-norm: 125.746308\n",
      "Learning rate (eta): 0.049559\n",
      "Total number of feature updates: 1445627\n",
      "Seconds required for this iteration: 0.327\n",
      "\n",
      "***** Epoch #90 *****\n",
      "Loss: 232.912214\n",
      "Improvement ratio: 0.079990\n",
      "Feature L2-norm: 126.008219\n",
      "Learning rate (eta): 0.049554\n",
      "Total number of feature updates: 1461870\n",
      "Seconds required for this iteration: 0.317\n",
      "\n",
      "***** Epoch #91 *****\n",
      "Loss: 228.315203\n",
      "Improvement ratio: 0.033614\n",
      "Feature L2-norm: 126.272307\n",
      "Learning rate (eta): 0.049549\n",
      "Total number of feature updates: 1478113\n",
      "Seconds required for this iteration: 0.322\n",
      "\n",
      "***** Epoch #92 *****\n",
      "Loss: 237.502435\n",
      "Improvement ratio: 0.029731\n",
      "Feature L2-norm: 126.532338\n",
      "Learning rate (eta): 0.049544\n",
      "Total number of feature updates: 1494356\n",
      "Seconds required for this iteration: 0.319\n",
      "\n",
      "***** Epoch #93 *****\n",
      "Loss: 227.596237\n",
      "Improvement ratio: 0.069274\n",
      "Feature L2-norm: 126.787527\n",
      "Learning rate (eta): 0.049539\n",
      "Total number of feature updates: 1510599\n",
      "Seconds required for this iteration: 0.316\n",
      "\n",
      "***** Epoch #94 *****\n",
      "Loss: 229.648813\n",
      "Improvement ratio: 0.047738\n",
      "Feature L2-norm: 127.036671\n",
      "Learning rate (eta): 0.049534\n",
      "Total number of feature updates: 1526842\n",
      "Seconds required for this iteration: 0.316\n",
      "\n",
      "***** Epoch #95 *****\n",
      "Loss: 212.005519\n",
      "Improvement ratio: 0.144397\n",
      "Feature L2-norm: 127.284708\n",
      "Learning rate (eta): 0.049529\n",
      "Total number of feature updates: 1543085\n",
      "Seconds required for this iteration: 0.315\n",
      "\n",
      "***** Epoch #96 *****\n",
      "Loss: 220.497221\n",
      "Improvement ratio: 0.093674\n",
      "Feature L2-norm: 127.533966\n",
      "Learning rate (eta): 0.049525\n",
      "Total number of feature updates: 1559328\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #97 *****\n",
      "Loss: 219.909305\n",
      "Improvement ratio: 0.043769\n",
      "Feature L2-norm: 127.781095\n",
      "Learning rate (eta): 0.049520\n",
      "Total number of feature updates: 1575571\n",
      "Seconds required for this iteration: 0.318\n",
      "\n",
      "***** Epoch #98 *****\n",
      "Loss: 234.458560\n",
      "Improvement ratio: 0.005585\n",
      "Feature L2-norm: 128.024258\n",
      "Learning rate (eta): 0.049515\n",
      "Total number of feature updates: 1591814\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #99 *****\n",
      "Loss: 216.360065\n",
      "Improvement ratio: 0.082935\n",
      "Feature L2-norm: 128.270938\n",
      "Learning rate (eta): 0.049510\n",
      "Total number of feature updates: 1608057\n",
      "Seconds required for this iteration: 0.319\n",
      "\n",
      "***** Epoch #100 *****\n",
      "Loss: 219.390777\n",
      "Improvement ratio: 0.061632\n",
      "Feature L2-norm: 128.507633\n",
      "Learning rate (eta): 0.049505\n",
      "Total number of feature updates: 1624300\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #101 *****\n",
      "Loss: 217.697448\n",
      "Improvement ratio: 0.048773\n",
      "Feature L2-norm: 128.744851\n",
      "Learning rate (eta): 0.049500\n",
      "Total number of feature updates: 1640543\n",
      "Seconds required for this iteration: 0.314\n",
      "\n",
      "***** Epoch #102 *****\n",
      "Loss: 204.729497\n",
      "Improvement ratio: 0.160079\n",
      "Feature L2-norm: 128.983284\n",
      "Learning rate (eta): 0.049495\n",
      "Total number of feature updates: 1656786\n",
      "Seconds required for this iteration: 0.317\n",
      "\n",
      "***** Epoch #103 *****\n",
      "Loss: 215.840164\n",
      "Improvement ratio: 0.054467\n",
      "Feature L2-norm: 129.210554\n",
      "Learning rate (eta): 0.049490\n",
      "Total number of feature updates: 1673029\n",
      "Seconds required for this iteration: 0.316\n",
      "\n",
      "***** Epoch #104 *****\n",
      "Loss: 201.512834\n",
      "Improvement ratio: 0.139624\n",
      "Feature L2-norm: 129.435427\n",
      "Learning rate (eta): 0.049485\n",
      "Total number of feature updates: 1689272\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #105 *****\n",
      "Loss: 228.228852\n",
      "Improvement ratio: -0.071084\n",
      "Feature L2-norm: 129.665980\n",
      "Learning rate (eta): 0.049480\n",
      "Total number of feature updates: 1705515\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "SGD terminated with the stopping criteria\n",
      "Loss: 201.512834\n",
      "Total seconds required for training: 35.442\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 347546 (347546)\n",
      "Number of active attributes: 313573 (313573)\n",
      "Number of active labels: 11 (11)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.924\n",
      "\n",
      "(!) NerTagger training done\n",
      "\n",
      "(!) Tagging...\n",
      "(!) Tagging Word Level NER\n",
      "1. Tagged file V6ru_R2pina_Kahkva_id24674_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "2. Tagged file L22ne_Martna_Martna_id14205_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "3. Tagged file Harju_Juuru_Juuru_id19451_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "4. Tagged file Tartu_Kodavere_Ranna_id11316_1845a.json\n",
      "(!) Tagging Word Level NER\n",
      "5. Tagged file J2rva_Peetri_V2ike-Kareda_id22448_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "6. Tagged file L22ne_Vormsi_Vormsi_id24908_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "7. Tagged file J2rva_Tyri_V22tsa_id20382_1901a.json\n",
      "(!) Tagging Word Level NER\n",
      "8. Tagged file Tartu_Laiuse_Kivij2rve_id13162_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "9. Tagged file Tartu_V6nnu_Ahja_id20418_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "10. Tagged file L22ne_Vormsi_Vormsi_id24521_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "11. Tagged file P2rnu_Mihkli_Mihkli_id1099_1852a.json\n",
      "(!) Tagging Word Level NER\n",
      "12. Tagged file Tartu_V6nnu_Ahja_id16184_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "13. Tagged file Tartu_V6nnu_Ahja_id10343_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "14. Tagged file L22ne_Ridala_V6nnu_id2373_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "15. Tagged file Harju_Hageri_Kohila_id2634_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "16. Tagged file L22ne_Martna_Martna_id10803_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "17. Tagged file V6ru_Vastseliina_Misso_id13294_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "18. Tagged file P2rnu_Tori_Sindi_id3778_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "19. Tagged file Tartu_V6nnu_Ahja_id16117_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "20. Tagged file V6ru_Vastseliina_Misso_id13682_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "21. Tagged file Tartu_V6nnu_Ahja_id3502_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "22. Tagged file J2rva_Tyri_V22tsa_id22541_1914a.json\n",
      "(!) Tagging Word Level NER\n",
      "23. Tagged file L22ne_Pyhalepa_K2rdla_id24804_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "24. Tagged file Tartu_Kodavere_Alatskivi_id10108_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "25. Tagged file Tartu_V6nnu_Ahja_id13562_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "26. Tagged file Harju_Kose_Palvere_id15594_1881a.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Tagging Word Level NER\n",
      "27. Tagged file L22ne_Emmaste_Emmaste_id15087_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "28. Tagged file V6ru_Vastseliina_Misso_id19866_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "29. Tagged file J2rva_Tyri_Kirna_id24452_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "30. Tagged file Tartu_V6nnu_Ahja_id12638_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "31. Tagged file Tartu_Kodavere_Pala_id16229_1849a.json\n",
      "(!) Tagging Word Level NER\n",
      "32. Tagged file Harju_Rapla_Rapla_id365_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "33. Tagged file Viljandi_P6ltsamaa_Adavere_id20278_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "34. Tagged file Viljandi_Viljandi_Karula_id19366_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "35. Tagged file Tartu_Kodavere_Pala_id22898_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "36. Tagged file P2rnu_Audru_V6lla_id5904_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "37. Tagged file Harju_J6el2htme_J6el2htme_id7612_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "38. Tagged file J2rva_Peetri_V2ike-Kareda_id19169_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "39. Tagged file Tartu_V6nnu_Ahja_id20825_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "40. Tagged file P2rnu_T6stamaa_Kihnu_id25292_1843a.json\n",
      "(!) Tagging Word Level NER\n",
      "41. Tagged file Tartu_Kodavere_Alatskivi_id12944_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "42. Tagged file Viljandi_Paistu_Holstre_id11341_1848a.json\n",
      "(!) Tagging Word Level NER\n",
      "43. Tagged file J2rva_Anna_Eivere_id985_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "44. Tagged file Tartu_Kodavere_Ranna_id14285_1858a.json\n",
      "(!) Tagging Word Level NER\n",
      "45. Tagged file V6ru_R2pina_R2pina_id9603_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "46. Tagged file Tartu_Kodavere_Alatskivi_id9028_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "47. Tagged file Harju_Juuru_Kaiu_id1203_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "48. Tagged file V6ru_R6uge_Saaluse_id10045_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "49. Tagged file Tartu_V6nnu_Ahja_id17204_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "50. Tagged file Tartu_Torma_Avinurme_id20727_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "51. Tagged file L22ne_Vormsi_Vormsi_id24539_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "52. Tagged file Tartu_R6ngu_Aakre_id14645_1829a.json\n",
      "(!) Tagging Word Level NER\n",
      "53. Tagged file Tartu_V6nnu_Ahja_id19396_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "54. Tagged file Tartu_Laiuse_Kivij2rve_id6107_1864a.json\n",
      "(!) Tagging Word Level NER\n",
      "55. Tagged file Tartu_Kodavere_Ranna_id14144_1855a.json\n",
      "(!) Tagging Word Level NER\n",
      "56. Tagged file J2rva_Tyri_V22tsa_id17503_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "57. Tagged file Harju_Hageri_Kohila_id4769_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "58. Tagged file J2rva_Tyri_Kirna_id24911_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "59. Tagged file Tartu_V6nnu_Ahja_id20077_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "60. Tagged file Tartu_V6nnu_Ahja_id9677_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "61. Tagged file Tartu_Otep22_Pyhaj2rve_id1315_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "62. Tagged file Tartu_Kodavere_Alatskivi_id1603_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "63. Tagged file J2rva_Tyri_S2revere_id12869_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "64. Tagged file Tartu_Otep22_Pyhaj2rve_id3496_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "65. Tagged file P2rnu_Tori_Sindi_id20059_1836a.json\n",
      "(!) Tagging Word Level NER\n",
      "66. Tagged file L22ne_Reigi_K6rgessaare_id23007_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "67. Tagged file Viljandi_P6ltsamaa_Adavere_id12306_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "68. Tagged file Harju_Keila_Saue_id10625_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "69. Tagged file L22ne_Kullamaa_Piirsalu_id12153_1893a.json\n",
      "(!) Tagging Word Level NER\n",
      "70. Tagged file Tartu_R6ngu_Aakre_id5583_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "71. Tagged file Tartu_V6nnu_Ahja_id18082_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "72. Tagged file J2rva_Tyri_S2revere_id13610_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "73. Tagged file Viljandi_K6pu_Suure-K6pu_id12977_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "74. Tagged file L22ne_Kullamaa_Reop2_id15839_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "75. Tagged file Tartu_N6o_Pangodi_id4217_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "76. Tagged file P2rnu_Halliste_Penuja_id815_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "77. Tagged file Tartu_Torma_Avinurme_id21177_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "78. Tagged file L22ne_Kullamaa_Piirsalu_id16751_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "79. Tagged file J2rva_Tyri_V22tsa_id18538_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "80. Tagged file V6ru_R6uge_Saaluse_id11478_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "81. Tagged file Tartu_Kodavere_Pala_id22839_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "82. Tagged file Saare_Kihelkonna_Lymanda_id790_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "83. Tagged file Harju_Rapla_Rapla_id20935_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "84. Tagged file Tartu_V6nnu_Ahja_id23907_1897a.json\n",
      "(!) Tagging Word Level NER\n",
      "85. Tagged file Harju_J6el2htme_J6el2htme_id8152_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "86. Tagged file L22ne_Pyhalepa_K2rdla_id23487_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "87. Tagged file J2rva_Tyri_V22tsa_id17593_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "88. Tagged file Tartu_Kodavere_Alatskivi_id11023_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "89. Tagged file Harju_Kose_Palvere_id19503_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "90. Tagged file J2rva_Anna_Eivere_id1936_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "91. Tagged file Tartu_Kodavere_Ranna_id15116_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "92. Tagged file Tartu_Kodavere_Alatskivi_id7763_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "93. Tagged file J2rva_Tyri_Kirna_id25043_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "94. Tagged file Tartu_V6nnu_Ahja_id14888_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "95. Tagged file L22ne_Kullamaa_Kuij6e_id15484_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "96. Tagged file Tartu_Torma_Avinurme_id2512_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "97. Tagged file Tartu_Torma_Avinurme_id21056_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "98. Tagged file Tartu_Kodavere_Alatskivi_id19709_1857a.json\n",
      "(!) Tagging Word Level NER\n",
      "99. Tagged file Tartu_V6nnu_Ahja_id19568_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "100. Tagged file Tartu_Rannu_Valguta_id13505_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "101. Tagged file Tartu_Kodavere_Alatskivi_id10725_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "102. Tagged file Tartu_V6nnu_Ahja_id19780_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "103. Tagged file Tartu_V6nnu_Ahja_id16763_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "104. Tagged file L22ne_Pyhalepa_Kassari_id18786_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "105. Tagged file Harju_Hageri_Kohila_id1337_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "106. Tagged file Tartu_V6nnu_Ahja_id23642_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "107. Tagged file Tartu_V6nnu_Ahja_id14784_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "108. Tagged file Tartu_V6nnu_Ahja_id11997_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "109. Tagged file Tartu_V6nnu_Ahja_id12411_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "110. Tagged file Tartu_Torma_Avinurme_id21622_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "111. Tagged file Tartu_Kodavere_Alatskivi_id15715_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "112. Tagged file Harju_Hageri_Kohila_id11668_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "113. Tagged file P2rnu_Tori_Sindi_id19931_1835a.json\n",
      "(!) Tagging Word Level NER\n",
      "114. Tagged file Tartu_V6nnu_Kiidj2rve_id24727_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "115. Tagged file Tartu_R6ngu_Aakre_id2515_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "116. Tagged file P2rnu_T6stamaa_Seli_id10936_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "117. Tagged file L22ne_Vormsi_Vormsi_id24901_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "118. Tagged file J2rva_Ambla_Uudekyla_id13887_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "119. Tagged file Tartu_Kodavere_Alatskivi_id12862_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "120. Tagged file Viljandi_K6pu_Suure-K6pu_id6458_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "121. Tagged file Harju_Hageri_Kohila_id10284_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "122. Tagged file J2rva_Tyri_V22tsa_id20769_1903a.json\n",
      "(!) Tagging Word Level NER\n",
      "123. Tagged file Viljandi_K6pu_Suure-K6pu_id10880_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "124. Tagged file Tartu_Kodavere_Alatskivi_id1662_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "125. Tagged file Harju_Kose_Kose-Uuem6isa_id3126_1867a.json\n",
      "(!) Tagging Word Level NER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126. Tagged file Tartu_V6nnu_Ahja_id18630_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "127. Tagged file V6ru_Vastseliina_Misso_id13714_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "128. Tagged file V6ru_R2pina_Kahkva_id24938_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "129. Tagged file J2rva_Tyri_S2revere_id12762_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "130. Tagged file Tartu_Kodavere_Alatskivi_id21934_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "131. Tagged file V6ru_Vastseliina_Misso_id7468_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "132. Tagged file Saare_K2rla_K2rla_id5736_1827a.json\n",
      "(!) Tagging Word Level NER\n",
      "133. Tagged file Tartu_Sangaste_Kuigatsi_id16414_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "134. Tagged file Harju_Kose_Kose-Uuem6isa_id2174_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "135. Tagged file Viljandi_P6ltsamaa_Pajusi_id2717_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "136. Tagged file Viljandi_P6ltsamaa_Vana-P6ltsamaa_id8104_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "137. Tagged file Viljandi_K6pu_Suure-K6pu_id7189_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "138. Tagged file Tartu_V6nnu_Kiidj2rve_id25125_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "139. Tagged file L22ne_Reigi_K6rgessaare_id22613_1892a.json\n",
      "(!) Tagging Word Level NER\n",
      "140. Tagged file J2rva_Peetri_V2ike-Kareda_id19114_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "141. Tagged file Harju_Hageri_Kohila_id22158_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "142. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id17814_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "143. Tagged file Harju_Kose_Palvere_id561_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "144. Tagged file V6ru_R2pina_R2pina_id21267_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "145. Tagged file J2rva_Tyri_V22tsa_id20541_1902a.json\n",
      "(!) Tagging Word Level NER\n",
      "146. Tagged file Tartu_V6nnu_Ahja_id21768_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "147. Tagged file Tartu_V6nnu_Ahja_id20314_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "148. Tagged file Tartu_R6ngu_Aakre_id4282_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "149. Tagged file J2rva_Tyri_S2revere_id6796_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "150. Tagged file V6ru_R2pina_R2pina_id10711_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "151. Tagged file Harju_Kose_Palvere_id23525_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "152. Tagged file Tartu_R6ngu_Aakre_id13836_1829a.json\n",
      "(!) Tagging Word Level NER\n",
      "153. Tagged file P2rnu_Halliste_Penuja_id657_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "154. Tagged file Tartu_Kodavere_Alatskivi_id11390_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "155. Tagged file V6ru_Vastseliina_Misso_id11633_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "156. Tagged file Viljandi_P6ltsamaa_Adavere_id20850_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "157. Tagged file Tartu_Otep22_Pyhaj2rve_id3008_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "158. Tagged file J2rva_Ambla_Ambla_id7255_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "159. Tagged file Tartu_Torma_Avinurme_id23576_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "160. Tagged file Harju_J6el2htme_J6el2htme_id7375_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "161. Tagged file Tartu_Kodavere_Pala_id18163_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "162. Tagged file L22ne_Vormsi_Vormsi_id24037_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "163. Tagged file Tartu_V6nnu_Ahja_id22714_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "164. Tagged file Tartu_V6nnu_Ahja_id16433_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "165. Tagged file J2rva_Tyri_S2revere_id7087_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "166. Tagged file J2rva_Tyri_S2revere_id9048_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "167. Tagged file Harju_Keila_Saue_id14410_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "168. Tagged file Saare_Kihelkonna_Pidula_id5660_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "169. Tagged file Tartu_Kodavere_Pala_id21953_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "170. Tagged file Tartu_Kodavere_Pala_id21737_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "171. Tagged file Viljandi_Pilistvere_Arussaare_id9898_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "172. Tagged file V6ru_Vastseliina_Misso_id13222_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "173. Tagged file P2rnu_T6stamaa_Seli_id6548_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "174. Tagged file Viljandi_Paistu_Holstre_id11321_1848a.json\n",
      "(!) Tagging Word Level NER\n",
      "175. Tagged file J2rva_Anna_Eivere_id981_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "176. Tagged file Harju_Kose_Triigi_id10535_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "177. Tagged file Tartu_V6nnu_Ahja_id18345_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "178. Tagged file Tartu_Torma_Avinurme_id14451_1903a.json\n",
      "(!) Tagging Word Level NER\n",
      "179. Tagged file Tartu_V6nnu_Ahja_id19549_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "180. Tagged file Harju_Kose_Habaja_id675_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "181. Tagged file Harju_Hageri_Kohila_id21386_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "182. Tagged file P2rnu_Tori_Sindi_id7854_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "183. Tagged file Tartu_V6nnu_Ahja_id22271_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "184. Tagged file Viljandi_P6ltsamaa_Pajusi_id2463_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "185. Tagged file Tartu_R6ngu_Aakre_id5938_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "186. Tagged file Tartu_Kodavere_Pala_id18246_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "187. Tagged file J2rva_Tyri_S2revere_id12169_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "188. Tagged file Tartu_Torma_Avinurme_id17501_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "189. Tagged file Tartu_V6nnu_Ahja_id16602_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "190. Tagged file Tartu_V6nnu_Ahja_id17125_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "191. Tagged file L22ne_Pyhalepa_Kassari_id20363_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "192. Tagged file Tartu_V6nnu_Ahja_id17321_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "193. Tagged file Tartu_Laiuse_Kivij2rve_id4876_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "194. Tagged file Harju_Juuru_Kaiu_id18571_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "195. Tagged file V6ru_P6lva_Kiuma_id1633_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "196. Tagged file V6ru_Vastseliina_Misso_id25270_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "197. Tagged file V6ru_Vastseliina_Misso_id10250_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "198. Tagged file Viljandi_Suure-Jaani_Syrgavere_id20998_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "199. Tagged file J2rva_Tyri_V22tsa_id16934_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "200. Tagged file J2rva_Ambla_Uudekyla_id13485_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "201. Tagged file V6ru_P6lva_Peri_id10138_1891a.json\n",
      "(!) Tagging Word Level NER\n",
      "202. Tagged file Viljandi_Kolga-Jaani_Paenasti_id330_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "203. Tagged file Tartu_Torma_Avinurme_id17385_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "204. Tagged file V6ru_Vastseliina_Misso_id18830_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "205. Tagged file Tartu_Torma_Avinurme_id4086_1858a.json\n",
      "(!) Tagging Word Level NER\n",
      "206. Tagged file J2rva_Tyri_S2revere_id10947_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "207. Tagged file Harju_Kose_Habaja_id735_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "208. Tagged file Viru_Haljala_Vihula_id10570_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "209. Tagged file Harju_Kose_Triigi_id9690_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "210. Tagged file Tartu_Kodavere_Alatskivi_id10323_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "211. Tagged file V6ru_Vastseliina_Misso_id21200_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "212. Tagged file J2rva_Tyri_Kirna_id23696_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "213. Tagged file J2rva_J2rva-Jaani_Einmanni_id10155_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "214. Tagged file J2rva_Tyri_V22tsa_id20184_1899a.json\n",
      "(!) Tagging Word Level NER\n",
      "215. Tagged file Tartu_Kodavere_Alatskivi_id6197_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "216. Tagged file P2rnu_T6stamaa_Kihnu_id291_1860a.json\n",
      "(!) Tagging Word Level NER\n",
      "217. Tagged file Tartu_N6o_Pangodi_id5252_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "218. Tagged file Tartu_Otep22_Pyhaj2rve_id1640_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "219. Tagged file Tartu_V6nnu_Ahja_id14028_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "220. Tagged file P2rnu_Halliste_Penuja_id3900_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "221. Tagged file Tartu_V6nnu_Ahja_id11314_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "222. Tagged file J2rva_Peetri_V2ike-Kareda_id20208_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "223. Tagged file V6ru_Vastseliina_Misso_id5942_1885a.json\n",
      "(!) Tagging Word Level NER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224. Tagged file Tartu_V6nnu_Ahja_id20664_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "225. Tagged file Harju_Rapla_Rapla_id15629_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "226. Tagged file Tartu_V6nnu_Ahja_id16115_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "227. Tagged file V6ru_Urvaste_Vaabina_id798_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "228. Tagged file V6ru_R2pina_Kahkva_id7319_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "229. Tagged file Tartu_Kodavere_Pala_id22626_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "230. Tagged file Harju_Kose_Palvere_id15360_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "231. Tagged file Tartu_Kodavere_Alatskivi_id6838_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "232. Tagged file Viljandi_P6ltsamaa_Pajusi_id2106_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "233. Tagged file V6ru_R6uge_Saaluse_id9979_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "234. Tagged file Tartu_V6nnu_Ahja_id23400_1893a.json\n",
      "(!) Tagging Word Level NER\n",
      "235. Tagged file J2rva_Anna_Purdi_id18906_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "236. Tagged file Harju_Juuru_Kaiu_id13544_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "237. Tagged file Tartu_V6nnu_Ahja_id13151_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "238. Tagged file Harju_Kose_Palvere_id25267_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "239. Tagged file Viljandi_P6ltsamaa_Uue-P6ltsamaa_id8744_1854a.json\n",
      "(!) Tagging Word Level NER\n",
      "240. Tagged file Harju_Kose_Triigi_id10831_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "241. Tagged file J2rva_Tyri_Kirna_id23927_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "242. Tagged file L22ne_K2ina_Vaemla_id284_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "243. Tagged file Saare_Kihelkonna_Lymanda_id5518_1833a.json\n",
      "(!) Tagging Word Level NER\n",
      "244. Tagged file V6ru_R2pina_Kahkva_id24658_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "245. Tagged file Harju_Hageri_Kohila_id11528_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "246. Tagged file J2rva_Tyri_S2revere_id9101_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "247. Tagged file Harju_Hageri_Kohila_id10509_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "248. Tagged file L22ne_Vormsi_Vormsi_id25041_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "249. Tagged file Tartu_V6nnu_Ahja_id12353_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "250. Tagged file J2rva_Tyri_S2revere_id14526_1886a.json\n",
      "(!) Files tagged\n",
      "(!) Preparing training texts\n",
      "(!) Training texts done\n",
      "(!) Training NerTagger\n",
      "(!) Warning: Location of the new \"settings.py\" is the same one as the old one. Model's settings are not copied.\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 350347\n",
      "Seconds required: 2.233\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 1000\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 31748.133412\n",
      "Trial #1 (eta = 0.100000): 2577.040740\n",
      "Trial #2 (eta = 0.200000): 3977.413390\n",
      "Trial #3 (eta = 0.400000): 8688.458606\n",
      "Trial #4 (eta = 0.800000): 17912.755161\n",
      "Trial #5 (eta = 1.600000): 35554.741476 (worse)\n",
      "Trial #6 (eta = 0.050000): 2352.505362\n",
      "Trial #7 (eta = 0.025000): 2566.291407\n",
      "Trial #8 (eta = 0.012500): 2993.099463\n",
      "Trial #9 (eta = 0.006250): 3578.967608\n",
      "Trial #10 (eta = 0.003125): 4394.440220\n",
      "Trial #11 (eta = 0.001563): 5592.482369\n",
      "Trial #12 (eta = 0.000781): 7452.256476\n",
      "Trial #13 (eta = 0.000391): 10380.266505\n",
      "Trial #14 (eta = 0.000195): 14599.958236\n",
      "Trial #15 (eta = 0.000098): 19893.256449\n",
      "Best learning rate (eta): 0.050000\n",
      "Seconds required: 0.330\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 18500.536855\n",
      "Feature L2-norm: 33.205216\n",
      "Learning rate (eta): 0.049995\n",
      "Total number of feature updates: 16201\n",
      "Seconds required for this iteration: 0.356\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 8440.160974\n",
      "Feature L2-norm: 42.775629\n",
      "Learning rate (eta): 0.049990\n",
      "Total number of feature updates: 32402\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 5985.762984\n",
      "Feature L2-norm: 49.476191\n",
      "Learning rate (eta): 0.049985\n",
      "Total number of feature updates: 48603\n",
      "Seconds required for this iteration: 0.377\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 4562.287772\n",
      "Feature L2-norm: 54.775693\n",
      "Learning rate (eta): 0.049980\n",
      "Total number of feature updates: 64804\n",
      "Seconds required for this iteration: 0.360\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 3785.041010\n",
      "Feature L2-norm: 59.351088\n",
      "Learning rate (eta): 0.049975\n",
      "Total number of feature updates: 81005\n",
      "Seconds required for this iteration: 0.354\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 3038.242756\n",
      "Feature L2-norm: 63.146666\n",
      "Learning rate (eta): 0.049970\n",
      "Total number of feature updates: 97206\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 2553.649444\n",
      "Feature L2-norm: 66.434269\n",
      "Learning rate (eta): 0.049965\n",
      "Total number of feature updates: 113407\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 2234.174360\n",
      "Feature L2-norm: 69.361010\n",
      "Learning rate (eta): 0.049960\n",
      "Total number of feature updates: 129608\n",
      "Seconds required for this iteration: 0.364\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 1948.778644\n",
      "Feature L2-norm: 71.988671\n",
      "Learning rate (eta): 0.049955\n",
      "Total number of feature updates: 145809\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 1931.925959\n",
      "Feature L2-norm: 74.552146\n",
      "Learning rate (eta): 0.049950\n",
      "Total number of feature updates: 162010\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 1591.267730\n",
      "Improvement ratio: 10.626288\n",
      "Feature L2-norm: 76.746518\n",
      "Learning rate (eta): 0.049945\n",
      "Total number of feature updates: 178211\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 1400.512587\n",
      "Improvement ratio: 5.026480\n",
      "Feature L2-norm: 78.721044\n",
      "Learning rate (eta): 0.049940\n",
      "Total number of feature updates: 194412\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 1300.087823\n",
      "Improvement ratio: 3.604122\n",
      "Feature L2-norm: 80.564567\n",
      "Learning rate (eta): 0.049935\n",
      "Total number of feature updates: 210613\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 1215.628809\n",
      "Improvement ratio: 2.753027\n",
      "Feature L2-norm: 82.298589\n",
      "Learning rate (eta): 0.049930\n",
      "Total number of feature updates: 226814\n",
      "Seconds required for this iteration: 0.342\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 1102.682275\n",
      "Improvement ratio: 2.432576\n",
      "Feature L2-norm: 83.900292\n",
      "Learning rate (eta): 0.049925\n",
      "Total number of feature updates: 243015\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 1020.545582\n",
      "Improvement ratio: 1.977077\n",
      "Feature L2-norm: 85.414935\n",
      "Learning rate (eta): 0.049920\n",
      "Total number of feature updates: 259216\n",
      "Seconds required for this iteration: 0.342\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 973.887171\n",
      "Improvement ratio: 1.622120\n",
      "Feature L2-norm: 86.849375\n",
      "Learning rate (eta): 0.049915\n",
      "Total number of feature updates: 275417\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 898.577914\n",
      "Improvement ratio: 1.486345\n",
      "Feature L2-norm: 88.175654\n",
      "Learning rate (eta): 0.049910\n",
      "Total number of feature updates: 291618\n",
      "Seconds required for this iteration: 0.342\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 872.432798\n",
      "Improvement ratio: 1.233729\n",
      "Feature L2-norm: 89.442593\n",
      "Learning rate (eta): 0.049905\n",
      "Total number of feature updates: 307819\n",
      "Seconds required for this iteration: 0.347\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 817.718397\n",
      "Improvement ratio: 1.362581\n",
      "Feature L2-norm: 90.663975\n",
      "Learning rate (eta): 0.049900\n",
      "Total number of feature updates: 324020\n",
      "Seconds required for this iteration: 0.347\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 771.812147\n",
      "Improvement ratio: 1.061729\n",
      "Feature L2-norm: 91.800664\n",
      "Learning rate (eta): 0.049895\n",
      "Total number of feature updates: 340221\n",
      "Seconds required for this iteration: 0.363\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 768.774172\n",
      "Improvement ratio: 0.821748\n",
      "Feature L2-norm: 92.914051\n",
      "Learning rate (eta): 0.049890\n",
      "Total number of feature updates: 356422\n",
      "Seconds required for this iteration: 0.390\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 717.651072\n",
      "Improvement ratio: 0.811588\n",
      "Feature L2-norm: 93.962942\n",
      "Learning rate (eta): 0.049885\n",
      "Total number of feature updates: 372623\n",
      "Seconds required for this iteration: 0.383\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 681.697823\n",
      "Improvement ratio: 0.783237\n",
      "Feature L2-norm: 94.974092\n",
      "Learning rate (eta): 0.049880\n",
      "Total number of feature updates: 388824\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 657.374329\n",
      "Improvement ratio: 0.677404\n",
      "Feature L2-norm: 95.940139\n",
      "Learning rate (eta): 0.049875\n",
      "Total number of feature updates: 405025\n",
      "Seconds required for this iteration: 0.349\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #26 *****\n",
      "Loss: 643.418905\n",
      "Improvement ratio: 0.586129\n",
      "Feature L2-norm: 96.868894\n",
      "Learning rate (eta): 0.049870\n",
      "Total number of feature updates: 421226\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 613.490752\n",
      "Improvement ratio: 0.587452\n",
      "Feature L2-norm: 97.755125\n",
      "Learning rate (eta): 0.049865\n",
      "Total number of feature updates: 437427\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 594.890996\n",
      "Improvement ratio: 0.510492\n",
      "Feature L2-norm: 98.615812\n",
      "Learning rate (eta): 0.049860\n",
      "Total number of feature updates: 453628\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 583.003786\n",
      "Improvement ratio: 0.496444\n",
      "Feature L2-norm: 99.439642\n",
      "Learning rate (eta): 0.049855\n",
      "Total number of feature updates: 469829\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 551.861776\n",
      "Improvement ratio: 0.481745\n",
      "Feature L2-norm: 100.238830\n",
      "Learning rate (eta): 0.049850\n",
      "Total number of feature updates: 486030\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 533.611150\n",
      "Improvement ratio: 0.446394\n",
      "Feature L2-norm: 101.015683\n",
      "Learning rate (eta): 0.049845\n",
      "Total number of feature updates: 502231\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 529.007178\n",
      "Improvement ratio: 0.453240\n",
      "Feature L2-norm: 101.757426\n",
      "Learning rate (eta): 0.049841\n",
      "Total number of feature updates: 518432\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 513.021239\n",
      "Improvement ratio: 0.398872\n",
      "Feature L2-norm: 102.481433\n",
      "Learning rate (eta): 0.049836\n",
      "Total number of feature updates: 534633\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 490.532478\n",
      "Improvement ratio: 0.389710\n",
      "Feature L2-norm: 103.193110\n",
      "Learning rate (eta): 0.049831\n",
      "Total number of feature updates: 550834\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 492.071730\n",
      "Improvement ratio: 0.335932\n",
      "Feature L2-norm: 103.885894\n",
      "Learning rate (eta): 0.049826\n",
      "Total number of feature updates: 567035\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 469.002414\n",
      "Improvement ratio: 0.371888\n",
      "Feature L2-norm: 104.554357\n",
      "Learning rate (eta): 0.049821\n",
      "Total number of feature updates: 583236\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 460.020986\n",
      "Improvement ratio: 0.333615\n",
      "Feature L2-norm: 105.203470\n",
      "Learning rate (eta): 0.049816\n",
      "Total number of feature updates: 599437\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 449.419599\n",
      "Improvement ratio: 0.323687\n",
      "Feature L2-norm: 105.837487\n",
      "Learning rate (eta): 0.049811\n",
      "Total number of feature updates: 615638\n",
      "Seconds required for this iteration: 0.347\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 446.316234\n",
      "Improvement ratio: 0.306257\n",
      "Feature L2-norm: 106.449777\n",
      "Learning rate (eta): 0.049806\n",
      "Total number of feature updates: 631839\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 430.775237\n",
      "Improvement ratio: 0.281090\n",
      "Feature L2-norm: 107.060007\n",
      "Learning rate (eta): 0.049801\n",
      "Total number of feature updates: 648040\n",
      "Seconds required for this iteration: 0.344\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 416.983289\n",
      "Improvement ratio: 0.279694\n",
      "Feature L2-norm: 107.650637\n",
      "Learning rate (eta): 0.049796\n",
      "Total number of feature updates: 664241\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 409.840064\n",
      "Improvement ratio: 0.290765\n",
      "Feature L2-norm: 108.235258\n",
      "Learning rate (eta): 0.049791\n",
      "Total number of feature updates: 680442\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 411.196038\n",
      "Improvement ratio: 0.247632\n",
      "Feature L2-norm: 108.791424\n",
      "Learning rate (eta): 0.049786\n",
      "Total number of feature updates: 696643\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 402.062679\n",
      "Improvement ratio: 0.220040\n",
      "Feature L2-norm: 109.331422\n",
      "Learning rate (eta): 0.049781\n",
      "Total number of feature updates: 712844\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 396.155474\n",
      "Improvement ratio: 0.242118\n",
      "Feature L2-norm: 109.866053\n",
      "Learning rate (eta): 0.049776\n",
      "Total number of feature updates: 729045\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 393.613547\n",
      "Improvement ratio: 0.191530\n",
      "Feature L2-norm: 110.393942\n",
      "Learning rate (eta): 0.049771\n",
      "Total number of feature updates: 745246\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 367.839240\n",
      "Improvement ratio: 0.250603\n",
      "Feature L2-norm: 110.907550\n",
      "Learning rate (eta): 0.049766\n",
      "Total number of feature updates: 761447\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 384.263669\n",
      "Improvement ratio: 0.169560\n",
      "Feature L2-norm: 111.406122\n",
      "Learning rate (eta): 0.049761\n",
      "Total number of feature updates: 777648\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 357.706872\n",
      "Improvement ratio: 0.247715\n",
      "Feature L2-norm: 111.896580\n",
      "Learning rate (eta): 0.049756\n",
      "Total number of feature updates: 793849\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 369.056274\n",
      "Improvement ratio: 0.167235\n",
      "Feature L2-norm: 112.389112\n",
      "Learning rate (eta): 0.049751\n",
      "Total number of feature updates: 810050\n",
      "Seconds required for this iteration: 0.390\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 354.005485\n",
      "Improvement ratio: 0.177901\n",
      "Feature L2-norm: 112.866171\n",
      "Learning rate (eta): 0.049746\n",
      "Total number of feature updates: 826251\n",
      "Seconds required for this iteration: 0.416\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 340.581068\n",
      "Improvement ratio: 0.203355\n",
      "Feature L2-norm: 113.329794\n",
      "Learning rate (eta): 0.049741\n",
      "Total number of feature updates: 842452\n",
      "Seconds required for this iteration: 0.354\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 352.113815\n",
      "Improvement ratio: 0.167793\n",
      "Feature L2-norm: 113.783298\n",
      "Learning rate (eta): 0.049736\n",
      "Total number of feature updates: 858653\n",
      "Seconds required for this iteration: 0.367\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 332.121738\n",
      "Improvement ratio: 0.210588\n",
      "Feature L2-norm: 114.235772\n",
      "Learning rate (eta): 0.049731\n",
      "Total number of feature updates: 874854\n",
      "Seconds required for this iteration: 0.401\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 322.480486\n",
      "Improvement ratio: 0.228463\n",
      "Feature L2-norm: 114.670876\n",
      "Learning rate (eta): 0.049727\n",
      "Total number of feature updates: 891055\n",
      "Seconds required for this iteration: 0.358\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 354.551675\n",
      "Improvement ratio: 0.110173\n",
      "Feature L2-norm: 115.100481\n",
      "Learning rate (eta): 0.049722\n",
      "Total number of feature updates: 907256\n",
      "Seconds required for this iteration: 0.358\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 334.978644\n",
      "Improvement ratio: 0.098098\n",
      "Feature L2-norm: 115.517680\n",
      "Learning rate (eta): 0.049717\n",
      "Total number of feature updates: 923457\n",
      "Seconds required for this iteration: 0.366\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 333.137609\n",
      "Improvement ratio: 0.153468\n",
      "Feature L2-norm: 115.939231\n",
      "Learning rate (eta): 0.049712\n",
      "Total number of feature updates: 939658\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 326.368322\n",
      "Improvement ratio: 0.096022\n",
      "Feature L2-norm: 116.344514\n",
      "Learning rate (eta): 0.049707\n",
      "Total number of feature updates: 955859\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 301.124638\n",
      "Improvement ratio: 0.225593\n",
      "Feature L2-norm: 116.745354\n",
      "Learning rate (eta): 0.049702\n",
      "Total number of feature updates: 972060\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 330.344446\n",
      "Improvement ratio: 0.071625\n",
      "Feature L2-norm: 117.138462\n",
      "Learning rate (eta): 0.049697\n",
      "Total number of feature updates: 988261\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 311.926267\n",
      "Improvement ratio: 0.091864\n",
      "Feature L2-norm: 117.530713\n",
      "Learning rate (eta): 0.049692\n",
      "Total number of feature updates: 1004462\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 308.252386\n",
      "Improvement ratio: 0.142291\n",
      "Feature L2-norm: 117.908870\n",
      "Learning rate (eta): 0.049687\n",
      "Total number of feature updates: 1020663\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 307.200455\n",
      "Improvement ratio: 0.081124\n",
      "Feature L2-norm: 118.288111\n",
      "Learning rate (eta): 0.049682\n",
      "Total number of feature updates: 1036864\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 297.379430\n",
      "Improvement ratio: 0.084408\n",
      "Feature L2-norm: 118.658771\n",
      "Learning rate (eta): 0.049677\n",
      "Total number of feature updates: 1053065\n",
      "Seconds required for this iteration: 0.347\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #66 *****\n",
      "Loss: 281.598319\n",
      "Improvement ratio: 0.259069\n",
      "Feature L2-norm: 119.019864\n",
      "Learning rate (eta): 0.049672\n",
      "Total number of feature updates: 1069266\n",
      "Seconds required for this iteration: 0.352\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 307.675712\n",
      "Improvement ratio: 0.088739\n",
      "Feature L2-norm: 119.380901\n",
      "Learning rate (eta): 0.049667\n",
      "Total number of feature updates: 1085467\n",
      "Seconds required for this iteration: 0.365\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 293.714445\n",
      "Improvement ratio: 0.134223\n",
      "Feature L2-norm: 119.733183\n",
      "Learning rate (eta): 0.049662\n",
      "Total number of feature updates: 1101668\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 289.918656\n",
      "Improvement ratio: 0.125724\n",
      "Feature L2-norm: 120.078536\n",
      "Learning rate (eta): 0.049657\n",
      "Total number of feature updates: 1117869\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 282.575739\n",
      "Improvement ratio: 0.065642\n",
      "Feature L2-norm: 120.425327\n",
      "Learning rate (eta): 0.049652\n",
      "Total number of feature updates: 1134070\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 288.347665\n",
      "Improvement ratio: 0.145646\n",
      "Feature L2-norm: 120.755814\n",
      "Learning rate (eta): 0.049648\n",
      "Total number of feature updates: 1150271\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 279.358555\n",
      "Improvement ratio: 0.116580\n",
      "Feature L2-norm: 121.091938\n",
      "Learning rate (eta): 0.049643\n",
      "Total number of feature updates: 1166472\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 280.484070\n",
      "Improvement ratio: 0.099001\n",
      "Feature L2-norm: 121.418908\n",
      "Learning rate (eta): 0.049638\n",
      "Total number of feature updates: 1182673\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 276.407752\n",
      "Improvement ratio: 0.111403\n",
      "Feature L2-norm: 121.744405\n",
      "Learning rate (eta): 0.049633\n",
      "Total number of feature updates: 1198874\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 275.093210\n",
      "Improvement ratio: 0.081013\n",
      "Feature L2-norm: 122.059580\n",
      "Learning rate (eta): 0.049628\n",
      "Total number of feature updates: 1215075\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #76 *****\n",
      "Loss: 256.278013\n",
      "Improvement ratio: 0.098800\n",
      "Feature L2-norm: 122.372940\n",
      "Learning rate (eta): 0.049623\n",
      "Total number of feature updates: 1231276\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 285.069791\n",
      "Improvement ratio: 0.079300\n",
      "Feature L2-norm: 122.681161\n",
      "Learning rate (eta): 0.049618\n",
      "Total number of feature updates: 1247477\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 261.829739\n",
      "Improvement ratio: 0.121776\n",
      "Feature L2-norm: 122.993204\n",
      "Learning rate (eta): 0.049613\n",
      "Total number of feature updates: 1263678\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #79 *****\n",
      "Loss: 261.699950\n",
      "Improvement ratio: 0.107828\n",
      "Feature L2-norm: 123.298677\n",
      "Learning rate (eta): 0.049608\n",
      "Total number of feature updates: 1279879\n",
      "Seconds required for this iteration: 0.353\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 262.562887\n",
      "Improvement ratio: 0.076221\n",
      "Feature L2-norm: 123.595675\n",
      "Learning rate (eta): 0.049603\n",
      "Total number of feature updates: 1296080\n",
      "Seconds required for this iteration: 0.357\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 258.306062\n",
      "Improvement ratio: 0.116302\n",
      "Feature L2-norm: 123.893318\n",
      "Learning rate (eta): 0.049598\n",
      "Total number of feature updates: 1312281\n",
      "Seconds required for this iteration: 0.354\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 257.259925\n",
      "Improvement ratio: 0.085900\n",
      "Feature L2-norm: 124.188329\n",
      "Learning rate (eta): 0.049593\n",
      "Total number of feature updates: 1328482\n",
      "Seconds required for this iteration: 0.360\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 242.044659\n",
      "Improvement ratio: 0.158811\n",
      "Feature L2-norm: 124.480815\n",
      "Learning rate (eta): 0.049588\n",
      "Total number of feature updates: 1344683\n",
      "Seconds required for this iteration: 0.354\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 238.051297\n",
      "Improvement ratio: 0.161127\n",
      "Feature L2-norm: 124.763800\n",
      "Learning rate (eta): 0.049583\n",
      "Total number of feature updates: 1360884\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 253.550781\n",
      "Improvement ratio: 0.084963\n",
      "Feature L2-norm: 125.046332\n",
      "Learning rate (eta): 0.049579\n",
      "Total number of feature updates: 1377085\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 264.300104\n",
      "Improvement ratio: -0.030352\n",
      "Feature L2-norm: 125.326877\n",
      "Learning rate (eta): 0.049574\n",
      "Total number of feature updates: 1393286\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "SGD terminated with the stopping criteria\n",
      "Loss: 238.051297\n",
      "Total seconds required for training: 30.282\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 350347 (350347)\n",
      "Number of active attributes: 316367 (316367)\n",
      "Number of active labels: 11 (11)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.942\n",
      "\n",
      "(!) NerTagger training done\n",
      "\n",
      "(!) Tagging...\n",
      "(!) Tagging Word Level NER\n",
      "1. Tagged file J2rva_Tyri_S2revere_id9947_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "2. Tagged file Tartu_R6ngu_Aakre_id6606_1826a.json\n",
      "(!) Tagging Word Level NER\n",
      "3. Tagged file Viru_Haljala_Vihula_id5807_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "4. Tagged file J2rva_Peetri_V2ike-Kareda_id19932_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "5. Tagged file Tartu_V6nnu_Ahja_id20321_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "6. Tagged file J2rva_Tyri_Kirna_id24067_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "7. Tagged file Tartu_V6nnu_Ahja_id19042_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "8. Tagged file V6ru_R2pina_R2pina_id9472_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "9. Tagged file Saare_Kihelkonna_Atla_id7135_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "10. Tagged file Tartu_Kodavere_Alatskivi_id22077_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "11. Tagged file Harju_Kuusalu_Kolga_id15956_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "12. Tagged file Tartu_V6nnu_Ahja_id23394_1893a.json\n",
      "(!) Tagging Word Level NER\n",
      "13. Tagged file Viljandi_Pilistvere_Arussaare_id24509_1855a.json\n",
      "(!) Tagging Word Level NER\n",
      "14. Tagged file Tartu_Torma_Avinurme_id14475_1903a.json\n",
      "(!) Tagging Word Level NER\n",
      "15. Tagged file L22ne_Kullamaa_Kuij6e_id15780_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "16. Tagged file Tartu_Kodavere_Alatskivi_id7557_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "17. Tagged file Tartu_V6nnu_Ahja_id14767_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "18. Tagged file Tartu_N6o_Luke_id4149_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "19. Tagged file Viljandi_Viljandi_Karula_id19357_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "20. Tagged file Tartu_Otep22_Pyhaj2rve_id1517_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "21. Tagged file Tartu_Kodavere_Alatskivi_id15347_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "22. Tagged file Tartu_V6nnu_Ahja_id21806_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "23. Tagged file Harju_Juuru_Kaiu_id3479_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "24. Tagged file Tartu_Torma_Avinurme_id10136_1901a.json\n",
      "(!) Tagging Word Level NER\n",
      "25. Tagged file Tartu_Kodavere_Pala_id21272_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "26. Tagged file Tartu_V6nnu_Ahja_id16981_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "27. Tagged file Tartu_Torma_Avinurme_id12737_1902a.json\n",
      "(!) Tagging Word Level NER\n",
      "28. Tagged file Saare_Kihelkonna_Kotlandi_id20933_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "29. Tagged file J2rva_J2rva-Jaani_Einmanni_id25202_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "30. Tagged file V6ru_R2pina_R2pina_id10850_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "31. Tagged file L22ne_Pyhalepa_K2rdla_id23543_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "32. Tagged file Harju_Juuru_Juuru_id17050_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "33. Tagged file Harju_Kose_Palvere_id20647_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "34. Tagged file Tartu_V6nnu_Ahja_id16395_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "35. Tagged file Tartu_V6nnu_Ahja_id12656_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "36. Tagged file Tartu_Kodavere_Pala_id22108_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "37. Tagged file Tartu_Kambja_Haaslava_id8704_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "38. Tagged file Tartu_N6o_Aru_id306_1859a.json\n",
      "(!) Tagging Word Level NER\n",
      "39. Tagged file Tartu_Kodavere_Ranna_id15165_1864a.json\n",
      "(!) Tagging Word Level NER\n",
      "40. Tagged file Tartu_V6nnu_Ahja_id17984_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "41. Tagged file Tartu_Kodavere_Ranna_id14138_1855a.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Tagging Word Level NER\n",
      "42. Tagged file L22ne_Kullamaa_Sooniste_id3541_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "43. Tagged file J2rva_Tyri_Tyri-Alliku_id2315_1897a.json\n",
      "(!) Tagging Word Level NER\n",
      "44. Tagged file J2rva_Tyri_S2revere_id11683_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "45. Tagged file Saare_Kaarma_Loona_id7575_1899a.json\n",
      "(!) Tagging Word Level NER\n",
      "46. Tagged file V6ru_P6lva_K2hri_id21590_1851a.json\n",
      "(!) Tagging Word Level NER\n",
      "47. Tagged file Tartu_V6nnu_Ahja_id16351_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "48. Tagged file Tartu_V6nnu_Ahja_id11361_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "49. Tagged file Tartu_V6nnu_Ahja_id16121_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "50. Tagged file Tartu_V6nnu_Ahja_id21444_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "51. Tagged file J2rva_Tyri_S2revere_id14702_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "52. Tagged file L22ne_Martna_Martna_id12705_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "53. Tagged file Tartu_Torma_Avinurme_id6291_1861a.json\n",
      "(!) Tagging Word Level NER\n",
      "54. Tagged file Harju_Kose_Palvere_id16297_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "55. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id18115_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "56. Tagged file Tartu_Kambja_Vana-Prangli_id19091_1909a.json\n",
      "(!) Tagging Word Level NER\n",
      "57. Tagged file Tartu_V6nnu_Ahja_id14900_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "58. Tagged file Tartu_V6nnu_Ahja_id19074_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "59. Tagged file L22ne_Kullamaa_Piirsalu_id15463_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "60. Tagged file Harju_Kose_Palvere_id14358_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "61. Tagged file L22ne_Vormsi_Vormsi_id24517_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "62. Tagged file Harju_Kose_Palvere_id18727_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "63. Tagged file Saare_P8ide_Laimjala_id6593_1917a.json\n",
      "(!) Tagging Word Level NER\n",
      "64. Tagged file V6ru_R6uge_Leevi_id24854_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "65. Tagged file Harju_Keila_Keila_id13472_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "66. Tagged file Tartu_R6ngu_Aakre_id2817_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "67. Tagged file Tartu_V6nnu_Ahja_id13953_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "68. Tagged file Tartu_Kodavere_Alatskivi_id12235_1856a.json\n",
      "(!) Tagging Word Level NER\n",
      "69. Tagged file J2rva_Peetri_Silmsi_id23715_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "70. Tagged file P2rnu_Tori_Tori_id25326_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "71. Tagged file Tartu_Kodavere_Alatskivi_id1266_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "72. Tagged file Tartu_Kodavere_Pala_id17804_1861a.json\n",
      "(!) Tagging Word Level NER\n",
      "73. Tagged file L22ne_Pyhalepa_Kassari_id20356_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "74. Tagged file Tartu_Otep22_Pyhaj2rve_id4865_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "75. Tagged file Tartu_Kodavere_Alatskivi_id21764_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "76. Tagged file Tartu_V6nnu_Ahja_id23497_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "77. Tagged file Tartu_Torma_Avinurme_id4091_1858a.json\n",
      "(!) Tagging Word Level NER\n",
      "78. Tagged file Tartu_V6nnu_Ahja_id1431_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "79. Tagged file Tartu_Otep22_Pyhaj2rve_id7845_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "80. Tagged file Tartu_V6nnu_Ahja_id17530_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "81. Tagged file L22ne_Emmaste_Emmaste_id16061_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "82. Tagged file J2rva_Tyri_V22tsa_id20587_1902a.json\n",
      "(!) Tagging Word Level NER\n",
      "83. Tagged file P2rnu_Halliste_Abja_id257_1844a.json\n",
      "(!) Tagging Word Level NER\n",
      "84. Tagged file Harju_Kuusalu_Kolga_id11586_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "85. Tagged file Tartu_Torma_Avinurme_id22159_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "86. Tagged file P2rnu_Tori_Tori_id22633_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "87. Tagged file Harju_Kose_Habaja_id733_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "88. Tagged file Harju_Hageri_Kohila_id5579_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "89. Tagged file Tartu_Kodavere_Alatskivi_id13497_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "90. Tagged file Tartu_R6ngu_Aakre_id1396_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "91. Tagged file Harju_Kuusalu_Kolga_id11589_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "92. Tagged file J2rva_J2rva-Jaani_Karinu_id1338_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "93. Tagged file Harju_Kose_Palvere_id18187_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "94. Tagged file Harju_Kose_Palvere_id15288_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "95. Tagged file L22ne_Martna_Martna_id24960_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "96. Tagged file V6ru_Vastseliina_Misso_id5941_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "97. Tagged file V6ru_Vastseliina_Misso_id24818_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "98. Tagged file Tartu_V6nnu_Ahja_id15321_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "99. Tagged file Harju_Juuru_Juuru_id493_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "100. Tagged file Tartu_Laiuse_Kivij2rve_id15455_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "101. Tagged file Tartu_V6nnu_Ahja_id16984_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "102. Tagged file J2rva_Ambla_Ambla_id7106_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "103. Tagged file L22ne_Ridala_Sinalepa_id25516_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "104. Tagged file J2rva_Ambla_Ambla_id11918_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "105. Tagged file Harju_Juuru_Juuru_id3335_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "106. Tagged file L22ne_Pyhalepa_K2rdla_id23196_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "107. Tagged file Tartu_Kodavere_Alatskivi_id7278_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "108. Tagged file Tartu_V6nnu_Ahja_id17220_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "109. Tagged file Tartu_V6nnu_Ahja_id22713_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "110. Tagged file Tartu_Kodavere_Alatskivi_id15038_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "111. Tagged file J2rva_Tyri_V22tsa_id16517_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "112. Tagged file L22ne_Pyhalepa_K2rdla_id23200_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "113. Tagged file Tartu_V6nnu_Ahja_id20514_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "114. Tagged file J2rva_Tyri_V22tsa_id17742_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "115. Tagged file J2rva_Tyri_S2revere_id13938_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "116. Tagged file J2rva_Tyri_S2revere_id6061_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "117. Tagged file Harju_Hageri_Kohila_id10758_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "118. Tagged file Harju_Kuusalu_Kolga_id12078_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "119. Tagged file Tartu_R6ngu_Aakre_id1481_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "120. Tagged file Tartu_V6nnu_Ahja_id18899_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "121. Tagged file J2rva_J2rva-Jaani_Karinu_id940_1864a.json\n",
      "(!) Tagging Word Level NER\n",
      "122. Tagged file L22ne_Ridala_Sinalepa_id24335_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "123. Tagged file Tartu_Kodavere_Ranna_id14412_1860a.json\n",
      "(!) Tagging Word Level NER\n",
      "124. Tagged file V6ru_R2pina_R2pina_id1164_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "125. Tagged file L22ne_Pyhalepa_K2rdla_id23140_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "126. Tagged file Tartu_Torma_Avinurme_id2572_1856a.json\n",
      "(!) Tagging Word Level NER\n",
      "127. Tagged file Viru_Haljala_Vihula_id5797_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "128. Tagged file L22ne_Kullamaa_Piirsalu_id13489_1897a.json\n",
      "(!) Tagging Word Level NER\n",
      "129. Tagged file V6ru_R6uge_Saaluse_id8433_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "130. Tagged file Harju_Kose_Triigi_id9764_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "131. Tagged file Tartu_N6o_Pangodi_id4215_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "132. Tagged file Harju_Kose_Triigi_id21084_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "133. Tagged file J2rva_Tyri_Kirna_id24860_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "134. Tagged file Tartu_Maarja-Magdaleena_J6e_id13818_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "135. Tagged file L22ne_Pyhalepa_K2rdla_id24150_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "136. Tagged file J2rva_Anna_Eivere_id7480_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "137. Tagged file Tartu_Kodavere_Alatskivi_id1528_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "138. Tagged file J2rva_Tyri_S2revere_id13475_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "139. Tagged file Tartu_V6nnu_Ahja_id23496_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "140. Tagged file Tartu_N6o_Pangodi_id5301_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "141. Tagged file Tartu_Otep22_Pyhaj2rve_id7892_1885a.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Tagging Word Level NER\n",
      "142. Tagged file Tartu_Otep22_Pyhaj2rve_id6032_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "143. Tagged file Tartu_V6nnu_Ahja_id12252_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "144. Tagged file Tartu_Laiuse_Kivij2rve_id1751_1860a.json\n",
      "(!) Tagging Word Level NER\n",
      "145. Tagged file Tartu_Kodavere_Pala_id15778_1842a.json\n",
      "(!) Tagging Word Level NER\n",
      "146. Tagged file Tartu_V6nnu_Ahja_id9743_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "147. Tagged file Tartu_V6nnu_Ahja_id11995_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "148. Tagged file Harju_J6el2htme_J6el2htme_id8161_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "149. Tagged file Tartu_Torma_Avinurme_id2545_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "150. Tagged file J2rva_Tyri_S2revere_id7477_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "151. Tagged file Tartu_Laiuse_Kivij2rve_id7913_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "152. Tagged file Viljandi_K6pu_Suure-K6pu_id6432_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "153. Tagged file Saare_Kaarma_Loona_id7805_1910a.json\n",
      "(!) Tagging Word Level NER\n",
      "154. Tagged file Harju_Jyri_Rae_id5339_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "155. Tagged file Tartu_Torma_Avinurme_id22233_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "156. Tagged file Tartu_Kodavere_Alatskivi_id1786_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "157. Tagged file Saare_P8ide_Laimjala_id7014_1920a.json\n",
      "(!) Tagging Word Level NER\n",
      "158. Tagged file Harju_Kose_Kose-Uuem6isa_id10389_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "159. Tagged file Harju_Hageri_Kohila_id10427_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "160. Tagged file J2rva_Tyri_Kirna_id25452_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "161. Tagged file Harju_Juuru_Juuru_id23775_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "162. Tagged file Tartu_V6nnu_Ahja_id14121_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "163. Tagged file Tartu_Kodavere_Alatskivi_id23000_1857a.json\n",
      "(!) Tagging Word Level NER\n",
      "164. Tagged file Tartu_V6nnu_Ahja_id20995_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "165. Tagged file Tartu_V6nnu_Ahja_id13250_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "166. Tagged file L22ne_Reigi_K6rgessaare_id22876_1893a.json\n",
      "(!) Tagging Word Level NER\n",
      "167. Tagged file J2rva_Tyri_V22tsa_id16656_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "168. Tagged file Harju_Kose_Triigi_id12028_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "169. Tagged file J2rva_Tyri_Kirna_id22825_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "170. Tagged file Tartu_Kodavere_Alatskivi_id13801_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "171. Tagged file J2rva_Tyri_Kirna_id25139_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "172. Tagged file Harju_Kose_Kose-Uuem6isa_id3340_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "173. Tagged file V6ru_Vastseliina_Misso_id16574_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "174. Tagged file J2rva_Tyri_Kirna_id23402_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "175. Tagged file J2rva_Tyri_Kirna_id22809_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "176. Tagged file J2rva_Tyri_Kirna_id22602_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "177. Tagged file Tartu_Kodavere_Kokora_id627_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "178. Tagged file L22ne_Kullamaa_Kuij6e_id15513_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "179. Tagged file J2rva_Tyri_S2revere_id11688_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "180. Tagged file Tartu_V6nnu_Ahja_id11263_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "181. Tagged file J2rva_Ambla_Ambla_id7441_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "182. Tagged file Tartu_Kodavere_Pala_id18456_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "183. Tagged file L22ne_Vormsi_Vormsi_id24029_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "184. Tagged file L22ne_Emmaste_Emmaste_id17716_1897a.json\n",
      "(!) Tagging Word Level NER\n",
      "185. Tagged file Viljandi_Tarvastu_Tarvastu_id4805_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "186. Tagged file Tartu_V6nnu_Ahja_id9782_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "187. Tagged file Tartu_V6nnu_Ahja_id22382_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "188. Tagged file J2rva_Tyri_Kirna_id22903_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "189. Tagged file Harju_Kose_Kose-Uuem6isa_id4916_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "190. Tagged file Harju_Juuru_Juuru_id20528_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "191. Tagged file Tartu_V6nnu_Ahja_id13655_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "192. Tagged file Tartu_Torma_Avinurme_id20455_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "193. Tagged file L22ne_Martna_Martna_id12611_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "194. Tagged file Tartu_Maarja-Magdaleena_J6e_id15191_1864a.json\n",
      "(!) Tagging Word Level NER\n",
      "195. Tagged file P2rnu_Halliste_Pornuse_id4791_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "196. Tagged file Tartu_R6ngu_Aakre_id8042_1827a.json\n",
      "(!) Tagging Word Level NER\n",
      "197. Tagged file Tartu_V6nnu_Ahja_id13144_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "198. Tagged file Tartu_V6nnu_Ahja_id17542_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "199. Tagged file Tartu_Kodavere_Pala_id17298_1857a.json\n",
      "(!) Tagging Word Level NER\n",
      "200. Tagged file Tartu_Otep22_Pyhaj2rve_id1642_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "201. Tagged file Tartu_Kodavere_Alatskivi_id14538_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "202. Tagged file Tartu_Torma_Avinurme_id24645_1823a.json\n",
      "(!) Tagging Word Level NER\n",
      "203. Tagged file Harju_Keila_Keila_id11680_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "204. Tagged file Tartu_V6nnu_Ahja_id17059_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "205. Tagged file Harju_Hageri_Kohila_id10480_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "206. Tagged file V6ru_Kanepi_Krootuse_id24518_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "207. Tagged file Harju_Kose_Triigi_id11470_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "208. Tagged file Tartu_V6nnu_Ahja_id15395_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "209. Tagged file Tartu_V6nnu_Ahja_id15584_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "210. Tagged file Harju_J6el2htme_J6el2htme_id9507_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "211. Tagged file Tartu_V6nnu_Ahja_id12372_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "212. Tagged file Harju_Kose_Triigi_id11552_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "213. Tagged file L22ne_Kullamaa_Kuij6e_id15386_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "214. Tagged file Harju_Hageri_Kohila_id4177_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "215. Tagged file V6ru_R6uge_Saaluse_id9629_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "216. Tagged file J2rva_Tyri_S2revere_id13094_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "217. Tagged file L22ne_Kullamaa_Piirsalu_id7491_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "218. Tagged file L22ne_Pyhalepa_K2rdla_id10158_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "219. Tagged file V6ru_Vastseliina_Misso_id13577_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "220. Tagged file J2rva_Tyri_V22tsa_id22488_1913a.json\n",
      "(!) Tagging Word Level NER\n",
      "221. Tagged file Harju_Hageri_Kohila_id5465_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "222. Tagged file Tartu_V6nnu_Ahja_id21646_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "223. Tagged file J2rva_J2rva-Jaani_Einmanni_id6497_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "224. Tagged file P2rnu_T6stamaa_Kihnu_id25042_1843a.json\n",
      "(!) Tagging Word Level NER\n",
      "225. Tagged file Tartu_Maarja-Magdaleena_J6e_id10704_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "226. Tagged file Saare_Kihelkonna_Kihelkonna_id22956_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "227. Tagged file Tartu_V6nnu_Ahja_id18088_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "228. Tagged file Viljandi_K6pu_Suure-K6pu_id7185_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "229. Tagged file Tartu_V6nnu_Ahja_id15141_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "230. Tagged file Tartu_V6nnu_Ahja_id19002_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "231. Tagged file J2rva_Tyri_S2revere_id9003_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "232. Tagged file Viljandi_Paistu_Holstre_id1818_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "233. Tagged file Tartu_R6ngu_Aakre_id3580_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "234. Tagged file Harju_Kose_Palvere_id17062_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "235. Tagged file V6ru_Vastseliina_Misso_id14456_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "236. Tagged file Viljandi_P6ltsamaa_Uue-P6ltsamaa_id9345_1855a.json\n",
      "(!) Tagging Word Level NER\n",
      "237. Tagged file J2rva_Tyri_S2revere_id14667_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "238. Tagged file Tartu_V6nnu_Ahja_id19686_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "239. Tagged file J2rva_Tyri_Kirna_id23886_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "240. Tagged file V6ru_R6uge_Leevi_id24219_1875a.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Tagging Word Level NER\n",
      "241. Tagged file J2rva_Tyri_Kirna_id23286_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "242. Tagged file Tartu_V6nnu_Ahja_id19466_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "243. Tagged file J2rva_Tyri_V22tsa_id18472_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "244. Tagged file Saare_Kihelkonna_Kotlandi_id15249_1860a.json\n",
      "(!) Tagging Word Level NER\n",
      "245. Tagged file Tartu_V6nnu_Ahja_id11346_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "246. Tagged file Harju_Rapla_Rapla_id22195_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "247. Tagged file Tartu_V6nnu_Ahja_id13021_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "248. Tagged file Harju_Jyri_Rae_id268_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "249. Tagged file Tartu_Kodavere_Alatskivi_id5700_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "250. Tagged file Tartu_Torma_Avinurme_id3955_1858a.json\n",
      "(!) Files tagged\n",
      "(!) Preparing training texts\n",
      "(!) Training texts done\n",
      "(!) Training NerTagger\n",
      "(!) Warning: Location of the new \"settings.py\" is the same one as the old one. Model's settings are not copied.\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 355996\n",
      "Seconds required: 2.145\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 1000\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 31131.874327\n",
      "Trial #1 (eta = 0.100000): 3061.281455\n",
      "Trial #2 (eta = 0.200000): 4867.513870\n",
      "Trial #3 (eta = 0.400000): 9544.031699\n",
      "Trial #4 (eta = 0.800000): 22058.748585\n",
      "Trial #5 (eta = 1.600000): 40567.995190 (worse)\n",
      "Trial #6 (eta = 0.050000): 2464.755042\n",
      "Trial #7 (eta = 0.025000): 2526.259942\n",
      "Trial #8 (eta = 0.012500): 2890.603146\n",
      "Trial #9 (eta = 0.006250): 3447.104158\n",
      "Trial #10 (eta = 0.003125): 4237.651997\n",
      "Trial #11 (eta = 0.001563): 5412.154596\n",
      "Trial #12 (eta = 0.000781): 7261.513909\n",
      "Trial #13 (eta = 0.000391): 10196.215490\n",
      "Trial #14 (eta = 0.000195): 14405.446942\n",
      "Trial #15 (eta = 0.000098): 19625.442847\n",
      "Best learning rate (eta): 0.050000\n",
      "Seconds required: 0.331\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 18931.562167\n",
      "Feature L2-norm: 33.326474\n",
      "Learning rate (eta): 0.049995\n",
      "Total number of feature updates: 16181\n",
      "Seconds required for this iteration: 0.379\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 8899.266801\n",
      "Feature L2-norm: 43.710676\n",
      "Learning rate (eta): 0.049990\n",
      "Total number of feature updates: 32362\n",
      "Seconds required for this iteration: 0.383\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 6239.389955\n",
      "Feature L2-norm: 50.245123\n",
      "Learning rate (eta): 0.049985\n",
      "Total number of feature updates: 48543\n",
      "Seconds required for this iteration: 0.389\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 4572.736127\n",
      "Feature L2-norm: 55.456025\n",
      "Learning rate (eta): 0.049980\n",
      "Total number of feature updates: 64724\n",
      "Seconds required for this iteration: 0.377\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 3666.242067\n",
      "Feature L2-norm: 59.821458\n",
      "Learning rate (eta): 0.049975\n",
      "Total number of feature updates: 80905\n",
      "Seconds required for this iteration: 0.391\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 2986.517417\n",
      "Feature L2-norm: 63.515223\n",
      "Learning rate (eta): 0.049970\n",
      "Total number of feature updates: 97086\n",
      "Seconds required for this iteration: 0.374\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 2547.968452\n",
      "Feature L2-norm: 66.774274\n",
      "Learning rate (eta): 0.049965\n",
      "Total number of feature updates: 113267\n",
      "Seconds required for this iteration: 0.387\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 2217.399027\n",
      "Feature L2-norm: 69.687257\n",
      "Learning rate (eta): 0.049960\n",
      "Total number of feature updates: 129448\n",
      "Seconds required for this iteration: 0.366\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 1944.460437\n",
      "Feature L2-norm: 72.321369\n",
      "Learning rate (eta): 0.049955\n",
      "Total number of feature updates: 145629\n",
      "Seconds required for this iteration: 0.375\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 1719.705622\n",
      "Feature L2-norm: 74.663795\n",
      "Learning rate (eta): 0.049950\n",
      "Total number of feature updates: 161810\n",
      "Seconds required for this iteration: 0.386\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 1540.288651\n",
      "Improvement ratio: 11.290918\n",
      "Feature L2-norm: 76.840915\n",
      "Learning rate (eta): 0.049945\n",
      "Total number of feature updates: 177991\n",
      "Seconds required for this iteration: 0.376\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 1406.844080\n",
      "Improvement ratio: 5.325695\n",
      "Feature L2-norm: 78.816760\n",
      "Learning rate (eta): 0.049940\n",
      "Total number of feature updates: 194172\n",
      "Seconds required for this iteration: 0.359\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 1268.280150\n",
      "Improvement ratio: 3.919568\n",
      "Feature L2-norm: 80.655380\n",
      "Learning rate (eta): 0.049935\n",
      "Total number of feature updates: 210353\n",
      "Seconds required for this iteration: 0.352\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 1179.504657\n",
      "Improvement ratio: 2.876828\n",
      "Feature L2-norm: 82.383552\n",
      "Learning rate (eta): 0.049930\n",
      "Total number of feature updates: 226534\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 1101.738462\n",
      "Improvement ratio: 2.327688\n",
      "Feature L2-norm: 83.969677\n",
      "Learning rate (eta): 0.049925\n",
      "Total number of feature updates: 242715\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 1025.991265\n",
      "Improvement ratio: 1.910860\n",
      "Feature L2-norm: 85.492142\n",
      "Learning rate (eta): 0.049920\n",
      "Total number of feature updates: 258896\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 966.776145\n",
      "Improvement ratio: 1.635531\n",
      "Feature L2-norm: 86.906696\n",
      "Learning rate (eta): 0.049915\n",
      "Total number of feature updates: 275077\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 891.127605\n",
      "Improvement ratio: 1.488307\n",
      "Feature L2-norm: 88.255033\n",
      "Learning rate (eta): 0.049910\n",
      "Total number of feature updates: 291258\n",
      "Seconds required for this iteration: 0.342\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 860.105804\n",
      "Improvement ratio: 1.260722\n",
      "Feature L2-norm: 89.538014\n",
      "Learning rate (eta): 0.049905\n",
      "Total number of feature updates: 307439\n",
      "Seconds required for this iteration: 0.344\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 814.428805\n",
      "Improvement ratio: 1.111548\n",
      "Feature L2-norm: 90.758952\n",
      "Learning rate (eta): 0.049900\n",
      "Total number of feature updates: 323620\n",
      "Seconds required for this iteration: 0.363\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 764.076105\n",
      "Improvement ratio: 1.015884\n",
      "Feature L2-norm: 91.905748\n",
      "Learning rate (eta): 0.049895\n",
      "Total number of feature updates: 339801\n",
      "Seconds required for this iteration: 0.377\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 722.662063\n",
      "Improvement ratio: 0.946752\n",
      "Feature L2-norm: 92.997435\n",
      "Learning rate (eta): 0.049890\n",
      "Total number of feature updates: 355982\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 715.679016\n",
      "Improvement ratio: 0.772135\n",
      "Feature L2-norm: 94.067095\n",
      "Learning rate (eta): 0.049885\n",
      "Total number of feature updates: 372163\n",
      "Seconds required for this iteration: 0.407\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 670.106767\n",
      "Improvement ratio: 0.760174\n",
      "Feature L2-norm: 95.067317\n",
      "Learning rate (eta): 0.049880\n",
      "Total number of feature updates: 388344\n",
      "Seconds required for this iteration: 0.410\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 660.856115\n",
      "Improvement ratio: 0.667138\n",
      "Feature L2-norm: 96.064379\n",
      "Learning rate (eta): 0.049875\n",
      "Total number of feature updates: 404525\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 639.923657\n",
      "Improvement ratio: 0.603303\n",
      "Feature L2-norm: 97.020703\n",
      "Learning rate (eta): 0.049870\n",
      "Total number of feature updates: 420706\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 602.501306\n",
      "Improvement ratio: 0.604604\n",
      "Feature L2-norm: 97.912756\n",
      "Learning rate (eta): 0.049865\n",
      "Total number of feature updates: 436887\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 583.750537\n",
      "Improvement ratio: 0.526556\n",
      "Feature L2-norm: 98.774470\n",
      "Learning rate (eta): 0.049860\n",
      "Total number of feature updates: 453068\n",
      "Seconds required for this iteration: 0.347\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 558.147232\n",
      "Improvement ratio: 0.541002\n",
      "Feature L2-norm: 99.603218\n",
      "Learning rate (eta): 0.049855\n",
      "Total number of feature updates: 469249\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 548.853855\n",
      "Improvement ratio: 0.483872\n",
      "Feature L2-norm: 100.392845\n",
      "Learning rate (eta): 0.049850\n",
      "Total number of feature updates: 485430\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 525.714770\n",
      "Improvement ratio: 0.453404\n",
      "Feature L2-norm: 101.167157\n",
      "Learning rate (eta): 0.049845\n",
      "Total number of feature updates: 501611\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 528.511555\n",
      "Improvement ratio: 0.367353\n",
      "Feature L2-norm: 101.918434\n",
      "Learning rate (eta): 0.049841\n",
      "Total number of feature updates: 517792\n",
      "Seconds required for this iteration: 0.340\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #33 *****\n",
      "Loss: 498.692489\n",
      "Improvement ratio: 0.435111\n",
      "Feature L2-norm: 102.647611\n",
      "Learning rate (eta): 0.049836\n",
      "Total number of feature updates: 533973\n",
      "Seconds required for this iteration: 0.359\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 493.195181\n",
      "Improvement ratio: 0.358705\n",
      "Feature L2-norm: 103.349276\n",
      "Learning rate (eta): 0.049831\n",
      "Total number of feature updates: 550154\n",
      "Seconds required for this iteration: 0.367\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 476.446423\n",
      "Improvement ratio: 0.387052\n",
      "Feature L2-norm: 104.037330\n",
      "Learning rate (eta): 0.049826\n",
      "Total number of feature updates: 566335\n",
      "Seconds required for this iteration: 0.353\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 465.025482\n",
      "Improvement ratio: 0.376104\n",
      "Feature L2-norm: 104.699110\n",
      "Learning rate (eta): 0.049821\n",
      "Total number of feature updates: 582516\n",
      "Seconds required for this iteration: 0.352\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 446.144079\n",
      "Improvement ratio: 0.350464\n",
      "Feature L2-norm: 105.354092\n",
      "Learning rate (eta): 0.049816\n",
      "Total number of feature updates: 598697\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 446.158303\n",
      "Improvement ratio: 0.308393\n",
      "Feature L2-norm: 105.983037\n",
      "Learning rate (eta): 0.049811\n",
      "Total number of feature updates: 614878\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 432.395422\n",
      "Improvement ratio: 0.290826\n",
      "Feature L2-norm: 106.598234\n",
      "Learning rate (eta): 0.049806\n",
      "Total number of feature updates: 631059\n",
      "Seconds required for this iteration: 0.344\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 412.021190\n",
      "Improvement ratio: 0.332101\n",
      "Feature L2-norm: 107.191849\n",
      "Learning rate (eta): 0.049801\n",
      "Total number of feature updates: 647240\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 429.274528\n",
      "Improvement ratio: 0.224659\n",
      "Feature L2-norm: 107.785699\n",
      "Learning rate (eta): 0.049796\n",
      "Total number of feature updates: 663421\n",
      "Seconds required for this iteration: 0.342\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 410.896534\n",
      "Improvement ratio: 0.286240\n",
      "Feature L2-norm: 108.349183\n",
      "Learning rate (eta): 0.049791\n",
      "Total number of feature updates: 679602\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 404.288946\n",
      "Improvement ratio: 0.233505\n",
      "Feature L2-norm: 108.900494\n",
      "Learning rate (eta): 0.049786\n",
      "Total number of feature updates: 695783\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 383.398834\n",
      "Improvement ratio: 0.286376\n",
      "Feature L2-norm: 109.452780\n",
      "Learning rate (eta): 0.049781\n",
      "Total number of feature updates: 711964\n",
      "Seconds required for this iteration: 0.344\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 371.966586\n",
      "Improvement ratio: 0.280885\n",
      "Feature L2-norm: 109.985033\n",
      "Learning rate (eta): 0.049776\n",
      "Total number of feature updates: 728145\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 387.669005\n",
      "Improvement ratio: 0.199543\n",
      "Feature L2-norm: 110.514344\n",
      "Learning rate (eta): 0.049771\n",
      "Total number of feature updates: 744326\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 377.468800\n",
      "Improvement ratio: 0.181936\n",
      "Feature L2-norm: 111.022872\n",
      "Learning rate (eta): 0.049766\n",
      "Total number of feature updates: 760507\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 361.772060\n",
      "Improvement ratio: 0.233258\n",
      "Feature L2-norm: 111.526131\n",
      "Learning rate (eta): 0.049761\n",
      "Total number of feature updates: 776688\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 354.948480\n",
      "Improvement ratio: 0.218192\n",
      "Feature L2-norm: 112.010959\n",
      "Learning rate (eta): 0.049756\n",
      "Total number of feature updates: 792869\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 356.741715\n",
      "Improvement ratio: 0.154957\n",
      "Feature L2-norm: 112.501158\n",
      "Learning rate (eta): 0.049751\n",
      "Total number of feature updates: 809050\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 351.273254\n",
      "Improvement ratio: 0.222053\n",
      "Feature L2-norm: 112.966345\n",
      "Learning rate (eta): 0.049746\n",
      "Total number of feature updates: 825231\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 346.867538\n",
      "Improvement ratio: 0.184592\n",
      "Feature L2-norm: 113.419111\n",
      "Learning rate (eta): 0.049741\n",
      "Total number of feature updates: 841412\n",
      "Seconds required for this iteration: 0.344\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 346.639617\n",
      "Improvement ratio: 0.166309\n",
      "Feature L2-norm: 113.881231\n",
      "Learning rate (eta): 0.049736\n",
      "Total number of feature updates: 857593\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 336.418929\n",
      "Improvement ratio: 0.139647\n",
      "Feature L2-norm: 114.321705\n",
      "Learning rate (eta): 0.049731\n",
      "Total number of feature updates: 873774\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 312.124212\n",
      "Improvement ratio: 0.191726\n",
      "Feature L2-norm: 114.754423\n",
      "Learning rate (eta): 0.049727\n",
      "Total number of feature updates: 889955\n",
      "Seconds required for this iteration: 0.391\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 331.482140\n",
      "Improvement ratio: 0.169502\n",
      "Feature L2-norm: 115.186714\n",
      "Learning rate (eta): 0.049722\n",
      "Total number of feature updates: 906136\n",
      "Seconds required for this iteration: 0.371\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 321.875085\n",
      "Improvement ratio: 0.172718\n",
      "Feature L2-norm: 115.602824\n",
      "Learning rate (eta): 0.049717\n",
      "Total number of feature updates: 922317\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 313.791173\n",
      "Improvement ratio: 0.152907\n",
      "Feature L2-norm: 116.021175\n",
      "Learning rate (eta): 0.049712\n",
      "Total number of feature updates: 938498\n",
      "Seconds required for this iteration: 0.362\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 314.812913\n",
      "Improvement ratio: 0.127490\n",
      "Feature L2-norm: 116.433241\n",
      "Learning rate (eta): 0.049707\n",
      "Total number of feature updates: 954679\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 314.586010\n",
      "Improvement ratio: 0.134004\n",
      "Feature L2-norm: 116.827915\n",
      "Learning rate (eta): 0.049702\n",
      "Total number of feature updates: 970860\n",
      "Seconds required for this iteration: 0.357\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 311.535455\n",
      "Improvement ratio: 0.127555\n",
      "Feature L2-norm: 117.229565\n",
      "Learning rate (eta): 0.049697\n",
      "Total number of feature updates: 987041\n",
      "Seconds required for this iteration: 0.364\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 302.696087\n",
      "Improvement ratio: 0.145927\n",
      "Feature L2-norm: 117.617358\n",
      "Learning rate (eta): 0.049692\n",
      "Total number of feature updates: 1003222\n",
      "Seconds required for this iteration: 0.344\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 297.178939\n",
      "Improvement ratio: 0.166434\n",
      "Feature L2-norm: 118.000346\n",
      "Learning rate (eta): 0.049687\n",
      "Total number of feature updates: 1019403\n",
      "Seconds required for this iteration: 0.367\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 296.833405\n",
      "Improvement ratio: 0.133359\n",
      "Feature L2-norm: 118.369749\n",
      "Learning rate (eta): 0.049682\n",
      "Total number of feature updates: 1035584\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 293.475768\n",
      "Improvement ratio: 0.063543\n",
      "Feature L2-norm: 118.737266\n",
      "Learning rate (eta): 0.049677\n",
      "Total number of feature updates: 1051765\n",
      "Seconds required for this iteration: 0.354\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 278.902617\n",
      "Improvement ratio: 0.188523\n",
      "Feature L2-norm: 119.094495\n",
      "Learning rate (eta): 0.049672\n",
      "Total number of feature updates: 1067946\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 299.941412\n",
      "Improvement ratio: 0.073127\n",
      "Feature L2-norm: 119.450400\n",
      "Learning rate (eta): 0.049667\n",
      "Total number of feature updates: 1084127\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 280.781334\n",
      "Improvement ratio: 0.117564\n",
      "Feature L2-norm: 119.804433\n",
      "Learning rate (eta): 0.049662\n",
      "Total number of feature updates: 1100308\n",
      "Seconds required for this iteration: 0.354\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 271.359269\n",
      "Improvement ratio: 0.160133\n",
      "Feature L2-norm: 120.146678\n",
      "Learning rate (eta): 0.049657\n",
      "Total number of feature updates: 1116489\n",
      "Seconds required for this iteration: 0.353\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 290.154436\n",
      "Improvement ratio: 0.084202\n",
      "Feature L2-norm: 120.489243\n",
      "Learning rate (eta): 0.049652\n",
      "Total number of feature updates: 1132670\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 274.887772\n",
      "Improvement ratio: 0.133319\n",
      "Feature L2-norm: 120.827774\n",
      "Learning rate (eta): 0.049648\n",
      "Total number of feature updates: 1148851\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 274.557026\n",
      "Improvement ratio: 0.102489\n",
      "Feature L2-norm: 121.155380\n",
      "Learning rate (eta): 0.049643\n",
      "Total number of feature updates: 1165032\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 272.152143\n",
      "Improvement ratio: 0.091959\n",
      "Feature L2-norm: 121.477235\n",
      "Learning rate (eta): 0.049638\n",
      "Total number of feature updates: 1181213\n",
      "Seconds required for this iteration: 0.374\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 269.366807\n",
      "Improvement ratio: 0.101967\n",
      "Feature L2-norm: 121.797471\n",
      "Learning rate (eta): 0.049633\n",
      "Total number of feature updates: 1197394\n",
      "Seconds required for this iteration: 0.362\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 252.113014\n",
      "Improvement ratio: 0.164064\n",
      "Feature L2-norm: 122.112691\n",
      "Learning rate (eta): 0.049628\n",
      "Total number of feature updates: 1213575\n",
      "Seconds required for this iteration: 0.374\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #76 *****\n",
      "Loss: 270.065901\n",
      "Improvement ratio: 0.032721\n",
      "Feature L2-norm: 122.434944\n",
      "Learning rate (eta): 0.049623\n",
      "Total number of feature updates: 1229756\n",
      "Seconds required for this iteration: 0.359\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 264.016780\n",
      "Improvement ratio: 0.136070\n",
      "Feature L2-norm: 122.742156\n",
      "Learning rate (eta): 0.049618\n",
      "Total number of feature updates: 1245937\n",
      "Seconds required for this iteration: 0.352\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 255.522731\n",
      "Improvement ratio: 0.098851\n",
      "Feature L2-norm: 123.049045\n",
      "Learning rate (eta): 0.049613\n",
      "Total number of feature updates: 1262118\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #79 *****\n",
      "Loss: 260.173118\n",
      "Improvement ratio: 0.042995\n",
      "Feature L2-norm: 123.351780\n",
      "Learning rate (eta): 0.049608\n",
      "Total number of feature updates: 1278299\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 254.510147\n",
      "Improvement ratio: 0.140051\n",
      "Feature L2-norm: 123.648179\n",
      "Learning rate (eta): 0.049603\n",
      "Total number of feature updates: 1294480\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 239.894703\n",
      "Improvement ratio: 0.145868\n",
      "Feature L2-norm: 123.940010\n",
      "Learning rate (eta): 0.049598\n",
      "Total number of feature updates: 1310661\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 262.238524\n",
      "Improvement ratio: 0.046974\n",
      "Feature L2-norm: 124.232241\n",
      "Learning rate (eta): 0.049593\n",
      "Total number of feature updates: 1326842\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 251.532260\n",
      "Improvement ratio: 0.081977\n",
      "Feature L2-norm: 124.523948\n",
      "Learning rate (eta): 0.049588\n",
      "Total number of feature updates: 1343023\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 245.489472\n",
      "Improvement ratio: 0.097264\n",
      "Feature L2-norm: 124.817595\n",
      "Learning rate (eta): 0.049583\n",
      "Total number of feature updates: 1359204\n",
      "Seconds required for this iteration: 0.393\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 248.084885\n",
      "Improvement ratio: 0.016237\n",
      "Feature L2-norm: 125.096201\n",
      "Learning rate (eta): 0.049579\n",
      "Total number of feature updates: 1375385\n",
      "Seconds required for this iteration: 0.416\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 245.796992\n",
      "Improvement ratio: 0.098736\n",
      "Feature L2-norm: 125.369551\n",
      "Learning rate (eta): 0.049574\n",
      "Total number of feature updates: 1391566\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #87 *****\n",
      "Loss: 231.282054\n",
      "Improvement ratio: 0.141536\n",
      "Feature L2-norm: 125.639776\n",
      "Learning rate (eta): 0.049569\n",
      "Total number of feature updates: 1407747\n",
      "Seconds required for this iteration: 0.358\n",
      "\n",
      "***** Epoch #88 *****\n",
      "Loss: 248.345537\n",
      "Improvement ratio: 0.028900\n",
      "Feature L2-norm: 125.915997\n",
      "Learning rate (eta): 0.049564\n",
      "Total number of feature updates: 1423928\n",
      "Seconds required for this iteration: 0.363\n",
      "\n",
      "***** Epoch #89 *****\n",
      "Loss: 241.689880\n",
      "Improvement ratio: 0.076475\n",
      "Feature L2-norm: 126.183036\n",
      "Learning rate (eta): 0.049559\n",
      "Total number of feature updates: 1440109\n",
      "Seconds required for this iteration: 0.384\n",
      "\n",
      "***** Epoch #90 *****\n",
      "Loss: 230.789328\n",
      "Improvement ratio: 0.102781\n",
      "Feature L2-norm: 126.449566\n",
      "Learning rate (eta): 0.049554\n",
      "Total number of feature updates: 1456290\n",
      "Seconds required for this iteration: 0.374\n",
      "\n",
      "***** Epoch #91 *****\n",
      "Loss: 235.183606\n",
      "Improvement ratio: 0.020032\n",
      "Feature L2-norm: 126.714457\n",
      "Learning rate (eta): 0.049549\n",
      "Total number of feature updates: 1472471\n",
      "Seconds required for this iteration: 0.394\n",
      "\n",
      "***** Epoch #92 *****\n",
      "Loss: 235.293279\n",
      "Improvement ratio: 0.114518\n",
      "Feature L2-norm: 126.969026\n",
      "Learning rate (eta): 0.049544\n",
      "Total number of feature updates: 1488652\n",
      "Seconds required for this iteration: 0.368\n",
      "\n",
      "***** Epoch #93 *****\n",
      "Loss: 234.090296\n",
      "Improvement ratio: 0.074510\n",
      "Feature L2-norm: 127.227285\n",
      "Learning rate (eta): 0.049539\n",
      "Total number of feature updates: 1504833\n",
      "Seconds required for this iteration: 0.370\n",
      "\n",
      "***** Epoch #94 *****\n",
      "Loss: 231.015669\n",
      "Improvement ratio: 0.062653\n",
      "Feature L2-norm: 127.483239\n",
      "Learning rate (eta): 0.049534\n",
      "Total number of feature updates: 1521014\n",
      "Seconds required for this iteration: 0.356\n",
      "\n",
      "***** Epoch #95 *****\n",
      "Loss: 231.305294\n",
      "Improvement ratio: 0.072543\n",
      "Feature L2-norm: 127.731961\n",
      "Learning rate (eta): 0.049529\n",
      "Total number of feature updates: 1537195\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #96 *****\n",
      "Loss: 226.091764\n",
      "Improvement ratio: 0.087156\n",
      "Feature L2-norm: 127.979461\n",
      "Learning rate (eta): 0.049525\n",
      "Total number of feature updates: 1553376\n",
      "Seconds required for this iteration: 0.358\n",
      "\n",
      "***** Epoch #97 *****\n",
      "Loss: 224.062869\n",
      "Improvement ratio: 0.032219\n",
      "Feature L2-norm: 128.226144\n",
      "Learning rate (eta): 0.049520\n",
      "Total number of feature updates: 1569557\n",
      "Seconds required for this iteration: 0.387\n",
      "\n",
      "***** Epoch #98 *****\n",
      "Loss: 228.760306\n",
      "Improvement ratio: 0.085615\n",
      "Feature L2-norm: 128.467291\n",
      "Learning rate (eta): 0.049515\n",
      "Total number of feature updates: 1585738\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #99 *****\n",
      "Loss: 225.511042\n",
      "Improvement ratio: 0.071743\n",
      "Feature L2-norm: 128.705761\n",
      "Learning rate (eta): 0.049510\n",
      "Total number of feature updates: 1601919\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #100 *****\n",
      "Loss: 226.598142\n",
      "Improvement ratio: 0.018496\n",
      "Feature L2-norm: 128.940854\n",
      "Learning rate (eta): 0.049505\n",
      "Total number of feature updates: 1618100\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #101 *****\n",
      "Loss: 220.131605\n",
      "Improvement ratio: 0.068377\n",
      "Feature L2-norm: 129.177663\n",
      "Learning rate (eta): 0.049500\n",
      "Total number of feature updates: 1634281\n",
      "Seconds required for this iteration: 0.390\n",
      "\n",
      "***** Epoch #102 *****\n",
      "Loss: 212.485819\n",
      "Improvement ratio: 0.107336\n",
      "Feature L2-norm: 129.414839\n",
      "Learning rate (eta): 0.049495\n",
      "Total number of feature updates: 1650462\n",
      "Seconds required for this iteration: 0.359\n",
      "\n",
      "***** Epoch #103 *****\n",
      "Loss: 222.069153\n",
      "Improvement ratio: 0.054132\n",
      "Feature L2-norm: 129.650910\n",
      "Learning rate (eta): 0.049490\n",
      "Total number of feature updates: 1666643\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #104 *****\n",
      "Loss: 219.438479\n",
      "Improvement ratio: 0.052758\n",
      "Feature L2-norm: 129.877611\n",
      "Learning rate (eta): 0.049485\n",
      "Total number of feature updates: 1682824\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #105 *****\n",
      "Loss: 213.527864\n",
      "Improvement ratio: 0.083256\n",
      "Feature L2-norm: 130.106074\n",
      "Learning rate (eta): 0.049480\n",
      "Total number of feature updates: 1699005\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #106 *****\n",
      "Loss: 218.064235\n",
      "Improvement ratio: 0.036813\n",
      "Feature L2-norm: 130.327779\n",
      "Learning rate (eta): 0.049476\n",
      "Total number of feature updates: 1715186\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #107 *****\n",
      "Loss: 217.584536\n",
      "Improvement ratio: 0.029774\n",
      "Feature L2-norm: 130.547767\n",
      "Learning rate (eta): 0.049471\n",
      "Total number of feature updates: 1731367\n",
      "Seconds required for this iteration: 0.352\n",
      "\n",
      "***** Epoch #108 *****\n",
      "Loss: 218.060158\n",
      "Improvement ratio: 0.049070\n",
      "Feature L2-norm: 130.772071\n",
      "Learning rate (eta): 0.049466\n",
      "Total number of feature updates: 1747548\n",
      "Seconds required for this iteration: 0.356\n",
      "\n",
      "***** Epoch #109 *****\n",
      "Loss: 215.503646\n",
      "Improvement ratio: 0.046437\n",
      "Feature L2-norm: 130.984838\n",
      "Learning rate (eta): 0.049461\n",
      "Total number of feature updates: 1763729\n",
      "Seconds required for this iteration: 0.377\n",
      "\n",
      "***** Epoch #110 *****\n",
      "Loss: 212.709174\n",
      "Improvement ratio: 0.065296\n",
      "Feature L2-norm: 131.203034\n",
      "Learning rate (eta): 0.049456\n",
      "Total number of feature updates: 1779910\n",
      "Seconds required for this iteration: 0.376\n",
      "\n",
      "***** Epoch #111 *****\n",
      "Loss: 212.396062\n",
      "Improvement ratio: 0.036420\n",
      "Feature L2-norm: 131.417526\n",
      "Learning rate (eta): 0.049451\n",
      "Total number of feature updates: 1796091\n",
      "Seconds required for this iteration: 0.358\n",
      "\n",
      "***** Epoch #112 *****\n",
      "Loss: 211.936122\n",
      "Improvement ratio: 0.002594\n",
      "Feature L2-norm: 131.627583\n",
      "Learning rate (eta): 0.049446\n",
      "Total number of feature updates: 1812272\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #113 *****\n",
      "Loss: 196.725800\n",
      "Improvement ratio: 0.128826\n",
      "Feature L2-norm: 131.839316\n",
      "Learning rate (eta): 0.049441\n",
      "Total number of feature updates: 1828453\n",
      "Seconds required for this iteration: 0.356\n",
      "\n",
      "***** Epoch #114 *****\n",
      "Loss: 202.919224\n",
      "Improvement ratio: 0.081408\n",
      "Feature L2-norm: 132.050799\n",
      "Learning rate (eta): 0.049436\n",
      "Total number of feature updates: 1844634\n",
      "Seconds required for this iteration: 0.407\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #115 *****\n",
      "Loss: 189.208469\n",
      "Improvement ratio: 0.128532\n",
      "Feature L2-norm: 132.256787\n",
      "Learning rate (eta): 0.049432\n",
      "Total number of feature updates: 1860815\n",
      "Seconds required for this iteration: 0.378\n",
      "\n",
      "***** Epoch #116 *****\n",
      "Loss: 219.333087\n",
      "Improvement ratio: -0.005785\n",
      "Feature L2-norm: 132.462477\n",
      "Learning rate (eta): 0.049427\n",
      "Total number of feature updates: 1876996\n",
      "Seconds required for this iteration: 0.357\n",
      "\n",
      "SGD terminated with the stopping criteria\n",
      "Loss: 189.208469\n",
      "Total seconds required for training: 42.074\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 355996 (355996)\n",
      "Number of active attributes: 321742 (321742)\n",
      "Number of active labels: 11 (11)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 1.044\n",
      "\n",
      "(!) NerTagger training done\n",
      "\n",
      "(!) Tagging...\n",
      "(!) Tagging Word Level NER\n",
      "1. Tagged file P2rnu_Tori_Sindi_id20212_1838a.json\n",
      "(!) Tagging Word Level NER\n",
      "2. Tagged file Viljandi_K6pu_Suure-K6pu_id12190_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "3. Tagged file Tartu_V6nnu_Ahja_id22375_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "4. Tagged file Tartu_Torma_Avinurme_id17128_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "5. Tagged file J2rva_Tyri_S2revere_id16142_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "6. Tagged file P2rnu_Audru_V6lla_id2931_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "7. Tagged file V6ru_R2pina_R2pina_id5391_1912a.json\n",
      "(!) Tagging Word Level NER\n",
      "8. Tagged file Tartu_V6nnu_Ahja_id22887_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "9. Tagged file V6ru_Kanepi_Krootuse_id25466_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "10. Tagged file Tartu_V6nnu_Kiidj2rve_id24772_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "11. Tagged file J2rva_Tyri_S2revere_id8223_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "12. Tagged file Tartu_Laiuse_Kivij2rve_id5885_1864a.json\n",
      "(!) Tagging Word Level NER\n",
      "13. Tagged file Harju_Kose_Palvere_id25266_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "14. Tagged file Tartu_Torma_Avinurme_id6491_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "15. Tagged file Harju_Juuru_Kaiu_id9068_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "16. Tagged file L22ne_Vormsi_Vormsi_id14916_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "17. Tagged file J2rva_Tyri_Kirna_id23407_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "18. Tagged file J2rva_Peetri_V2ike-Kareda_id20027_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "19. Tagged file Tartu_Kodavere_Pala_id18165_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "20. Tagged file Tartu_V6nnu_Ahja_id14178_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "21. Tagged file Tartu_V6nnu_Ahja_id13959_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "22. Tagged file Viru_V2ike-Maarja_Porkuni_id11941_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "23. Tagged file Tartu_Kodavere_Pala_id17750_1861a.json\n",
      "(!) Tagging Word Level NER\n",
      "24. Tagged file V6ru_R2pina_R2pina_id12544_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "25. Tagged file Tartu_Kodavere_Alatskivi_id9807_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "26. Tagged file Tartu_V6nnu_Ahja_id19012_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "27. Tagged file Viljandi_K6pu_Suure-K6pu_id13155_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "28. Tagged file Saare_Kaarma_Loona_id7769_1910a.json\n",
      "(!) Tagging Word Level NER\n",
      "29. Tagged file Tartu_Kodavere_Alatskivi_id6270_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "30. Tagged file Tartu_Kursi_Puurmani_id11055_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "31. Tagged file Tartu_V6nnu_Ahja_id19102_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "32. Tagged file Viljandi_K6pu_Suure-K6pu_id3746_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "33. Tagged file Tartu_N6o_Aru_id4068_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "34. Tagged file P2rnu_Tori_Sindi_id20034_1836a.json\n",
      "(!) Tagging Word Level NER\n",
      "35. Tagged file Tartu_Kodavere_Pala_id20260_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "36. Tagged file L22ne_Vormsi_Vormsi_id24532_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "37. Tagged file Tartu_Kodavere_Pala_id25066_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "38. Tagged file Tartu_Kodavere_Ranna_id19679_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "39. Tagged file J2rva_Peetri_V2ike-Kareda_id19197_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "40. Tagged file Harju_J6el2htme_J6el2htme_id8180_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "41. Tagged file Harju_Kose_Triigi_id11473_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "42. Tagged file V6ru_R2pina_R2pina_id11101_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "43. Tagged file Saare_Kihelkonna_Kotlandi_id21849_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "44. Tagged file Tartu_V6nnu_Ahja_id20420_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "45. Tagged file Tartu_Torma_Avinurme_id22230_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "46. Tagged file Tartu_Kodavere_Pala_id18366_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "47. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id17127_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "48. Tagged file J2rva_J2rva-Jaani_Karinu_id1334_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "49. Tagged file Tartu_Torma_Avinurme_id20634_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "50. Tagged file Viljandi_Paistu_Holstre_id10302_1899a.json\n",
      "(!) Tagging Word Level NER\n",
      "51. Tagged file V6ru_P6lva_Kiuma_id7856_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "52. Tagged file L22ne_Emmaste_Emmaste_id17976_1898a.json\n",
      "(!) Tagging Word Level NER\n",
      "53. Tagged file Harju_Juuru_Juuru_id20262_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "54. Tagged file Tartu_V6nnu_Ahja_id15822_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "55. Tagged file Tartu_V6nnu_Ahja_id14975_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "56. Tagged file P2rnu_Halliste_Penuja_id701_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "57. Tagged file J2rva_Peetri_V2ike-Kareda_id19110_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "58. Tagged file J2rva_Tyri_V22tsa_id20630_1902a.json\n",
      "(!) Tagging Word Level NER\n",
      "59. Tagged file J2rva_Peetri_V2ike-Kareda_id19258_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "60. Tagged file J2rva_Tyri_S2revere_id8113_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "61. Tagged file Tartu_Kambja_Vana-Prangli_id17547_1906a.json\n",
      "(!) Tagging Word Level NER\n",
      "62. Tagged file Tartu_V6nnu_Ahja_id16450_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "63. Tagged file V6ru_R2pina_R2pina_id11883_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "64. Tagged file J2rva_J2rva-Jaani_Karinu_id1197_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "65. Tagged file Tartu_Laiuse_Kivij2rve_id11540_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "66. Tagged file Harju_Kuusalu_K6nnu_id14416_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "67. Tagged file Viljandi_P6ltsamaa_Adavere_id19020_1892a.json\n",
      "(!) Tagging Word Level NER\n",
      "68. Tagged file Tartu_Otep22_Pyhaj2rve_id3227_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "69. Tagged file Tartu_Kodavere_Pala_id17430_1859a.json\n",
      "(!) Tagging Word Level NER\n",
      "70. Tagged file Tartu_V6nnu_Ahja_id14781_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "71. Tagged file Harju_Kose_Palvere_id18876_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "72. Tagged file J2rva_Tyri_V22tsa_id18783_1897a.json\n",
      "(!) Tagging Word Level NER\n",
      "73. Tagged file Tartu_V6nnu_Ahja_id20890_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "74. Tagged file L22ne_Kullamaa_Teenuse_id3775_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "75. Tagged file Tartu_Kodavere_Pala_id22060_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "76. Tagged file Tartu_V6nnu_Ahja_id23441_1893a.json\n",
      "(!) Tagging Word Level NER\n",
      "77. Tagged file Saare_Kihelkonna_Kotlandi_id18845_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "78. Tagged file Tartu_Kodavere_Alatskivi_id12469_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "79. Tagged file L22ne_Vormsi_Vormsi_id24524_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "80. Tagged file Harju_Kose_Palvere_id20249_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "81. Tagged file Tartu_Kodavere_Pala_id18192_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "82. Tagged file Tartu_V6nnu_Ahja_id17632_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "83. Tagged file Harju_J6el2htme_J6el2htme_id6437_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "84. Tagged file V6ru_Urvaste_Urvaste_id8023_1859a.json\n",
      "(!) Tagging Word Level NER\n",
      "85. Tagged file Viljandi_Paistu_Holstre_id9107_1836a.json\n",
      "(!) Tagging Word Level NER\n",
      "86. Tagged file Tartu_V6nnu_Ahja_id21575_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "87. Tagged file Tartu_Laiuse_Kivij2rve_id5382_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "88. Tagged file Tartu_Kodavere_Alatskivi_id7573_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "89. Tagged file Tartu_Kodavere_Alatskivi_id6169_1879a.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Tagging Word Level NER\n",
      "90. Tagged file L22ne_Vormsi_Vormsi_id24526_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "91. Tagged file J2rva_Tyri_S2revere_id14656_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "92. Tagged file Tartu_Maarja-Magdaleena_J6e_id12945_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "93. Tagged file J2rva_Peetri_Silmsi_id22492_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "94. Tagged file L22ne_Pyhalepa_K2rdla_id23150_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "95. Tagged file Viljandi_K6pu_Suure-K6pu_id4473_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "96. Tagged file Tartu_Kodavere_Ranna_id15127_1864a.json\n",
      "(!) Tagging Word Level NER\n",
      "97. Tagged file Tartu_V6nnu_Ahja_id14086_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "98. Tagged file Saare_Kihelkonna_Pidula_id5682_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "99. Tagged file Tartu_Kodavere_Pala_id22067_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "100. Tagged file L22ne_Pyhalepa_K2rdla_id23206_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "101. Tagged file Tartu_N6o_Pangodi_id5083_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "102. Tagged file V6ru_R2pina_Kahkva_id14001_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "103. Tagged file Harju_Kose_Palvere_id23127_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "104. Tagged file Tartu_V6nnu_Ahja_id22345_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "105. Tagged file Tartu_N6o_Pangodi_id3054_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "106. Tagged file J2rva_Tyri_V22tsa_id22024_1912a.json\n",
      "(!) Tagging Word Level NER\n",
      "107. Tagged file Tartu_V6nnu_Ahja_id22715_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "108. Tagged file Tartu_V6nnu_Rasina_id2088_1906a.json\n",
      "(!) Tagging Word Level NER\n",
      "109. Tagged file V6ru_R6uge_Saaluse_id11045_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "110. Tagged file Harju_Rapla_Rapla_id24008_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "111. Tagged file Tartu_Kodavere_Pala_id22811_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "112. Tagged file L22ne_K2ina_Putkaste_id8765_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "113. Tagged file Saare_P8ide_Laimjala_id7049_1915a.json\n",
      "(!) Tagging Word Level NER\n",
      "114. Tagged file Tartu_V6nnu_Ahja_id18951_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "115. Tagged file Tartu_Torma_Avinurme_id21503_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "116. Tagged file Viljandi_Paistu_Holstre_id10774_1910a.json\n",
      "(!) Tagging Word Level NER\n",
      "117. Tagged file Viljandi_K6pu_Suure-K6pu_id12857_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "118. Tagged file Viru_Haljala_Vihula_id10881_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "119. Tagged file V6ru_Kanepi_Krootuse_id24412_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "120. Tagged file Tartu_V6nnu_Ahja_id20417_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "121. Tagged file Harju_Kose_Palvere_id23830_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "122. Tagged file P2rnu_Halliste_Abja_id5030_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "123. Tagged file V6ru_Vastseliina_Misso_id13326_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "124. Tagged file Saare_Kihelkonna_Atla_id7055_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "125. Tagged file J2rva_Tyri_V22tsa_id17507_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "126. Tagged file Tartu_V6nnu_Ahja_id2739_1899a.json\n",
      "(!) Tagging Word Level NER\n",
      "127. Tagged file P2rnu_Tori_Sindi_id19854_1834a.json\n",
      "(!) Tagging Word Level NER\n",
      "128. Tagged file Viru_Lyganuse_Pyssi_id8850_1904a.json\n",
      "(!) Tagging Word Level NER\n",
      "129. Tagged file Tartu_V6nnu_Ahja_id18473_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "130. Tagged file J2rva_J2rva-Jaani_Karinu_id1817_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "131. Tagged file Tartu_V6nnu_Ahja_id17455_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "132. Tagged file Viru_Iisaku_Pootsiku_id7993_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "133. Tagged file Tartu_Otep22_Pyhaj2rve_id3664_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "134. Tagged file V6ru_Vastseliina_Misso_id10864_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "135. Tagged file L22ne_Martna_Martna_id13208_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "136. Tagged file Tartu_V6nnu_Ahja_id18356_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "137. Tagged file V6ru_R6uge_Saaluse_id9637_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "138. Tagged file Tartu_Kodavere_Alatskivi_id12703_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "139. Tagged file Saare_Kihelkonna_Kotlandi_id20006_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "140. Tagged file Tartu_Kodavere_Pala_id22521_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "141. Tagged file Tartu_Kodavere_Alatskivi_id15770_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "142. Tagged file Tartu_Torma_Avinurme_id14519_1903a.json\n",
      "(!) Tagging Word Level NER\n",
      "143. Tagged file Tartu_V6nnu_Ahja_id10335_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "144. Tagged file Tartu_Kodavere_Pala_id708_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "145. Tagged file Saare_Kihelkonna_Kotlandi_id20014_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "146. Tagged file V6ru_R2pina_Kahkva_id5746_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "147. Tagged file Tartu_Kursi_Puurmani_id10088_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "148. Tagged file Tartu_Kodavere_Pala_id21385_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "149. Tagged file V6ru_Vastseliina_Misso_id22118_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "150. Tagged file Viljandi_Pilistvere_K6o_id25231_1843a.json\n",
      "(!) Tagging Word Level NER\n",
      "151. Tagged file Harju_J6el2htme_J6el2htme_id7659_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "152. Tagged file P2rnu_P2rnu-Jaagupi_Soosalu_id14278_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "153. Tagged file Harju_Hageri_Kohila_id3017_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "154. Tagged file L22ne_Kullamaa_Kuij6e_id15112_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "155. Tagged file V6ru_R2pina_R2pina_id1170_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "156. Tagged file Harju_Hageri_Kohila_id4902_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "157. Tagged file J2rva_Tyri_Kirna_id23198_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "158. Tagged file Tartu_Otep22_Pyhaj2rve_id1480_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "159. Tagged file L22ne_Kullamaa_Kuij6e_id15113_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "160. Tagged file Harju_Juuru_Kaiu_id17271_1903a.json\n",
      "(!) Tagging Word Level NER\n",
      "161. Tagged file J2rva_Tyri_S2revere_id15373_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "162. Tagged file Tartu_V6nnu_Ahja_id21776_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "163. Tagged file Tartu_V6nnu_Ahja_id14675_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "164. Tagged file Tartu_V6nnu_Ahja_id21777_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "165. Tagged file Harju_Rapla_Rapla_id17272_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "166. Tagged file Harju_Kuusalu_Kolga_id11722_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "167. Tagged file Tartu_V6nnu_Ahja_id17574_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "168. Tagged file J2rva_Tyri_Kirna_id23791_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "169. Tagged file Harju_Juuru_Kaiu_id16276_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "170. Tagged file V6ru_P6lva_Kiuma_id7579_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "171. Tagged file V6ru_R2pina_Kahkva_id8809_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "172. Tagged file Viljandi_K6pu_Suure-K6pu_id12428_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "173. Tagged file V6ru_R6uge_Saaluse_id11377_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "174. Tagged file Viljandi_K6pu_Suure-K6pu_id7202_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "175. Tagged file Viljandi_P6ltsamaa_Uue-P6ltsamaa_id11984_1856a.json\n",
      "(!) Tagging Word Level NER\n",
      "176. Tagged file Tartu_V6nnu_Ahja_id14978_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "177. Tagged file J2rva_Tyri_V22tsa_id22177_1911a.json\n",
      "(!) Tagging Word Level NER\n",
      "178. Tagged file L22ne_Kullamaa_Piirsalu_id12912_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "179. Tagged file J2rva_Tyri_V22tsa_id19055_1898a.json\n",
      "(!) Tagging Word Level NER\n",
      "180. Tagged file Harju_Kose_Palvere_id13987_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "181. Tagged file V6ru_Vastseliina_Misso_id24810_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "182. Tagged file Tartu_Torma_Avinurme_id22547_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "183. Tagged file Tartu_N6o_Pangodi_id2808_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "184. Tagged file V6ru_P6lva_Kiuma_id7167_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "185. Tagged file Tartu_V6nnu_Ahja_id14727_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "186. Tagged file Tartu_Kodavere_Alatskivi_id23068_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "187. Tagged file Tartu_Torma_Avinurme_id3646_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "188. Tagged file V6ru_Vastseliina_Misso_id11543_1886a.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Tagging Word Level NER\n",
      "189. Tagged file Tartu_V6nnu_Ahja_id22666_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "190. Tagged file Harju_J6el2htme_J6el2htme_id6475_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "191. Tagged file V6ru_R6uge_Saaluse_id11773_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "192. Tagged file L22ne_Vormsi_Vormsi_id25013_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "193. Tagged file V6ru_Urvaste_Vaabina_id785_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "194. Tagged file V6ru_R2pina_R2pina_id12011_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "195. Tagged file Tartu_V6nnu_Ahja_id20646_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "196. Tagged file Harju_Rapla_Rapla_id20938_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "197. Tagged file J2rva_Tyri_S2revere_id10443_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "198. Tagged file L22ne_Vormsi_Vormsi_id13660_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "199. Tagged file Tartu_Torma_Avinurme_id20772_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "200. Tagged file V6ru_P6lva_Kiuma_id6113_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "201. Tagged file Tartu_R6ngu_Aakre_id14648_1829a.json\n",
      "(!) Tagging Word Level NER\n",
      "202. Tagged file Tartu_V6nnu_Ahja_id18352_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "203. Tagged file L22ne_Kullamaa_Kuij6e_id15473_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "204. Tagged file Tartu_Otep22_Pyhaj2rve_id1309_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "205. Tagged file L22ne_Reigi_K6rgessaare_id23290_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "206. Tagged file J2rva_Tyri_Kirna_id23810_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "207. Tagged file Viljandi_Paistu_Holstre_id10692_1905a.json\n",
      "(!) Tagging Word Level NER\n",
      "208. Tagged file Tartu_Kodavere_Pala_id21377_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "209. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id18057_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "210. Tagged file Harju_Kose_Palvere_id18877_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "211. Tagged file Harju_Jyri_Rae_id277_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "212. Tagged file V6ru_R2pina_R2pina_id10845_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "213. Tagged file Tartu_V6nnu_Ahja_id9071_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "214. Tagged file Tartu_Kursi_Puurmani_id20904_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "215. Tagged file J2rva_Tyri_V22tsa_id22259_1913a.json\n",
      "(!) Tagging Word Level NER\n",
      "216. Tagged file J2rva_Tyri_Kirna_id23935_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "217. Tagged file J2rva_Tyri_Kirna_id24596_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "218. Tagged file J2rva_Tyri_V22tsa_id22155_1911a.json\n",
      "(!) Tagging Word Level NER\n",
      "219. Tagged file Tartu_Kodavere_Alatskivi_id15364_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "220. Tagged file Harju_J6el2htme_J6el2htme_id7651_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "221. Tagged file Tartu_Kodavere_Pala_id18894_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "222. Tagged file P2rnu_Halliste_Penuja_id810_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "223. Tagged file Tartu_V6nnu_Ahja_id17563_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "224. Tagged file Saare_Kihelkonna_Kihelkonna_id3244_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "225. Tagged file J2rva_Tyri_V22tsa_id16949_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "226. Tagged file Saare_Kaarma_Loona_id7599_1910a.json\n",
      "(!) Tagging Word Level NER\n",
      "227. Tagged file Harju_Hageri_Kohila_id3108_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "228. Tagged file Tartu_Kodavere_Pala_id18113_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "229. Tagged file Tartu_Kodavere_Alatskivi_id2944_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "230. Tagged file Viru_Haljala_Vihula_id10064_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "231. Tagged file Harju_Jyri_Rae_id280_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "232. Tagged file L22ne_Martna_Martna_id12255_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "233. Tagged file Tartu_V6nnu_Ahja_id17061_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "234. Tagged file Tartu_Laiuse_Kivij2rve_id4711_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "235. Tagged file Saare_Kaarma_Loona_id7729_1910a.json\n",
      "(!) Tagging Word Level NER\n",
      "236. Tagged file Harju_Juuru_Kaiu_id16091_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "237. Tagged file Viljandi_K6pu_Suure-K6pu_id6426_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "238. Tagged file Harju_Juuru_Kaiu_id9788_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "239. Tagged file Tartu_Kodavere_Alatskivi_id19636_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "240. Tagged file P2rnu_Halliste_Penuja_id823_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "241. Tagged file J2rva_Tyri_Kirna_id23279_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "242. Tagged file Tartu_Kodavere_Alatskivi_id13105_1856a.json\n",
      "(!) Tagging Word Level NER\n",
      "243. Tagged file Tartu_Kodavere_Ranna_id683_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "244. Tagged file J2rva_Tyri_V22tsa_id21987_1911a.json\n",
      "(!) Tagging Word Level NER\n",
      "245. Tagged file Tartu_Kodavere_Alatskivi_id1825_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "246. Tagged file Tartu_V6nnu_Ahja_id12318_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "247. Tagged file J2rva_Tyri_V22tsa_id18465_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "248. Tagged file L22ne_Martna_Martna_id14983_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "249. Tagged file Tartu_Kodavere_Alatskivi_id12991_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "250. Tagged file Harju_Kose_Palvere_id17844_1882a.json\n",
      "(!) Files tagged\n",
      "(!) Preparing training texts\n",
      "(!) Training texts done\n",
      "(!) Training NerTagger\n",
      "(!) Warning: Location of the new \"settings.py\" is the same one as the old one. Model's settings are not copied.\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 349140\n",
      "Seconds required: 2.472\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 1000\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 34452.959280\n",
      "Trial #1 (eta = 0.100000): 2671.840605\n",
      "Trial #2 (eta = 0.200000): 3993.045204\n",
      "Trial #3 (eta = 0.400000): 7853.236387\n",
      "Trial #4 (eta = 0.800000): 16273.584547\n",
      "Trial #5 (eta = 1.600000): 32509.095863\n",
      "Trial #6 (eta = 3.200000): 67477.143631 (worse)\n",
      "Trial #7 (eta = 0.050000): 2411.806001\n",
      "Trial #8 (eta = 0.025000): 2608.234594\n",
      "Trial #9 (eta = 0.012500): 3053.720760\n",
      "Trial #10 (eta = 0.006250): 3694.052131\n",
      "Trial #11 (eta = 0.003125): 4572.902577\n",
      "Trial #12 (eta = 0.001563): 5814.350765\n",
      "Trial #13 (eta = 0.000781): 7704.008349\n",
      "Trial #14 (eta = 0.000391): 10692.270290\n",
      "Trial #15 (eta = 0.000195): 15062.660141\n",
      "Trial #16 (eta = 0.000098): 20647.441719\n",
      "Best learning rate (eta): 0.050000\n",
      "Seconds required: 0.361\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 18113.132876\n",
      "Feature L2-norm: 33.356425\n",
      "Learning rate (eta): 0.049995\n",
      "Total number of feature updates: 15345\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 8117.029309\n",
      "Feature L2-norm: 42.506520\n",
      "Learning rate (eta): 0.049990\n",
      "Total number of feature updates: 30690\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 5718.802661\n",
      "Feature L2-norm: 49.153004\n",
      "Learning rate (eta): 0.049985\n",
      "Total number of feature updates: 46035\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 4232.256410\n",
      "Feature L2-norm: 54.271160\n",
      "Learning rate (eta): 0.049980\n",
      "Total number of feature updates: 61380\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 3499.377640\n",
      "Feature L2-norm: 58.697889\n",
      "Learning rate (eta): 0.049975\n",
      "Total number of feature updates: 76725\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 2813.011673\n",
      "Feature L2-norm: 62.311760\n",
      "Learning rate (eta): 0.049970\n",
      "Total number of feature updates: 92070\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 2405.092644\n",
      "Feature L2-norm: 65.530105\n",
      "Learning rate (eta): 0.049965\n",
      "Total number of feature updates: 107415\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 2052.910759\n",
      "Feature L2-norm: 68.317387\n",
      "Learning rate (eta): 0.049960\n",
      "Total number of feature updates: 122760\n",
      "Seconds required for this iteration: 0.352\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 1799.512280\n",
      "Feature L2-norm: 70.846700\n",
      "Learning rate (eta): 0.049955\n",
      "Total number of feature updates: 138105\n",
      "Seconds required for this iteration: 0.397\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 1603.367320\n",
      "Feature L2-norm: 73.120486\n",
      "Learning rate (eta): 0.049950\n",
      "Total number of feature updates: 153450\n",
      "Seconds required for this iteration: 0.369\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 1454.914292\n",
      "Improvement ratio: 11.449622\n",
      "Feature L2-norm: 75.212259\n",
      "Learning rate (eta): 0.049945\n",
      "Total number of feature updates: 168795\n",
      "Seconds required for this iteration: 0.350\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #12 *****\n",
      "Loss: 1296.589067\n",
      "Improvement ratio: 5.260294\n",
      "Feature L2-norm: 77.123105\n",
      "Learning rate (eta): 0.049940\n",
      "Total number of feature updates: 184140\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 1199.162338\n",
      "Improvement ratio: 3.768998\n",
      "Feature L2-norm: 78.894400\n",
      "Learning rate (eta): 0.049935\n",
      "Total number of feature updates: 199485\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 1112.172480\n",
      "Improvement ratio: 2.805396\n",
      "Feature L2-norm: 80.554207\n",
      "Learning rate (eta): 0.049930\n",
      "Total number of feature updates: 214830\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 1025.144642\n",
      "Improvement ratio: 2.413545\n",
      "Feature L2-norm: 82.098644\n",
      "Learning rate (eta): 0.049925\n",
      "Total number of feature updates: 230175\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 962.428341\n",
      "Improvement ratio: 1.922827\n",
      "Feature L2-norm: 83.558921\n",
      "Learning rate (eta): 0.049920\n",
      "Total number of feature updates: 245520\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 896.926020\n",
      "Improvement ratio: 1.681484\n",
      "Feature L2-norm: 84.916337\n",
      "Learning rate (eta): 0.049915\n",
      "Total number of feature updates: 260865\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 848.302172\n",
      "Improvement ratio: 1.420023\n",
      "Feature L2-norm: 86.212162\n",
      "Learning rate (eta): 0.049910\n",
      "Total number of feature updates: 276210\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 797.603276\n",
      "Improvement ratio: 1.256150\n",
      "Feature L2-norm: 87.438700\n",
      "Learning rate (eta): 0.049905\n",
      "Total number of feature updates: 291555\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 751.459424\n",
      "Improvement ratio: 1.133671\n",
      "Feature L2-norm: 88.599676\n",
      "Learning rate (eta): 0.049900\n",
      "Total number of feature updates: 306900\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 716.055093\n",
      "Improvement ratio: 1.031847\n",
      "Feature L2-norm: 89.703219\n",
      "Learning rate (eta): 0.049895\n",
      "Total number of feature updates: 322245\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 691.118829\n",
      "Improvement ratio: 0.876073\n",
      "Feature L2-norm: 90.762124\n",
      "Learning rate (eta): 0.049890\n",
      "Total number of feature updates: 337590\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 660.683644\n",
      "Improvement ratio: 0.815033\n",
      "Feature L2-norm: 91.783122\n",
      "Learning rate (eta): 0.049885\n",
      "Total number of feature updates: 352935\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 634.186402\n",
      "Improvement ratio: 0.753700\n",
      "Feature L2-norm: 92.750510\n",
      "Learning rate (eta): 0.049880\n",
      "Total number of feature updates: 368280\n",
      "Seconds required for this iteration: 0.366\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 606.792172\n",
      "Improvement ratio: 0.689449\n",
      "Feature L2-norm: 93.683095\n",
      "Learning rate (eta): 0.049875\n",
      "Total number of feature updates: 383625\n",
      "Seconds required for this iteration: 0.368\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 589.219161\n",
      "Improvement ratio: 0.633396\n",
      "Feature L2-norm: 94.576667\n",
      "Learning rate (eta): 0.049870\n",
      "Total number of feature updates: 398970\n",
      "Seconds required for this iteration: 0.405\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 565.821542\n",
      "Improvement ratio: 0.585175\n",
      "Feature L2-norm: 95.430827\n",
      "Learning rate (eta): 0.049865\n",
      "Total number of feature updates: 414315\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 545.205499\n",
      "Improvement ratio: 0.555931\n",
      "Feature L2-norm: 96.260086\n",
      "Learning rate (eta): 0.049860\n",
      "Total number of feature updates: 429660\n",
      "Seconds required for this iteration: 0.361\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 526.002700\n",
      "Improvement ratio: 0.516348\n",
      "Feature L2-norm: 97.061082\n",
      "Learning rate (eta): 0.049855\n",
      "Total number of feature updates: 445005\n",
      "Seconds required for this iteration: 0.368\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 512.737300\n",
      "Improvement ratio: 0.465584\n",
      "Feature L2-norm: 97.835223\n",
      "Learning rate (eta): 0.049850\n",
      "Total number of feature updates: 460350\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 500.511827\n",
      "Improvement ratio: 0.430646\n",
      "Feature L2-norm: 98.584318\n",
      "Learning rate (eta): 0.049845\n",
      "Total number of feature updates: 475695\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 483.931649\n",
      "Improvement ratio: 0.428133\n",
      "Feature L2-norm: 99.312889\n",
      "Learning rate (eta): 0.049841\n",
      "Total number of feature updates: 491040\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 472.176607\n",
      "Improvement ratio: 0.399230\n",
      "Feature L2-norm: 100.012645\n",
      "Learning rate (eta): 0.049836\n",
      "Total number of feature updates: 506385\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 456.717648\n",
      "Improvement ratio: 0.388574\n",
      "Feature L2-norm: 100.696880\n",
      "Learning rate (eta): 0.049831\n",
      "Total number of feature updates: 521730\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 445.854786\n",
      "Improvement ratio: 0.360964\n",
      "Feature L2-norm: 101.357624\n",
      "Learning rate (eta): 0.049826\n",
      "Total number of feature updates: 537075\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 433.372655\n",
      "Improvement ratio: 0.359613\n",
      "Feature L2-norm: 102.003087\n",
      "Learning rate (eta): 0.049821\n",
      "Total number of feature updates: 552420\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 426.323775\n",
      "Improvement ratio: 0.327211\n",
      "Feature L2-norm: 102.630520\n",
      "Learning rate (eta): 0.049816\n",
      "Total number of feature updates: 567765\n",
      "Seconds required for this iteration: 0.366\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 415.190811\n",
      "Improvement ratio: 0.313144\n",
      "Feature L2-norm: 103.238452\n",
      "Learning rate (eta): 0.049811\n",
      "Total number of feature updates: 583110\n",
      "Seconds required for this iteration: 0.384\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 405.640692\n",
      "Improvement ratio: 0.296721\n",
      "Feature L2-norm: 103.831959\n",
      "Learning rate (eta): 0.049806\n",
      "Total number of feature updates: 598455\n",
      "Seconds required for this iteration: 0.357\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 397.526231\n",
      "Improvement ratio: 0.289820\n",
      "Feature L2-norm: 104.410146\n",
      "Learning rate (eta): 0.049801\n",
      "Total number of feature updates: 613800\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 387.997822\n",
      "Improvement ratio: 0.289986\n",
      "Feature L2-norm: 104.971580\n",
      "Learning rate (eta): 0.049796\n",
      "Total number of feature updates: 629145\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 379.132954\n",
      "Improvement ratio: 0.276417\n",
      "Feature L2-norm: 105.525516\n",
      "Learning rate (eta): 0.049791\n",
      "Total number of feature updates: 644490\n",
      "Seconds required for this iteration: 0.342\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 374.493146\n",
      "Improvement ratio: 0.260842\n",
      "Feature L2-norm: 106.064525\n",
      "Learning rate (eta): 0.049786\n",
      "Total number of feature updates: 659835\n",
      "Seconds required for this iteration: 0.353\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 366.077025\n",
      "Improvement ratio: 0.247600\n",
      "Feature L2-norm: 106.589862\n",
      "Learning rate (eta): 0.049781\n",
      "Total number of feature updates: 675180\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 359.235756\n",
      "Improvement ratio: 0.241120\n",
      "Feature L2-norm: 107.104422\n",
      "Learning rate (eta): 0.049776\n",
      "Total number of feature updates: 690525\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 352.876093\n",
      "Improvement ratio: 0.228116\n",
      "Feature L2-norm: 107.610459\n",
      "Learning rate (eta): 0.049771\n",
      "Total number of feature updates: 705870\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 346.556983\n",
      "Improvement ratio: 0.230169\n",
      "Feature L2-norm: 108.103476\n",
      "Learning rate (eta): 0.049766\n",
      "Total number of feature updates: 721215\n",
      "Seconds required for this iteration: 0.370\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 340.078639\n",
      "Improvement ratio: 0.220867\n",
      "Feature L2-norm: 108.586697\n",
      "Learning rate (eta): 0.049761\n",
      "Total number of feature updates: 736560\n",
      "Seconds required for this iteration: 0.363\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 337.287945\n",
      "Improvement ratio: 0.202654\n",
      "Feature L2-norm: 109.060897\n",
      "Learning rate (eta): 0.049756\n",
      "Total number of feature updates: 751905\n",
      "Seconds required for this iteration: 0.363\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 332.646641\n",
      "Improvement ratio: 0.195041\n",
      "Feature L2-norm: 109.525118\n",
      "Learning rate (eta): 0.049751\n",
      "Total number of feature updates: 767250\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 325.865818\n",
      "Improvement ratio: 0.190667\n",
      "Feature L2-norm: 109.979793\n",
      "Learning rate (eta): 0.049746\n",
      "Total number of feature updates: 782595\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 321.427366\n",
      "Improvement ratio: 0.179529\n",
      "Feature L2-norm: 110.423375\n",
      "Learning rate (eta): 0.049741\n",
      "Total number of feature updates: 797940\n",
      "Seconds required for this iteration: 0.348\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #53 *****\n",
      "Loss: 313.388454\n",
      "Improvement ratio: 0.194981\n",
      "Feature L2-norm: 110.862044\n",
      "Learning rate (eta): 0.049736\n",
      "Total number of feature updates: 813285\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 309.131775\n",
      "Improvement ratio: 0.184210\n",
      "Feature L2-norm: 111.291069\n",
      "Learning rate (eta): 0.049731\n",
      "Total number of feature updates: 828630\n",
      "Seconds required for this iteration: 0.344\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 308.333389\n",
      "Improvement ratio: 0.165089\n",
      "Feature L2-norm: 111.712822\n",
      "Learning rate (eta): 0.049727\n",
      "Total number of feature updates: 843975\n",
      "Seconds required for this iteration: 0.346\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 302.311528\n",
      "Improvement ratio: 0.167260\n",
      "Feature L2-norm: 112.129452\n",
      "Learning rate (eta): 0.049722\n",
      "Total number of feature updates: 859320\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 296.043034\n",
      "Improvement ratio: 0.170630\n",
      "Feature L2-norm: 112.539778\n",
      "Learning rate (eta): 0.049717\n",
      "Total number of feature updates: 874665\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 297.351481\n",
      "Improvement ratio: 0.143692\n",
      "Feature L2-norm: 112.939503\n",
      "Learning rate (eta): 0.049712\n",
      "Total number of feature updates: 890010\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 288.708275\n",
      "Improvement ratio: 0.168266\n",
      "Feature L2-norm: 113.335307\n",
      "Learning rate (eta): 0.049707\n",
      "Total number of feature updates: 905355\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 287.173638\n",
      "Improvement ratio: 0.158347\n",
      "Feature L2-norm: 113.723224\n",
      "Learning rate (eta): 0.049702\n",
      "Total number of feature updates: 920700\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 282.406295\n",
      "Improvement ratio: 0.153890\n",
      "Feature L2-norm: 114.102687\n",
      "Learning rate (eta): 0.049697\n",
      "Total number of feature updates: 936045\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 278.747547\n",
      "Improvement ratio: 0.153113\n",
      "Feature L2-norm: 114.477796\n",
      "Learning rate (eta): 0.049692\n",
      "Total number of feature updates: 951390\n",
      "Seconds required for this iteration: 0.328\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 276.171824\n",
      "Improvement ratio: 0.134759\n",
      "Feature L2-norm: 114.847309\n",
      "Learning rate (eta): 0.049687\n",
      "Total number of feature updates: 966735\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 274.815956\n",
      "Improvement ratio: 0.124868\n",
      "Feature L2-norm: 115.208494\n",
      "Learning rate (eta): 0.049682\n",
      "Total number of feature updates: 982080\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 269.033392\n",
      "Improvement ratio: 0.146079\n",
      "Feature L2-norm: 115.566180\n",
      "Learning rate (eta): 0.049677\n",
      "Total number of feature updates: 997425\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 266.022968\n",
      "Improvement ratio: 0.136411\n",
      "Feature L2-norm: 115.919386\n",
      "Learning rate (eta): 0.049672\n",
      "Total number of feature updates: 1012770\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 264.139775\n",
      "Improvement ratio: 0.120782\n",
      "Feature L2-norm: 116.264939\n",
      "Learning rate (eta): 0.049667\n",
      "Total number of feature updates: 1028115\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 260.764908\n",
      "Improvement ratio: 0.140305\n",
      "Feature L2-norm: 116.607316\n",
      "Learning rate (eta): 0.049662\n",
      "Total number of feature updates: 1043460\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 257.883908\n",
      "Improvement ratio: 0.119528\n",
      "Feature L2-norm: 116.943043\n",
      "Learning rate (eta): 0.049657\n",
      "Total number of feature updates: 1058805\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 256.840304\n",
      "Improvement ratio: 0.118102\n",
      "Feature L2-norm: 117.274480\n",
      "Learning rate (eta): 0.049652\n",
      "Total number of feature updates: 1074150\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 253.048265\n",
      "Improvement ratio: 0.116018\n",
      "Feature L2-norm: 117.599371\n",
      "Learning rate (eta): 0.049648\n",
      "Total number of feature updates: 1089495\n",
      "Seconds required for this iteration: 0.372\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 250.079043\n",
      "Improvement ratio: 0.114638\n",
      "Feature L2-norm: 117.923513\n",
      "Learning rate (eta): 0.049643\n",
      "Total number of feature updates: 1104840\n",
      "Seconds required for this iteration: 0.361\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 248.260591\n",
      "Improvement ratio: 0.112427\n",
      "Feature L2-norm: 118.241143\n",
      "Learning rate (eta): 0.049638\n",
      "Total number of feature updates: 1120185\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 243.602900\n",
      "Improvement ratio: 0.128131\n",
      "Feature L2-norm: 118.557903\n",
      "Learning rate (eta): 0.049633\n",
      "Total number of feature updates: 1135530\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 245.704967\n",
      "Improvement ratio: 0.094945\n",
      "Feature L2-norm: 118.866314\n",
      "Learning rate (eta): 0.049628\n",
      "Total number of feature updates: 1150875\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #76 *****\n",
      "Loss: 242.437055\n",
      "Improvement ratio: 0.097287\n",
      "Feature L2-norm: 119.170702\n",
      "Learning rate (eta): 0.049623\n",
      "Total number of feature updates: 1166220\n",
      "Seconds required for this iteration: 0.345\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 238.089389\n",
      "Improvement ratio: 0.109414\n",
      "Feature L2-norm: 119.471805\n",
      "Learning rate (eta): 0.049618\n",
      "Total number of feature updates: 1181565\n",
      "Seconds required for this iteration: 0.347\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 235.818413\n",
      "Improvement ratio: 0.105787\n",
      "Feature L2-norm: 119.767967\n",
      "Learning rate (eta): 0.049613\n",
      "Total number of feature updates: 1196910\n",
      "Seconds required for this iteration: 0.350\n",
      "\n",
      "***** Epoch #79 *****\n",
      "Loss: 237.075301\n",
      "Improvement ratio: 0.087772\n",
      "Feature L2-norm: 120.061337\n",
      "Learning rate (eta): 0.049608\n",
      "Total number of feature updates: 1212255\n",
      "Seconds required for this iteration: 0.352\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 233.954606\n",
      "Improvement ratio: 0.097821\n",
      "Feature L2-norm: 120.350042\n",
      "Learning rate (eta): 0.049603\n",
      "Total number of feature updates: 1227600\n",
      "Seconds required for this iteration: 0.353\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 230.445397\n",
      "Improvement ratio: 0.098083\n",
      "Feature L2-norm: 120.635496\n",
      "Learning rate (eta): 0.049598\n",
      "Total number of feature updates: 1242945\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 230.414048\n",
      "Improvement ratio: 0.085346\n",
      "Feature L2-norm: 120.917586\n",
      "Learning rate (eta): 0.049593\n",
      "Total number of feature updates: 1258290\n",
      "Seconds required for this iteration: 0.356\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 227.900914\n",
      "Improvement ratio: 0.089336\n",
      "Feature L2-norm: 121.196206\n",
      "Learning rate (eta): 0.049588\n",
      "Total number of feature updates: 1273635\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 227.468373\n",
      "Improvement ratio: 0.070931\n",
      "Feature L2-norm: 121.470772\n",
      "Learning rate (eta): 0.049583\n",
      "Total number of feature updates: 1288980\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 220.043608\n",
      "Improvement ratio: 0.116619\n",
      "Feature L2-norm: 121.745255\n",
      "Learning rate (eta): 0.049579\n",
      "Total number of feature updates: 1304325\n",
      "Seconds required for this iteration: 0.348\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 220.761930\n",
      "Improvement ratio: 0.098183\n",
      "Feature L2-norm: 122.014650\n",
      "Learning rate (eta): 0.049574\n",
      "Total number of feature updates: 1319670\n",
      "Seconds required for this iteration: 0.351\n",
      "\n",
      "***** Epoch #87 *****\n",
      "Loss: 223.464335\n",
      "Improvement ratio: 0.065447\n",
      "Feature L2-norm: 122.279278\n",
      "Learning rate (eta): 0.049569\n",
      "Total number of feature updates: 1335015\n",
      "Seconds required for this iteration: 0.347\n",
      "\n",
      "***** Epoch #88 *****\n",
      "Loss: 219.346405\n",
      "Improvement ratio: 0.075096\n",
      "Feature L2-norm: 122.543316\n",
      "Learning rate (eta): 0.049564\n",
      "Total number of feature updates: 1350360\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #89 *****\n",
      "Loss: 217.420313\n",
      "Improvement ratio: 0.090401\n",
      "Feature L2-norm: 122.804393\n",
      "Learning rate (eta): 0.049559\n",
      "Total number of feature updates: 1365705\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #90 *****\n",
      "Loss: 218.312637\n",
      "Improvement ratio: 0.071649\n",
      "Feature L2-norm: 123.060250\n",
      "Learning rate (eta): 0.049554\n",
      "Total number of feature updates: 1381050\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #91 *****\n",
      "Loss: 212.800550\n",
      "Improvement ratio: 0.082917\n",
      "Feature L2-norm: 123.315651\n",
      "Learning rate (eta): 0.049549\n",
      "Total number of feature updates: 1396395\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #92 *****\n",
      "Loss: 212.088075\n",
      "Improvement ratio: 0.086407\n",
      "Feature L2-norm: 123.568498\n",
      "Learning rate (eta): 0.049544\n",
      "Total number of feature updates: 1411740\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #93 *****\n",
      "Loss: 209.450985\n",
      "Improvement ratio: 0.088087\n",
      "Feature L2-norm: 123.815595\n",
      "Learning rate (eta): 0.049539\n",
      "Total number of feature updates: 1427085\n",
      "Seconds required for this iteration: 0.333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #94 *****\n",
      "Loss: 209.603986\n",
      "Improvement ratio: 0.085229\n",
      "Feature L2-norm: 124.063361\n",
      "Learning rate (eta): 0.049534\n",
      "Total number of feature updates: 1442430\n",
      "Seconds required for this iteration: 0.369\n",
      "\n",
      "***** Epoch #95 *****\n",
      "Loss: 210.480954\n",
      "Improvement ratio: 0.045432\n",
      "Feature L2-norm: 124.305813\n",
      "Learning rate (eta): 0.049529\n",
      "Total number of feature updates: 1457775\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #96 *****\n",
      "Loss: 206.610219\n",
      "Improvement ratio: 0.068495\n",
      "Feature L2-norm: 124.547803\n",
      "Learning rate (eta): 0.049525\n",
      "Total number of feature updates: 1473120\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #97 *****\n",
      "Loss: 205.524305\n",
      "Improvement ratio: 0.087289\n",
      "Feature L2-norm: 124.784978\n",
      "Learning rate (eta): 0.049520\n",
      "Total number of feature updates: 1488465\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #98 *****\n",
      "Loss: 204.672875\n",
      "Improvement ratio: 0.071693\n",
      "Feature L2-norm: 125.019509\n",
      "Learning rate (eta): 0.049515\n",
      "Total number of feature updates: 1503810\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #99 *****\n",
      "Loss: 202.662562\n",
      "Improvement ratio: 0.072819\n",
      "Feature L2-norm: 125.253599\n",
      "Learning rate (eta): 0.049510\n",
      "Total number of feature updates: 1519155\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #100 *****\n",
      "Loss: 202.432557\n",
      "Improvement ratio: 0.078446\n",
      "Feature L2-norm: 125.483378\n",
      "Learning rate (eta): 0.049505\n",
      "Total number of feature updates: 1534500\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #101 *****\n",
      "Loss: 199.519583\n",
      "Improvement ratio: 0.066565\n",
      "Feature L2-norm: 125.713302\n",
      "Learning rate (eta): 0.049500\n",
      "Total number of feature updates: 1549845\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #102 *****\n",
      "Loss: 198.678554\n",
      "Improvement ratio: 0.067494\n",
      "Feature L2-norm: 125.939834\n",
      "Learning rate (eta): 0.049495\n",
      "Total number of feature updates: 1565190\n",
      "Seconds required for this iteration: 0.342\n",
      "\n",
      "***** Epoch #103 *****\n",
      "Loss: 199.454951\n",
      "Improvement ratio: 0.050117\n",
      "Feature L2-norm: 126.165974\n",
      "Learning rate (eta): 0.049490\n",
      "Total number of feature updates: 1580535\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #104 *****\n",
      "Loss: 198.364430\n",
      "Improvement ratio: 0.056661\n",
      "Feature L2-norm: 126.387406\n",
      "Learning rate (eta): 0.049485\n",
      "Total number of feature updates: 1595880\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #105 *****\n",
      "Loss: 193.974452\n",
      "Improvement ratio: 0.085096\n",
      "Feature L2-norm: 126.607611\n",
      "Learning rate (eta): 0.049480\n",
      "Total number of feature updates: 1611225\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #106 *****\n",
      "Loss: 193.496819\n",
      "Improvement ratio: 0.067771\n",
      "Feature L2-norm: 126.828204\n",
      "Learning rate (eta): 0.049476\n",
      "Total number of feature updates: 1626570\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #107 *****\n",
      "Loss: 193.895032\n",
      "Improvement ratio: 0.059977\n",
      "Feature L2-norm: 127.042030\n",
      "Learning rate (eta): 0.049471\n",
      "Total number of feature updates: 1641915\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #108 *****\n",
      "Loss: 192.211598\n",
      "Improvement ratio: 0.064831\n",
      "Feature L2-norm: 127.257679\n",
      "Learning rate (eta): 0.049466\n",
      "Total number of feature updates: 1657260\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #109 *****\n",
      "Loss: 191.073432\n",
      "Improvement ratio: 0.060653\n",
      "Feature L2-norm: 127.470409\n",
      "Learning rate (eta): 0.049461\n",
      "Total number of feature updates: 1672605\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #110 *****\n",
      "Loss: 188.490635\n",
      "Improvement ratio: 0.073966\n",
      "Feature L2-norm: 127.681123\n",
      "Learning rate (eta): 0.049456\n",
      "Total number of feature updates: 1687950\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #111 *****\n",
      "Loss: 189.525623\n",
      "Improvement ratio: 0.052731\n",
      "Feature L2-norm: 127.888776\n",
      "Learning rate (eta): 0.049451\n",
      "Total number of feature updates: 1703295\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #112 *****\n",
      "Loss: 187.956542\n",
      "Improvement ratio: 0.057045\n",
      "Feature L2-norm: 128.094183\n",
      "Learning rate (eta): 0.049446\n",
      "Total number of feature updates: 1718640\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #113 *****\n",
      "Loss: 189.937852\n",
      "Improvement ratio: 0.050106\n",
      "Feature L2-norm: 128.298285\n",
      "Learning rate (eta): 0.049441\n",
      "Total number of feature updates: 1733985\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #114 *****\n",
      "Loss: 186.112729\n",
      "Improvement ratio: 0.065829\n",
      "Feature L2-norm: 128.502879\n",
      "Learning rate (eta): 0.049436\n",
      "Total number of feature updates: 1749330\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #115 *****\n",
      "Loss: 185.325535\n",
      "Improvement ratio: 0.046669\n",
      "Feature L2-norm: 128.704050\n",
      "Learning rate (eta): 0.049432\n",
      "Total number of feature updates: 1764675\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #116 *****\n",
      "Loss: 184.716385\n",
      "Improvement ratio: 0.047535\n",
      "Feature L2-norm: 128.903597\n",
      "Learning rate (eta): 0.049427\n",
      "Total number of feature updates: 1780020\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #117 *****\n",
      "Loss: 182.246752\n",
      "Improvement ratio: 0.063915\n",
      "Feature L2-norm: 129.102397\n",
      "Learning rate (eta): 0.049422\n",
      "Total number of feature updates: 1795365\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #118 *****\n",
      "Loss: 183.489776\n",
      "Improvement ratio: 0.047533\n",
      "Feature L2-norm: 129.295334\n",
      "Learning rate (eta): 0.049417\n",
      "Total number of feature updates: 1810710\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #119 *****\n",
      "Loss: 181.351342\n",
      "Improvement ratio: 0.053609\n",
      "Feature L2-norm: 129.490035\n",
      "Learning rate (eta): 0.049412\n",
      "Total number of feature updates: 1826055\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #120 *****\n",
      "Loss: 177.420023\n",
      "Improvement ratio: 0.062398\n",
      "Feature L2-norm: 129.684264\n",
      "Learning rate (eta): 0.049407\n",
      "Total number of feature updates: 1841400\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #121 *****\n",
      "Loss: 179.717616\n",
      "Improvement ratio: 0.054575\n",
      "Feature L2-norm: 129.873888\n",
      "Learning rate (eta): 0.049402\n",
      "Total number of feature updates: 1856745\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #122 *****\n",
      "Loss: 181.968028\n",
      "Improvement ratio: 0.032910\n",
      "Feature L2-norm: 130.061401\n",
      "Learning rate (eta): 0.049397\n",
      "Total number of feature updates: 1872090\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #123 *****\n",
      "Loss: 176.451360\n",
      "Improvement ratio: 0.076432\n",
      "Feature L2-norm: 130.248416\n",
      "Learning rate (eta): 0.049392\n",
      "Total number of feature updates: 1887435\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #124 *****\n",
      "Loss: 180.110851\n",
      "Improvement ratio: 0.033323\n",
      "Feature L2-norm: 130.433721\n",
      "Learning rate (eta): 0.049388\n",
      "Total number of feature updates: 1902780\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #125 *****\n",
      "Loss: 175.549460\n",
      "Improvement ratio: 0.055688\n",
      "Feature L2-norm: 130.617466\n",
      "Learning rate (eta): 0.049383\n",
      "Total number of feature updates: 1918125\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #126 *****\n",
      "Loss: 177.086927\n",
      "Improvement ratio: 0.043083\n",
      "Feature L2-norm: 130.801499\n",
      "Learning rate (eta): 0.049378\n",
      "Total number of feature updates: 1933470\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #127 *****\n",
      "Loss: 176.960544\n",
      "Improvement ratio: 0.029872\n",
      "Feature L2-norm: 130.983176\n",
      "Learning rate (eta): 0.049373\n",
      "Total number of feature updates: 1948815\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #128 *****\n",
      "Loss: 175.028530\n",
      "Improvement ratio: 0.048342\n",
      "Feature L2-norm: 131.163515\n",
      "Learning rate (eta): 0.049368\n",
      "Total number of feature updates: 1964160\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #129 *****\n",
      "Loss: 176.011010\n",
      "Improvement ratio: 0.030341\n",
      "Feature L2-norm: 131.342381\n",
      "Learning rate (eta): 0.049363\n",
      "Total number of feature updates: 1979505\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #130 *****\n",
      "Loss: 174.631620\n",
      "Improvement ratio: 0.015967\n",
      "Feature L2-norm: 131.517096\n",
      "Learning rate (eta): 0.049358\n",
      "Total number of feature updates: 1994850\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #131 *****\n",
      "Loss: 172.103520\n",
      "Improvement ratio: 0.044241\n",
      "Feature L2-norm: 131.691491\n",
      "Learning rate (eta): 0.049353\n",
      "Total number of feature updates: 2010195\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #132 *****\n",
      "Loss: 175.210271\n",
      "Improvement ratio: 0.038569\n",
      "Feature L2-norm: 131.865860\n",
      "Learning rate (eta): 0.049349\n",
      "Total number of feature updates: 2025540\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #133 *****\n",
      "Loss: 169.498893\n",
      "Improvement ratio: 0.041018\n",
      "Feature L2-norm: 132.038909\n",
      "Learning rate (eta): 0.049344\n",
      "Total number of feature updates: 2040885\n",
      "Seconds required for this iteration: 0.335\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #134 *****\n",
      "Loss: 173.030619\n",
      "Improvement ratio: 0.040919\n",
      "Feature L2-norm: 132.210275\n",
      "Learning rate (eta): 0.049339\n",
      "Total number of feature updates: 2056230\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #135 *****\n",
      "Loss: 170.278876\n",
      "Improvement ratio: 0.030953\n",
      "Feature L2-norm: 132.381256\n",
      "Learning rate (eta): 0.049334\n",
      "Total number of feature updates: 2071575\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #136 *****\n",
      "Loss: 169.229278\n",
      "Improvement ratio: 0.046432\n",
      "Feature L2-norm: 132.550037\n",
      "Learning rate (eta): 0.049329\n",
      "Total number of feature updates: 2086920\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #137 *****\n",
      "Loss: 168.359135\n",
      "Improvement ratio: 0.051090\n",
      "Feature L2-norm: 132.717439\n",
      "Learning rate (eta): 0.049324\n",
      "Total number of feature updates: 2102265\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #138 *****\n",
      "Loss: 169.674593\n",
      "Improvement ratio: 0.031554\n",
      "Feature L2-norm: 132.884184\n",
      "Learning rate (eta): 0.049319\n",
      "Total number of feature updates: 2117610\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #139 *****\n",
      "Loss: 168.458650\n",
      "Improvement ratio: 0.044832\n",
      "Feature L2-norm: 133.048727\n",
      "Learning rate (eta): 0.049315\n",
      "Total number of feature updates: 2132955\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #140 *****\n",
      "Loss: 164.881639\n",
      "Improvement ratio: 0.059133\n",
      "Feature L2-norm: 133.213822\n",
      "Learning rate (eta): 0.049310\n",
      "Total number of feature updates: 2148300\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #141 *****\n",
      "Loss: 165.740144\n",
      "Improvement ratio: 0.038394\n",
      "Feature L2-norm: 133.377204\n",
      "Learning rate (eta): 0.049305\n",
      "Total number of feature updates: 2163645\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #142 *****\n",
      "Loss: 166.610353\n",
      "Improvement ratio: 0.051617\n",
      "Feature L2-norm: 133.539059\n",
      "Learning rate (eta): 0.049300\n",
      "Total number of feature updates: 2178990\n",
      "Seconds required for this iteration: 0.339\n",
      "\n",
      "***** Epoch #143 *****\n",
      "Loss: 166.535510\n",
      "Improvement ratio: 0.017794\n",
      "Feature L2-norm: 133.698689\n",
      "Learning rate (eta): 0.049295\n",
      "Total number of feature updates: 2194335\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #144 *****\n",
      "Loss: 164.097586\n",
      "Improvement ratio: 0.054437\n",
      "Feature L2-norm: 133.858569\n",
      "Learning rate (eta): 0.049290\n",
      "Total number of feature updates: 2209680\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #145 *****\n",
      "Loss: 165.508745\n",
      "Improvement ratio: 0.028821\n",
      "Feature L2-norm: 134.017552\n",
      "Learning rate (eta): 0.049285\n",
      "Total number of feature updates: 2225025\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #146 *****\n",
      "Loss: 164.517720\n",
      "Improvement ratio: 0.028639\n",
      "Feature L2-norm: 134.174685\n",
      "Learning rate (eta): 0.049281\n",
      "Total number of feature updates: 2240370\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #147 *****\n",
      "Loss: 161.992812\n",
      "Improvement ratio: 0.039300\n",
      "Feature L2-norm: 134.331643\n",
      "Learning rate (eta): 0.049276\n",
      "Total number of feature updates: 2255715\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #148 *****\n",
      "Loss: 161.893997\n",
      "Improvement ratio: 0.048060\n",
      "Feature L2-norm: 134.486549\n",
      "Learning rate (eta): 0.049271\n",
      "Total number of feature updates: 2271060\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #149 *****\n",
      "Loss: 163.308659\n",
      "Improvement ratio: 0.031535\n",
      "Feature L2-norm: 134.640173\n",
      "Learning rate (eta): 0.049266\n",
      "Total number of feature updates: 2286405\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #150 *****\n",
      "Loss: 158.154665\n",
      "Improvement ratio: 0.042534\n",
      "Feature L2-norm: 134.793592\n",
      "Learning rate (eta): 0.049261\n",
      "Total number of feature updates: 2301750\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #151 *****\n",
      "Loss: 161.099115\n",
      "Improvement ratio: 0.028809\n",
      "Feature L2-norm: 134.943568\n",
      "Learning rate (eta): 0.049256\n",
      "Total number of feature updates: 2317095\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #152 *****\n",
      "Loss: 162.054868\n",
      "Improvement ratio: 0.028111\n",
      "Feature L2-norm: 135.093349\n",
      "Learning rate (eta): 0.049251\n",
      "Total number of feature updates: 2332440\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #153 *****\n",
      "Loss: 157.299729\n",
      "Improvement ratio: 0.058715\n",
      "Feature L2-norm: 135.246247\n",
      "Learning rate (eta): 0.049247\n",
      "Total number of feature updates: 2347785\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #154 *****\n",
      "Loss: 159.830516\n",
      "Improvement ratio: 0.026697\n",
      "Feature L2-norm: 135.394154\n",
      "Learning rate (eta): 0.049242\n",
      "Total number of feature updates: 2363130\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #155 *****\n",
      "Loss: 158.867758\n",
      "Improvement ratio: 0.041802\n",
      "Feature L2-norm: 135.541689\n",
      "Learning rate (eta): 0.049237\n",
      "Total number of feature updates: 2378475\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #156 *****\n",
      "Loss: 157.302799\n",
      "Improvement ratio: 0.045866\n",
      "Feature L2-norm: 135.689565\n",
      "Learning rate (eta): 0.049232\n",
      "Total number of feature updates: 2393820\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #157 *****\n",
      "Loss: 158.567500\n",
      "Improvement ratio: 0.021602\n",
      "Feature L2-norm: 135.835898\n",
      "Learning rate (eta): 0.049227\n",
      "Total number of feature updates: 2409165\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #158 *****\n",
      "Loss: 157.561743\n",
      "Improvement ratio: 0.027496\n",
      "Feature L2-norm: 135.981179\n",
      "Learning rate (eta): 0.049222\n",
      "Total number of feature updates: 2424510\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #159 *****\n",
      "Loss: 156.775508\n",
      "Improvement ratio: 0.041672\n",
      "Feature L2-norm: 136.125082\n",
      "Learning rate (eta): 0.049217\n",
      "Total number of feature updates: 2439855\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #160 *****\n",
      "Loss: 153.992624\n",
      "Improvement ratio: 0.027028\n",
      "Feature L2-norm: 136.268694\n",
      "Learning rate (eta): 0.049213\n",
      "Total number of feature updates: 2455200\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #161 *****\n",
      "Loss: 154.848082\n",
      "Improvement ratio: 0.040369\n",
      "Feature L2-norm: 136.412611\n",
      "Learning rate (eta): 0.049208\n",
      "Total number of feature updates: 2470545\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #162 *****\n",
      "Loss: 156.108398\n",
      "Improvement ratio: 0.038092\n",
      "Feature L2-norm: 136.552747\n",
      "Learning rate (eta): 0.049203\n",
      "Total number of feature updates: 2485890\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #163 *****\n",
      "Loss: 155.877094\n",
      "Improvement ratio: 0.009127\n",
      "Feature L2-norm: 136.692739\n",
      "Learning rate (eta): 0.049198\n",
      "Total number of feature updates: 2501235\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #164 *****\n",
      "Loss: 154.641373\n",
      "Improvement ratio: 0.033556\n",
      "Feature L2-norm: 136.833411\n",
      "Learning rate (eta): 0.049193\n",
      "Total number of feature updates: 2516580\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #165 *****\n",
      "Loss: 153.279521\n",
      "Improvement ratio: 0.036458\n",
      "Feature L2-norm: 136.972377\n",
      "Learning rate (eta): 0.049188\n",
      "Total number of feature updates: 2531925\n",
      "Seconds required for this iteration: 0.342\n",
      "\n",
      "***** Epoch #166 *****\n",
      "Loss: 152.530549\n",
      "Improvement ratio: 0.031287\n",
      "Feature L2-norm: 137.110867\n",
      "Learning rate (eta): 0.049184\n",
      "Total number of feature updates: 2547270\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #167 *****\n",
      "Loss: 153.022830\n",
      "Improvement ratio: 0.036234\n",
      "Feature L2-norm: 137.247220\n",
      "Learning rate (eta): 0.049179\n",
      "Total number of feature updates: 2562615\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #168 *****\n",
      "Loss: 151.095876\n",
      "Improvement ratio: 0.042793\n",
      "Feature L2-norm: 137.384185\n",
      "Learning rate (eta): 0.049174\n",
      "Total number of feature updates: 2577960\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #169 *****\n",
      "Loss: 153.659996\n",
      "Improvement ratio: 0.020275\n",
      "Feature L2-norm: 137.519095\n",
      "Learning rate (eta): 0.049169\n",
      "Total number of feature updates: 2593305\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #170 *****\n",
      "Loss: 150.781103\n",
      "Improvement ratio: 0.021299\n",
      "Feature L2-norm: 137.655051\n",
      "Learning rate (eta): 0.049164\n",
      "Total number of feature updates: 2608650\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #171 *****\n",
      "Loss: 153.631655\n",
      "Improvement ratio: 0.007918\n",
      "Feature L2-norm: 137.787151\n",
      "Learning rate (eta): 0.049159\n",
      "Total number of feature updates: 2623995\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #172 *****\n",
      "Loss: 151.376769\n",
      "Improvement ratio: 0.031257\n",
      "Feature L2-norm: 137.920557\n",
      "Learning rate (eta): 0.049155\n",
      "Total number of feature updates: 2639340\n",
      "Seconds required for this iteration: 0.337\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #173 *****\n",
      "Loss: 149.327476\n",
      "Improvement ratio: 0.043861\n",
      "Feature L2-norm: 138.053787\n",
      "Learning rate (eta): 0.049150\n",
      "Total number of feature updates: 2654685\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #174 *****\n",
      "Loss: 152.346429\n",
      "Improvement ratio: 0.015064\n",
      "Feature L2-norm: 138.183683\n",
      "Learning rate (eta): 0.049145\n",
      "Total number of feature updates: 2670030\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #175 *****\n",
      "Loss: 150.211894\n",
      "Improvement ratio: 0.020422\n",
      "Feature L2-norm: 138.314473\n",
      "Learning rate (eta): 0.049140\n",
      "Total number of feature updates: 2685375\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #176 *****\n",
      "Loss: 147.933119\n",
      "Improvement ratio: 0.031078\n",
      "Feature L2-norm: 138.443279\n",
      "Learning rate (eta): 0.049135\n",
      "Total number of feature updates: 2700720\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #177 *****\n",
      "Loss: 150.763254\n",
      "Improvement ratio: 0.014988\n",
      "Feature L2-norm: 138.571279\n",
      "Learning rate (eta): 0.049130\n",
      "Total number of feature updates: 2716065\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #178 *****\n",
      "Loss: 147.967675\n",
      "Improvement ratio: 0.021141\n",
      "Feature L2-norm: 138.699590\n",
      "Learning rate (eta): 0.049126\n",
      "Total number of feature updates: 2731410\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #179 *****\n",
      "Loss: 149.804783\n",
      "Improvement ratio: 0.025735\n",
      "Feature L2-norm: 138.827707\n",
      "Learning rate (eta): 0.049121\n",
      "Total number of feature updates: 2746755\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #180 *****\n",
      "Loss: 149.669255\n",
      "Improvement ratio: 0.007429\n",
      "Feature L2-norm: 138.953653\n",
      "Learning rate (eta): 0.049116\n",
      "Total number of feature updates: 2762100\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #181 *****\n",
      "Loss: 149.382382\n",
      "Improvement ratio: 0.028446\n",
      "Feature L2-norm: 139.079105\n",
      "Learning rate (eta): 0.049111\n",
      "Total number of feature updates: 2777445\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #182 *****\n",
      "Loss: 149.149299\n",
      "Improvement ratio: 0.014934\n",
      "Feature L2-norm: 139.205026\n",
      "Learning rate (eta): 0.049106\n",
      "Total number of feature updates: 2792790\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #183 *****\n",
      "Loss: 144.949439\n",
      "Improvement ratio: 0.030204\n",
      "Feature L2-norm: 139.330524\n",
      "Learning rate (eta): 0.049101\n",
      "Total number of feature updates: 2808135\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #184 *****\n",
      "Loss: 146.348363\n",
      "Improvement ratio: 0.040985\n",
      "Feature L2-norm: 139.454546\n",
      "Learning rate (eta): 0.049097\n",
      "Total number of feature updates: 2823480\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #185 *****\n",
      "Loss: 145.518978\n",
      "Improvement ratio: 0.032250\n",
      "Feature L2-norm: 139.577297\n",
      "Learning rate (eta): 0.049092\n",
      "Total number of feature updates: 2838825\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #186 *****\n",
      "Loss: 147.160209\n",
      "Improvement ratio: 0.005252\n",
      "Feature L2-norm: 139.699113\n",
      "Learning rate (eta): 0.049087\n",
      "Total number of feature updates: 2854170\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #187 *****\n",
      "Loss: 143.089202\n",
      "Improvement ratio: 0.053631\n",
      "Feature L2-norm: 139.823320\n",
      "Learning rate (eta): 0.049082\n",
      "Total number of feature updates: 2869515\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #188 *****\n",
      "Loss: 146.515607\n",
      "Improvement ratio: 0.009911\n",
      "Feature L2-norm: 139.943782\n",
      "Learning rate (eta): 0.049077\n",
      "Total number of feature updates: 2884860\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #189 *****\n",
      "Loss: 144.478401\n",
      "Improvement ratio: 0.036866\n",
      "Feature L2-norm: 140.064881\n",
      "Learning rate (eta): 0.049073\n",
      "Total number of feature updates: 2900205\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #190 *****\n",
      "Loss: 144.977078\n",
      "Improvement ratio: 0.032365\n",
      "Feature L2-norm: 140.185122\n",
      "Learning rate (eta): 0.049068\n",
      "Total number of feature updates: 2915550\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #191 *****\n",
      "Loss: 144.819308\n",
      "Improvement ratio: 0.031509\n",
      "Feature L2-norm: 140.302510\n",
      "Learning rate (eta): 0.049063\n",
      "Total number of feature updates: 2930895\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #192 *****\n",
      "Loss: 147.101387\n",
      "Improvement ratio: 0.013922\n",
      "Feature L2-norm: 140.420143\n",
      "Learning rate (eta): 0.049058\n",
      "Total number of feature updates: 2946240\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #193 *****\n",
      "Loss: 144.467150\n",
      "Improvement ratio: 0.003338\n",
      "Feature L2-norm: 140.538384\n",
      "Learning rate (eta): 0.049053\n",
      "Total number of feature updates: 2961585\n",
      "Seconds required for this iteration: 0.369\n",
      "\n",
      "***** Epoch #194 *****\n",
      "Loss: 141.918455\n",
      "Improvement ratio: 0.031214\n",
      "Feature L2-norm: 140.656142\n",
      "Learning rate (eta): 0.049048\n",
      "Total number of feature updates: 2976930\n",
      "Seconds required for this iteration: 0.355\n",
      "\n",
      "***** Epoch #195 *****\n",
      "Loss: 143.773929\n",
      "Improvement ratio: 0.012137\n",
      "Feature L2-norm: 140.774220\n",
      "Learning rate (eta): 0.049044\n",
      "Total number of feature updates: 2992275\n",
      "Seconds required for this iteration: 0.341\n",
      "\n",
      "***** Epoch #196 *****\n",
      "Loss: 142.378174\n",
      "Improvement ratio: 0.033587\n",
      "Feature L2-norm: 140.891160\n",
      "Learning rate (eta): 0.049039\n",
      "Total number of feature updates: 3007620\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #197 *****\n",
      "Loss: 141.413859\n",
      "Improvement ratio: 0.011847\n",
      "Feature L2-norm: 141.006884\n",
      "Learning rate (eta): 0.049034\n",
      "Total number of feature updates: 3022965\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #198 *****\n",
      "Loss: 143.552648\n",
      "Improvement ratio: 0.020640\n",
      "Feature L2-norm: 141.121005\n",
      "Learning rate (eta): 0.049029\n",
      "Total number of feature updates: 3038310\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #199 *****\n",
      "Loss: 143.254899\n",
      "Improvement ratio: 0.008541\n",
      "Feature L2-norm: 141.234994\n",
      "Learning rate (eta): 0.049024\n",
      "Total number of feature updates: 3053655\n",
      "Seconds required for this iteration: 0.360\n",
      "\n",
      "***** Epoch #200 *****\n",
      "Loss: 144.050301\n",
      "Improvement ratio: 0.006434\n",
      "Feature L2-norm: 141.347459\n",
      "Learning rate (eta): 0.049020\n",
      "Total number of feature updates: 3069000\n",
      "Seconds required for this iteration: 0.373\n",
      "\n",
      "***** Epoch #201 *****\n",
      "Loss: 138.990358\n",
      "Improvement ratio: 0.041938\n",
      "Feature L2-norm: 141.460190\n",
      "Learning rate (eta): 0.049015\n",
      "Total number of feature updates: 3084345\n",
      "Seconds required for this iteration: 0.367\n",
      "\n",
      "***** Epoch #202 *****\n",
      "Loss: 142.192802\n",
      "Improvement ratio: 0.034521\n",
      "Feature L2-norm: 141.571724\n",
      "Learning rate (eta): 0.049010\n",
      "Total number of feature updates: 3099690\n",
      "Seconds required for this iteration: 0.412\n",
      "\n",
      "***** Epoch #203 *****\n",
      "Loss: 141.391442\n",
      "Improvement ratio: 0.021753\n",
      "Feature L2-norm: 141.683406\n",
      "Learning rate (eta): 0.049005\n",
      "Total number of feature updates: 3115035\n",
      "Seconds required for this iteration: 0.501\n",
      "\n",
      "***** Epoch #204 *****\n",
      "Loss: 141.454159\n",
      "Improvement ratio: 0.003282\n",
      "Feature L2-norm: 141.794145\n",
      "Learning rate (eta): 0.049000\n",
      "Total number of feature updates: 3130380\n",
      "Seconds required for this iteration: 0.635\n",
      "\n",
      "***** Epoch #205 *****\n",
      "Loss: 140.557546\n",
      "Improvement ratio: 0.022883\n",
      "Feature L2-norm: 141.903996\n",
      "Learning rate (eta): 0.048996\n",
      "Total number of feature updates: 3145725\n",
      "Seconds required for this iteration: 0.467\n",
      "\n",
      "***** Epoch #206 *****\n",
      "Loss: 140.889752\n",
      "Improvement ratio: 0.010564\n",
      "Feature L2-norm: 142.014414\n",
      "Learning rate (eta): 0.048991\n",
      "Total number of feature updates: 3161070\n",
      "Seconds required for this iteration: 0.496\n",
      "\n",
      "***** Epoch #207 *****\n",
      "Loss: 137.906540\n",
      "Improvement ratio: 0.025433\n",
      "Feature L2-norm: 142.126411\n",
      "Learning rate (eta): 0.048986\n",
      "Total number of feature updates: 3176415\n",
      "Seconds required for this iteration: 0.538\n",
      "\n",
      "***** Epoch #208 *****\n",
      "Loss: 139.003389\n",
      "Improvement ratio: 0.032728\n",
      "Feature L2-norm: 142.235220\n",
      "Learning rate (eta): 0.048981\n",
      "Total number of feature updates: 3191760\n",
      "Seconds required for this iteration: 0.511\n",
      "\n",
      "***** Epoch #209 *****\n",
      "Loss: 138.555096\n",
      "Improvement ratio: 0.033920\n",
      "Feature L2-norm: 142.342727\n",
      "Learning rate (eta): 0.048976\n",
      "Total number of feature updates: 3207105\n",
      "Seconds required for this iteration: 0.447\n",
      "\n",
      "***** Epoch #210 *****\n",
      "Loss: 139.319350\n",
      "Improvement ratio: 0.033958\n",
      "Feature L2-norm: 142.449588\n",
      "Learning rate (eta): 0.048972\n",
      "Total number of feature updates: 3222450\n",
      "Seconds required for this iteration: 0.398\n",
      "\n",
      "***** Epoch #211 *****\n",
      "Loss: 141.373254\n",
      "Improvement ratio: -0.016855\n",
      "Feature L2-norm: 142.557695\n",
      "Learning rate (eta): 0.048967\n",
      "Total number of feature updates: 3237795\n",
      "Seconds required for this iteration: 0.353\n",
      "\n",
      "SGD terminated with the stopping criteria\n",
      "Loss: 137.906540\n",
      "Total seconds required for training: 73.521\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 349140 (349140)\n",
      "Number of active attributes: 315973 (315973)\n",
      "Number of active labels: 11 (11)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 1.007\n",
      "\n",
      "(!) NerTagger training done\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Tagging...\n",
      "(!) Tagging Word Level NER\n",
      "1. Tagged file Tartu_Kodavere_Kokora_id1325_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "2. Tagged file J2rva_Tyri_V22tsa_id22266_1913a.json\n",
      "(!) Tagging Word Level NER\n",
      "3. Tagged file L22ne_Martna_Martna_id18100_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "4. Tagged file Tartu_V6nnu_Ahja_id16620_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "5. Tagged file V6ru_R2pina_R2pina_id12080_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "6. Tagged file P2rnu_Halliste_Pornuse_id3474_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "7. Tagged file Viljandi_Viljandi_Karula_id19401_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "8. Tagged file J2rva_Tyri_V22tsa_id17427_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "9. Tagged file Harju_Kose_Kose-Uuem6isa_id3144_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "10. Tagged file Tartu_V6nnu_Ahja_id16098_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "11. Tagged file V6ru_Vastseliina_Misso_id21127_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "12. Tagged file Tartu_Otep22_Pyhaj2rve_id1280_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "13. Tagged file Saare_Kihelkonna_Lymanda_id8401_1834a.json\n",
      "(!) Tagging Word Level NER\n",
      "14. Tagged file V6ru_R2pina_Kahkva_id10870_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "15. Tagged file L22ne_Kullamaa_Piirsalu_id14393_1908a.json\n",
      "(!) Tagging Word Level NER\n",
      "16. Tagged file Tartu_V6nnu_Ahja_id9602_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "17. Tagged file Tartu_V6nnu_Ahja_id13567_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "18. Tagged file Tartu_Kodavere_Alatskivi_id22106_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "19. Tagged file L22ne_Martna_Martna_id12249_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "20. Tagged file Harju_Hageri_Kohila_id1346_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "21. Tagged file Viljandi_P6ltsamaa_Uue-P6ltsamaa_id12394_1856a.json\n",
      "(!) Tagging Word Level NER\n",
      "22. Tagged file Harju_Hageri_Kohila_id5466_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "23. Tagged file Harju_Kose_Kose-Uuem6isa_id1725_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "24. Tagged file Tartu_Torma_Avinurme_id23583_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "25. Tagged file J2rva_Tyri_V22tsa_id17884_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "26. Tagged file J2rva_Tyri_S2revere_id16082_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "27. Tagged file V6ru_Vastseliina_Misso_id17348_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "28. Tagged file P2rnu_Audru_V6lla_id6632_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "29. Tagged file P2rnu_Audru_V6lla_id5372_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "30. Tagged file Tartu_V6nnu_Ahja_id18232_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "31. Tagged file Tartu_R6ngu_Aakre_id1698_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "32. Tagged file Tartu_V6nnu_Ahja_id20833_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "33. Tagged file Tartu_V6nnu_Kiidj2rve_id25082_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "34. Tagged file Tartu_V6nnu_Ahja_id16983_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "35. Tagged file Tartu_Otep22_Pyhaj2rve_id5239_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "36. Tagged file Tartu_Kodavere_Alatskivi_id14509_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "37. Tagged file Tartu_V6nnu_Ahja_id17201_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "38. Tagged file J2rva_Ambla_Ambla_id6188_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "39. Tagged file J2rva_Ambla_Ambla_id6411_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "40. Tagged file Viljandi_P6ltsamaa_Adavere_id22490_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "41. Tagged file L22ne_Kullamaa_Piirsalu_id14765_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "42. Tagged file V6ru_R2pina_R2pina_id1978_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "43. Tagged file L22ne_Kullamaa_Piirsalu_id7490_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "44. Tagged file Viljandi_Paistu_Holstre_id6601_1827a.json\n",
      "(!) Tagging Word Level NER\n",
      "45. Tagged file L22ne_Kullamaa_Sooniste_id3738_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "46. Tagged file L22ne_Emmaste_Emmaste_id15405_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "47. Tagged file J2rva_Peetri_V2ike-Kareda_id21174_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "48. Tagged file Harju_Hageri_Kohila_id11667_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "49. Tagged file Harju_Juuru_Juuru_id14480_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "50. Tagged file L22ne_Kullamaa_K22nda_id18344_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "51. Tagged file Harju_Hageri_Kohila_id24217_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "52. Tagged file Tartu_V6nnu_Ahja_id17527_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "53. Tagged file P2rnu_Tori_Sindi_id11974_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "54. Tagged file Viljandi_P6ltsamaa_Adavere_id17828_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "55. Tagged file Tartu_Kodavere_Alatskivi_id14506_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "56. Tagged file Harju_Juuru_Juuru_id19472_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "57. Tagged file Harju_Kose_Palvere_id18184_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "58. Tagged file Tartu_Laiuse_Kivij2rve_id4917_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "59. Tagged file J2rva_Peetri_V2ike-Kareda_id21217_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "60. Tagged file J2rva_Tyri_S2revere_id14565_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "61. Tagged file V6ru_R2pina_R2pina_id10635_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "62. Tagged file Tartu_Kodavere_Alatskivi_id14511_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "63. Tagged file Tartu_Kodavere_Pala_id22058_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "64. Tagged file V6ru_Kanepi_Krootuse_id25390_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "65. Tagged file Tartu_V6nnu_Ahja_id14012_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "66. Tagged file Tartu_Kodavere_Alatskivi_id22167_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "67. Tagged file Tartu_Kodavere_Pala_id22543_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "68. Tagged file Viljandi_Paistu_Holstre_id9042_1836a.json\n",
      "(!) Tagging Word Level NER\n",
      "69. Tagged file Tartu_Kodavere_Pala_id20291_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "70. Tagged file Viljandi_P6ltsamaa_Adavere_id20855_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "71. Tagged file V6ru_R2pina_Kahkva_id5748_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "72. Tagged file Harju_Hageri_Kohila_id10684_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "73. Tagged file Tartu_N6o_Pangodi_id3130_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "74. Tagged file V6ru_R6uge_Saaluse_id9066_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "75. Tagged file Tartu_N6o_Aru_id4639_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "76. Tagged file Tartu_R6ngu_Aakre_id12559_1827a.json\n",
      "(!) Tagging Word Level NER\n",
      "77. Tagged file J2rva_Tyri_Kirna_id24586_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "78. Tagged file Tartu_V6nnu_Ahja_id23443_1893a.json\n",
      "(!) Tagging Word Level NER\n",
      "79. Tagged file Tartu_V6nnu_Ahja_id21672_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "80. Tagged file L22ne_Kullamaa_Piirsalu_id6018_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "81. Tagged file Tartu_R6ngu_Aakre_id6652_1826a.json\n",
      "(!) Tagging Word Level NER\n",
      "82. Tagged file J2rva_Tyri_S2revere_id13469_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "83. Tagged file Tartu_Rannu_Valguta_id15519_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "84. Tagged file Harju_Juuru_Juuru_id18980_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "85. Tagged file V6ru_P6lva_Kiuma_id6861_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "86. Tagged file V6ru_R2pina_R2pina_id9282_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "87. Tagged file Tartu_V6nnu_Ahja_id12119_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "88. Tagged file Tartu_Maarja-Magdaleena_J6e_id13745_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "89. Tagged file Harju_Juuru_Kaiu_id962_1912a.json\n",
      "(!) Tagging Word Level NER\n",
      "90. Tagged file Viljandi_Paistu_Holstre_id7105_1829a.json\n",
      "(!) Tagging Word Level NER\n",
      "91. Tagged file L22ne_Emmaste_Emmaste_id17806_1898a.json\n",
      "(!) Tagging Word Level NER\n",
      "92. Tagged file V6ru_R2pina_R2pina_id1194_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "93. Tagged file L22ne_Martna_Martna_id12495_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "94. Tagged file Tartu_Kodavere_Alatskivi_id13487_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "95. Tagged file L22ne_Emmaste_Emmaste_id15415_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "96. Tagged file Saare_Kihelkonna_Loona_id5138_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "97. Tagged file Viljandi_P6ltsamaa_Pajusi_id5261_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "98. Tagged file L22ne_Martna_Martna_id12491_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "99. Tagged file Harju_Kose_Triigi_id12117_1871a.json\n",
      "(!) Tagging Word Level NER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100. Tagged file L22ne_Pyhalepa_K2rdla_id23208_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "101. Tagged file Tartu_V6nnu_Ahja_id17090_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "102. Tagged file Harju_Kose_Palvere_id18191_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "103. Tagged file J2rva_J2rva-Jaani_Karinu_id1193_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "104. Tagged file V6ru_Kanepi_Krootuse_id16254_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "105. Tagged file Tartu_V6nnu_Ahja_id14796_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "106. Tagged file V6ru_R2pina_R2pina_id1168_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "107. Tagged file V6ru_R6uge_Saaluse_id9577_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "108. Tagged file V6ru_R2pina_Kahkva_id5750_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "109. Tagged file J2rva_Tyri_Tyri-Alliku_id1370_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "110. Tagged file V6ru_R2pina_Kahkva_id19205_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "111. Tagged file J2rva_Tyri_S2revere_id13737_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "112. Tagged file Saare_Kihelkonna_Kotlandi_id20759_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "113. Tagged file L22ne_Pyhalepa_K2rdla_id22767_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "114. Tagged file Tartu_Kodavere_Alatskivi_id4069_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "115. Tagged file J2rva_Tyri_V22tsa_id16522_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "116. Tagged file J2rva_Ambla_Ambla_id6971_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "117. Tagged file L22ne_Pyhalepa_K2rdla_id25541_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "118. Tagged file Harju_Kose_Palvere_id25472_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "119. Tagged file V6ru_Vastseliina_Misso_id20265_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "120. Tagged file J2rva_Tyri_V22tsa_id18003_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "121. Tagged file Tartu_Kodavere_Pala_id20447_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "122. Tagged file V6ru_Vastseliina_Misso_id13641_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "123. Tagged file Harju_Keila_Keila_id13005_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "124. Tagged file V6ru_R2pina_Kahkva_id7771_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "125. Tagged file Tartu_N6o_Pangodi_id5095_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "126. Tagged file Tartu_N6o_Pangodi_id4146_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "127. Tagged file Tartu_Kodavere_Ranna_id14405_1860a.json\n",
      "(!) Tagging Word Level NER\n",
      "128. Tagged file J2rva_Peetri_V2ike-Kareda_id19122_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "129. Tagged file Tartu_V6nnu_Ahja_id19084_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "130. Tagged file Harju_Hageri_Kohila_id4010_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "131. Tagged file V6ru_R2pina_Kahkva_id6489_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "132. Tagged file Harju_Kose_Palvere_id13989_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "133. Tagged file Viljandi_Paistu_Holstre_id6625_1828a.json\n",
      "(!) Tagging Word Level NER\n",
      "134. Tagged file V6ru_Vastseliina_Misso_id22084_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "135. Tagged file L22ne_Vormsi_Vormsi_id24683_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "136. Tagged file Tartu_Kodavere_Pala_id22815_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "137. Tagged file L22ne_Martna_Martna_id18619_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "138. Tagged file Tartu_V6nnu_Ahja_id20555_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "139. Tagged file J2rva_Ambla_Ambla_id5939_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "140. Tagged file J2rva_Tyri_Kirna_id24973_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "141. Tagged file Tartu_Torma_Avinurme_id20542_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "142. Tagged file Harju_Kose_Triigi_id10000_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "143. Tagged file Harju_Juuru_Juuru_id23774_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "144. Tagged file Viljandi_Paistu_Holstre_id11504_1848a.json\n",
      "(!) Tagging Word Level NER\n",
      "145. Tagged file Tartu_N6o_Pangodi_id5642_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "146. Tagged file Harju_Rapla_Rapla_id20943_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "147. Tagged file L22ne_Vormsi_Vormsi_id14921_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "148. Tagged file L22ne_Vormsi_Vormsi_id25012_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "149. Tagged file J2rva_Tyri_V22tsa_id19025_1898a.json\n",
      "(!) Tagging Word Level NER\n",
      "150. Tagged file J2rva_Tyri_V22tsa_id16384_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "151. Tagged file Harju_Kose_Palvere_id21108_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "152. Tagged file Tartu_R6ngu_Aakre_id4809_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "153. Tagged file Tartu_Kodavere_Alatskivi_id13022_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "154. Tagged file Tartu_R6ngu_Aakre_id8898_1827a.json\n",
      "(!) Tagging Word Level NER\n",
      "155. Tagged file Tartu_V6nnu_Ahja_id22170_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "156. Tagged file Tartu_Otep22_Pyhaj2rve_id22089_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "157. Tagged file J2rva_Anna_Purdi_id25497_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "158. Tagged file Tartu_V6nnu_Ahja_id17890_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "159. Tagged file Viljandi_P6ltsamaa_Pajusi_id6831_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "160. Tagged file L22ne_Pyhalepa_K2rdla_id23188_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "161. Tagged file Tartu_Kodavere_Alatskivi_id1584_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "162. Tagged file Viljandi_P6ltsamaa_Uue-P6ltsamaa_id6410_1853a.json\n",
      "(!) Tagging Word Level NER\n",
      "163. Tagged file L22ne_Martna_Martna_id17524_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "164. Tagged file V6ru_Vastseliina_Misso_id24932_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "165. Tagged file Tartu_Laiuse_Kivij2rve_id4291_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "166. Tagged file V6ru_Vastseliina_Misso_id13301_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "167. Tagged file L22ne_Emmaste_Emmaste_id15690_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "168. Tagged file Tartu_V6nnu_Ahja_id14973_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "169. Tagged file Tartu_V6nnu_Ahja_id21238_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "170. Tagged file Tartu_V6nnu_Ahja_id9656_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "171. Tagged file Saare_Kaarma_Loona_id1233_1912a.json\n",
      "(!) Tagging Word Level NER\n",
      "172. Tagged file Tartu_Torma_Avinurme_id21307_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "173. Tagged file V6ru_Vastseliina_Misso_id20674_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "174. Tagged file Harju_Jyri_Rae_id3658_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "175. Tagged file J2rva_Tyri_S2revere_id16041_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "176. Tagged file Tartu_V6nnu_Ahja_id21350_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "177. Tagged file Harju_Kose_Palvere_id22755_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "178. Tagged file Harju_J6el2htme_J6el2htme_id7359_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "179. Tagged file J2rva_Tyri_Vahastu_id16427_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "180. Tagged file J2rva_Tyri_S2revere_id5632_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "181. Tagged file V6ru_Vastseliina_Misso_id11636_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "182. Tagged file Tartu_V6nnu_Ahja_id19717_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "183. Tagged file Harju_Hageri_Kohila_id7391_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "184. Tagged file L22ne_Kullamaa_Sooniste_id3686_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "185. Tagged file Harju_Juuru_Kaiu_id12588_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "186. Tagged file Tartu_Otep22_Pyhaj2rve_id11890_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "187. Tagged file Tartu_V6nnu_Ahja_id23070_1891a.json\n",
      "(!) Tagging Word Level NER\n",
      "188. Tagged file P2rnu_Tori_Sindi_id20040_1836a.json\n",
      "(!) Tagging Word Level NER\n",
      "189. Tagged file Tartu_Torma_Avinurme_id21181_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "190. Tagged file L22ne_Pyhalepa_K2rdla_id22386_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "191. Tagged file Tartu_V6nnu_Ahja_id21023_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "192. Tagged file Tartu_Kodavere_Pala_id20578_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "193. Tagged file V6ru_Vastseliina_Misso_id21929_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "194. Tagged file L22ne_Ridala_Sinalepa_id25579_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "195. Tagged file J2rva_Tyri_Kirna_id25219_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "196. Tagged file J2rva_Tyri_S2revere_id11686_1874a.json\n",
      "(!) Tagging Word Level NER\n",
      "197. Tagged file Tartu_V6nnu_Ahja_id18911_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "198. Tagged file Saare_P8ide_Laimjala_id10240_1910a.json\n",
      "(!) Tagging Word Level NER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199. Tagged file Tartu_Torma_Avinurme_id17369_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "200. Tagged file Harju_Keila_Keila_id13018_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "201. Tagged file V6ru_Vastseliina_Misso_id21891_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "202. Tagged file Harju_Hageri_Kohila_id4966_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "203. Tagged file Viljandi_P6ltsamaa_Uue-P6ltsamaa_id8714_1854a.json\n",
      "(!) Tagging Word Level NER\n",
      "204. Tagged file V6ru_P6lva_Kiuma_id9794_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "205. Tagged file Tartu_V6nnu_Kiidj2rve_id24401_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "206. Tagged file J2rva_Tyri_V22tsa_id16408_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "207. Tagged file J2rva_Tyri_Tyri-Alliku_id3994_1903a.json\n",
      "(!) Tagging Word Level NER\n",
      "208. Tagged file P2rnu_Audru_V6lla_id5150_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "209. Tagged file V6ru_R2pina_Kahkva_id8829_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "210. Tagged file L22ne_Karuse_Saastna_id22146_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "211. Tagged file Tartu_V6nnu_Ahja_id22857_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "212. Tagged file Tartu_V6nnu_Ahja_id12159_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "213. Tagged file Tartu_Torma_Avinurme_id5061_1860a.json\n",
      "(!) Tagging Word Level NER\n",
      "214. Tagged file Tartu_R6ngu_Aakre_id6659_1826a.json\n",
      "(!) Tagging Word Level NER\n",
      "215. Tagged file Tartu_V6nnu_Kiidj2rve_id24500_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "216. Tagged file Viru_Rakvere_Rakvere_id5143_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "217. Tagged file Tartu_V6nnu_Ahja_id17913_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "218. Tagged file Tartu_Kodavere_Pala_id23275_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "219. Tagged file L22ne_Reigi_K6rgessaare_id23087_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "220. Tagged file Tartu_N6o_Aru_id5374_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "221. Tagged file Harju_Juuru_Juuru_id20228_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "222. Tagged file Tartu_V6nnu_Rasina_id13313_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "223. Tagged file Tartu_V6nnu_Ahja_id15819_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "224. Tagged file Tartu_V6nnu_Ahja_id13002_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "225. Tagged file Tartu_Kodavere_Pala_id21493_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "226. Tagged file V6ru_Vastseliina_Misso_id19537_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "227. Tagged file Saare_Mustjala_Mustjala_id7076_1821a.json\n",
      "(!) Tagging Word Level NER\n",
      "228. Tagged file L22ne_Vormsi_Vormsi_id24033_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "229. Tagged file Viru_Rakvere_S6meru_id10293_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "230. Tagged file Tartu_Torma_Avinurme_id24697_1824a.json\n",
      "(!) Tagging Word Level NER\n",
      "231. Tagged file Harju_Kose_Palvere_id13988_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "232. Tagged file Tartu_V6nnu_Ahja_id12425_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "233. Tagged file Viljandi_K6pu_Suure-K6pu_id4649_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "234. Tagged file Tartu_V6nnu_Ahja_id20421_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "235. Tagged file Harju_Kose_Palvere_id19467_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "236. Tagged file Viljandi_Viljandi_Karula_id19345_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "237. Tagged file P2rnu_P2rnu-Jaagupi_Soosalu_id14294_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "238. Tagged file Harju_Rapla_Rapla_id17276_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "239. Tagged file Tartu_Kursi_Puurmani_id3066_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "240. Tagged file Tartu_Torma_Avinurme_id17101_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "241. Tagged file Harju_Kose_Palvere_id22520_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "242. Tagged file J2rva_Tyri_S2revere_id8279_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "243. Tagged file Tartu_V6nnu_Ahja_id17669_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "244. Tagged file Tartu_Kodavere_Pala_id24085_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "245. Tagged file Tartu_Torma_Avinurme_id14737_1905a.json\n",
      "(!) Tagging Word Level NER\n",
      "246. Tagged file L22ne_Kullamaa_Piirsalu_id13504_1899a.json\n",
      "(!) Tagging Word Level NER\n",
      "247. Tagged file L22ne_Hanila_Massu_id446_1913a.json\n",
      "(!) Tagging Word Level NER\n",
      "248. Tagged file J2rva_Tyri_V22tsa_id18591_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "249. Tagged file Harju_Hageri_Kohila_id21266_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "250. Tagged file Tartu_R6ngu_Aakre_id5921_1890a.json\n",
      "(!) Files tagged\n",
      "(!) Preparing training texts\n",
      "(!) Training texts done\n",
      "(!) Training NerTagger\n",
      "(!) Warning: Location of the new \"settings.py\" is the same one as the old one. Model's settings are not copied.\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 345801\n",
      "Seconds required: 2.298\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 1000\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 31995.116625\n",
      "Trial #1 (eta = 0.100000): 2786.502816\n",
      "Trial #2 (eta = 0.200000): 4596.425920\n",
      "Trial #3 (eta = 0.400000): 9350.799080\n",
      "Trial #4 (eta = 0.800000): 19080.548517\n",
      "Trial #5 (eta = 1.600000): 37179.682803 (worse)\n",
      "Trial #6 (eta = 0.050000): 2315.028693\n",
      "Trial #7 (eta = 0.025000): 2482.870855\n",
      "Trial #8 (eta = 0.012500): 2903.513158\n",
      "Trial #9 (eta = 0.006250): 3519.648536\n",
      "Trial #10 (eta = 0.003125): 4362.213671\n",
      "Trial #11 (eta = 0.001563): 5570.176356\n",
      "Trial #12 (eta = 0.000781): 7424.971988\n",
      "Trial #13 (eta = 0.000391): 10346.721893\n",
      "Trial #14 (eta = 0.000195): 14535.940849\n",
      "Trial #15 (eta = 0.000098): 19840.491264\n",
      "Best learning rate (eta): 0.050000\n",
      "Seconds required: 0.341\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 18508.728127\n",
      "Feature L2-norm: 33.243397\n",
      "Learning rate (eta): 0.049995\n",
      "Total number of feature updates: 15614\n",
      "Seconds required for this iteration: 0.358\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 8867.261916\n",
      "Feature L2-norm: 43.159399\n",
      "Learning rate (eta): 0.049990\n",
      "Total number of feature updates: 31228\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 6016.984448\n",
      "Feature L2-norm: 49.910428\n",
      "Learning rate (eta): 0.049985\n",
      "Total number of feature updates: 46842\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 4475.071006\n",
      "Feature L2-norm: 55.134816\n",
      "Learning rate (eta): 0.049980\n",
      "Total number of feature updates: 62456\n",
      "Seconds required for this iteration: 0.337\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 3635.177752\n",
      "Feature L2-norm: 59.479701\n",
      "Learning rate (eta): 0.049975\n",
      "Total number of feature updates: 78070\n",
      "Seconds required for this iteration: 0.330\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 2987.852619\n",
      "Feature L2-norm: 63.210706\n",
      "Learning rate (eta): 0.049970\n",
      "Total number of feature updates: 93684\n",
      "Seconds required for this iteration: 0.338\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 2528.315237\n",
      "Feature L2-norm: 66.430259\n",
      "Learning rate (eta): 0.049965\n",
      "Total number of feature updates: 109298\n",
      "Seconds required for this iteration: 0.332\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 2152.171298\n",
      "Feature L2-norm: 69.282786\n",
      "Learning rate (eta): 0.049960\n",
      "Total number of feature updates: 124912\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 1910.653352\n",
      "Feature L2-norm: 71.853634\n",
      "Learning rate (eta): 0.049955\n",
      "Total number of feature updates: 140526\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 1676.962829\n",
      "Feature L2-norm: 74.212020\n",
      "Learning rate (eta): 0.049950\n",
      "Total number of feature updates: 156140\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 1512.972848\n",
      "Improvement ratio: 11.233351\n",
      "Feature L2-norm: 76.371651\n",
      "Learning rate (eta): 0.049945\n",
      "Total number of feature updates: 171754\n",
      "Seconds required for this iteration: 0.335\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 1383.089146\n",
      "Improvement ratio: 5.411201\n",
      "Feature L2-norm: 78.344782\n",
      "Learning rate (eta): 0.049940\n",
      "Total number of feature updates: 187368\n",
      "Seconds required for this iteration: 0.327\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 1241.136561\n",
      "Improvement ratio: 3.847963\n",
      "Feature L2-norm: 80.180601\n",
      "Learning rate (eta): 0.049935\n",
      "Total number of feature updates: 202982\n",
      "Seconds required for this iteration: 0.322\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 1161.165800\n",
      "Improvement ratio: 2.853947\n",
      "Feature L2-norm: 81.900434\n",
      "Learning rate (eta): 0.049930\n",
      "Total number of feature updates: 218596\n",
      "Seconds required for this iteration: 0.334\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 1089.490133\n",
      "Improvement ratio: 2.336586\n",
      "Feature L2-norm: 83.491855\n",
      "Learning rate (eta): 0.049925\n",
      "Total number of feature updates: 234210\n",
      "Seconds required for this iteration: 0.330\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #16 *****\n",
      "Loss: 1002.038645\n",
      "Improvement ratio: 1.981774\n",
      "Feature L2-norm: 84.986986\n",
      "Learning rate (eta): 0.049920\n",
      "Total number of feature updates: 249824\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 939.802186\n",
      "Improvement ratio: 1.690263\n",
      "Feature L2-norm: 86.393819\n",
      "Learning rate (eta): 0.049915\n",
      "Total number of feature updates: 265438\n",
      "Seconds required for this iteration: 0.322\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 890.885643\n",
      "Improvement ratio: 1.415766\n",
      "Feature L2-norm: 87.722122\n",
      "Learning rate (eta): 0.049910\n",
      "Total number of feature updates: 281052\n",
      "Seconds required for this iteration: 0.336\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 835.923823\n",
      "Improvement ratio: 1.285679\n",
      "Feature L2-norm: 88.981328\n",
      "Learning rate (eta): 0.049905\n",
      "Total number of feature updates: 296666\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 787.997047\n",
      "Improvement ratio: 1.128133\n",
      "Feature L2-norm: 90.182740\n",
      "Learning rate (eta): 0.049900\n",
      "Total number of feature updates: 312280\n",
      "Seconds required for this iteration: 0.327\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 768.169961\n",
      "Improvement ratio: 0.969581\n",
      "Feature L2-norm: 91.321187\n",
      "Learning rate (eta): 0.049895\n",
      "Total number of feature updates: 327894\n",
      "Seconds required for this iteration: 0.314\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 720.088295\n",
      "Improvement ratio: 0.920722\n",
      "Feature L2-norm: 92.406598\n",
      "Learning rate (eta): 0.049890\n",
      "Total number of feature updates: 343508\n",
      "Seconds required for this iteration: 0.317\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 678.897833\n",
      "Improvement ratio: 0.828164\n",
      "Feature L2-norm: 93.436559\n",
      "Learning rate (eta): 0.049885\n",
      "Total number of feature updates: 359122\n",
      "Seconds required for this iteration: 0.311\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 670.953618\n",
      "Improvement ratio: 0.730620\n",
      "Feature L2-norm: 94.434632\n",
      "Learning rate (eta): 0.049880\n",
      "Total number of feature updates: 374736\n",
      "Seconds required for this iteration: 0.309\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 633.163035\n",
      "Improvement ratio: 0.720710\n",
      "Feature L2-norm: 95.391379\n",
      "Learning rate (eta): 0.049875\n",
      "Total number of feature updates: 390350\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 609.350809\n",
      "Improvement ratio: 0.644436\n",
      "Feature L2-norm: 96.314227\n",
      "Learning rate (eta): 0.049870\n",
      "Total number of feature updates: 405964\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 592.925794\n",
      "Improvement ratio: 0.585025\n",
      "Feature L2-norm: 97.204213\n",
      "Learning rate (eta): 0.049865\n",
      "Total number of feature updates: 421578\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 566.541420\n",
      "Improvement ratio: 0.572499\n",
      "Feature L2-norm: 98.055370\n",
      "Learning rate (eta): 0.049860\n",
      "Total number of feature updates: 437192\n",
      "Seconds required for this iteration: 0.308\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 556.428390\n",
      "Improvement ratio: 0.502303\n",
      "Feature L2-norm: 98.878944\n",
      "Learning rate (eta): 0.049855\n",
      "Total number of feature updates: 452806\n",
      "Seconds required for this iteration: 0.313\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 539.573795\n",
      "Improvement ratio: 0.460406\n",
      "Feature L2-norm: 99.665273\n",
      "Learning rate (eta): 0.049850\n",
      "Total number of feature updates: 468420\n",
      "Seconds required for this iteration: 0.309\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 524.348213\n",
      "Improvement ratio: 0.465000\n",
      "Feature L2-norm: 100.426157\n",
      "Learning rate (eta): 0.049845\n",
      "Total number of feature updates: 484034\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 508.232598\n",
      "Improvement ratio: 0.416848\n",
      "Feature L2-norm: 101.163368\n",
      "Learning rate (eta): 0.049841\n",
      "Total number of feature updates: 499648\n",
      "Seconds required for this iteration: 0.329\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 493.112400\n",
      "Improvement ratio: 0.376761\n",
      "Feature L2-norm: 101.884788\n",
      "Learning rate (eta): 0.049836\n",
      "Total number of feature updates: 515262\n",
      "Seconds required for this iteration: 0.314\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 472.281584\n",
      "Improvement ratio: 0.420664\n",
      "Feature L2-norm: 102.573743\n",
      "Learning rate (eta): 0.049831\n",
      "Total number of feature updates: 530876\n",
      "Seconds required for this iteration: 0.311\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 467.746145\n",
      "Improvement ratio: 0.353647\n",
      "Feature L2-norm: 103.258121\n",
      "Learning rate (eta): 0.049826\n",
      "Total number of feature updates: 546490\n",
      "Seconds required for this iteration: 0.393\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 474.503973\n",
      "Improvement ratio: 0.284185\n",
      "Feature L2-norm: 103.920062\n",
      "Learning rate (eta): 0.049821\n",
      "Total number of feature updates: 562104\n",
      "Seconds required for this iteration: 0.349\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 438.612879\n",
      "Improvement ratio: 0.351820\n",
      "Feature L2-norm: 104.561529\n",
      "Learning rate (eta): 0.049816\n",
      "Total number of feature updates: 577718\n",
      "Seconds required for this iteration: 0.319\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 437.022412\n",
      "Improvement ratio: 0.296367\n",
      "Feature L2-norm: 105.182311\n",
      "Learning rate (eta): 0.049811\n",
      "Total number of feature updates: 593332\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 431.321080\n",
      "Improvement ratio: 0.290056\n",
      "Feature L2-norm: 105.782279\n",
      "Learning rate (eta): 0.049806\n",
      "Total number of feature updates: 608946\n",
      "Seconds required for this iteration: 0.319\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 417.458704\n",
      "Improvement ratio: 0.292520\n",
      "Feature L2-norm: 106.378285\n",
      "Learning rate (eta): 0.049801\n",
      "Total number of feature updates: 624560\n",
      "Seconds required for this iteration: 0.343\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 419.173157\n",
      "Improvement ratio: 0.250911\n",
      "Feature L2-norm: 106.960514\n",
      "Learning rate (eta): 0.049796\n",
      "Total number of feature updates: 640174\n",
      "Seconds required for this iteration: 0.327\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 399.363409\n",
      "Improvement ratio: 0.272607\n",
      "Feature L2-norm: 107.526484\n",
      "Learning rate (eta): 0.049791\n",
      "Total number of feature updates: 655788\n",
      "Seconds required for this iteration: 0.333\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 381.984800\n",
      "Improvement ratio: 0.290922\n",
      "Feature L2-norm: 108.085540\n",
      "Learning rate (eta): 0.049786\n",
      "Total number of feature updates: 671402\n",
      "Seconds required for this iteration: 0.326\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 388.691142\n",
      "Improvement ratio: 0.215056\n",
      "Feature L2-norm: 108.618614\n",
      "Learning rate (eta): 0.049781\n",
      "Total number of feature updates: 687016\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 364.368481\n",
      "Improvement ratio: 0.283717\n",
      "Feature L2-norm: 109.139973\n",
      "Learning rate (eta): 0.049776\n",
      "Total number of feature updates: 702630\n",
      "Seconds required for this iteration: 0.323\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 388.306872\n",
      "Improvement ratio: 0.221982\n",
      "Feature L2-norm: 109.663730\n",
      "Learning rate (eta): 0.049771\n",
      "Total number of feature updates: 718244\n",
      "Seconds required for this iteration: 0.311\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 370.228947\n",
      "Improvement ratio: 0.184707\n",
      "Feature L2-norm: 110.167348\n",
      "Learning rate (eta): 0.049766\n",
      "Total number of feature updates: 733858\n",
      "Seconds required for this iteration: 0.316\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 352.221130\n",
      "Improvement ratio: 0.240761\n",
      "Feature L2-norm: 110.664148\n",
      "Learning rate (eta): 0.049761\n",
      "Total number of feature updates: 749472\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 371.131953\n",
      "Improvement ratio: 0.162177\n",
      "Feature L2-norm: 111.148972\n",
      "Learning rate (eta): 0.049756\n",
      "Total number of feature updates: 765086\n",
      "Seconds required for this iteration: 0.307\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 338.792084\n",
      "Improvement ratio: 0.232197\n",
      "Feature L2-norm: 111.617751\n",
      "Learning rate (eta): 0.049751\n",
      "Total number of feature updates: 780700\n",
      "Seconds required for this iteration: 0.321\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 362.831069\n",
      "Improvement ratio: 0.155285\n",
      "Feature L2-norm: 112.079270\n",
      "Learning rate (eta): 0.049746\n",
      "Total number of feature updates: 796314\n",
      "Seconds required for this iteration: 0.319\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 337.962165\n",
      "Improvement ratio: 0.181681\n",
      "Feature L2-norm: 112.534397\n",
      "Learning rate (eta): 0.049741\n",
      "Total number of feature updates: 811928\n",
      "Seconds required for this iteration: 0.328\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 341.581417\n",
      "Improvement ratio: 0.118283\n",
      "Feature L2-norm: 112.984915\n",
      "Learning rate (eta): 0.049736\n",
      "Total number of feature updates: 827542\n",
      "Seconds required for this iteration: 0.321\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 326.773100\n",
      "Improvement ratio: 0.189483\n",
      "Feature L2-norm: 113.430218\n",
      "Learning rate (eta): 0.049731\n",
      "Total number of feature updates: 843156\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 327.775189\n",
      "Improvement ratio: 0.111641\n",
      "Feature L2-norm: 113.856563\n",
      "Learning rate (eta): 0.049727\n",
      "Total number of feature updates: 858770\n",
      "Seconds required for this iteration: 0.329\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #56 *****\n",
      "Loss: 321.903113\n",
      "Improvement ratio: 0.206285\n",
      "Feature L2-norm: 114.282871\n",
      "Learning rate (eta): 0.049722\n",
      "Total number of feature updates: 874384\n",
      "Seconds required for this iteration: 0.323\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 324.435576\n",
      "Improvement ratio: 0.141148\n",
      "Feature L2-norm: 114.692085\n",
      "Learning rate (eta): 0.049717\n",
      "Total number of feature updates: 889998\n",
      "Seconds required for this iteration: 0.317\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 298.642348\n",
      "Improvement ratio: 0.179408\n",
      "Feature L2-norm: 115.098436\n",
      "Learning rate (eta): 0.049712\n",
      "Total number of feature updates: 905612\n",
      "Seconds required for this iteration: 0.328\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 316.739260\n",
      "Improvement ratio: 0.171727\n",
      "Feature L2-norm: 115.503341\n",
      "Learning rate (eta): 0.049707\n",
      "Total number of feature updates: 921226\n",
      "Seconds required for this iteration: 0.311\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 292.676873\n",
      "Improvement ratio: 0.157564\n",
      "Feature L2-norm: 115.896642\n",
      "Learning rate (eta): 0.049702\n",
      "Total number of feature updates: 936840\n",
      "Seconds required for this iteration: 0.308\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 305.570137\n",
      "Improvement ratio: 0.187390\n",
      "Feature L2-norm: 116.281373\n",
      "Learning rate (eta): 0.049697\n",
      "Total number of feature updates: 952454\n",
      "Seconds required for this iteration: 0.310\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 300.128102\n",
      "Improvement ratio: 0.126060\n",
      "Feature L2-norm: 116.666262\n",
      "Learning rate (eta): 0.049692\n",
      "Total number of feature updates: 968068\n",
      "Seconds required for this iteration: 0.315\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 298.765103\n",
      "Improvement ratio: 0.143311\n",
      "Feature L2-norm: 117.042016\n",
      "Learning rate (eta): 0.049687\n",
      "Total number of feature updates: 983682\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 291.006786\n",
      "Improvement ratio: 0.122905\n",
      "Feature L2-norm: 117.411085\n",
      "Learning rate (eta): 0.049682\n",
      "Total number of feature updates: 999296\n",
      "Seconds required for this iteration: 0.328\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 290.352274\n",
      "Improvement ratio: 0.128888\n",
      "Feature L2-norm: 117.773779\n",
      "Learning rate (eta): 0.049677\n",
      "Total number of feature updates: 1014910\n",
      "Seconds required for this iteration: 0.325\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 273.814495\n",
      "Improvement ratio: 0.175625\n",
      "Feature L2-norm: 118.129958\n",
      "Learning rate (eta): 0.049672\n",
      "Total number of feature updates: 1030524\n",
      "Seconds required for this iteration: 0.317\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 298.374710\n",
      "Improvement ratio: 0.087343\n",
      "Feature L2-norm: 118.482558\n",
      "Learning rate (eta): 0.049667\n",
      "Total number of feature updates: 1046138\n",
      "Seconds required for this iteration: 0.313\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 281.728783\n",
      "Improvement ratio: 0.060035\n",
      "Feature L2-norm: 118.822844\n",
      "Learning rate (eta): 0.049662\n",
      "Total number of feature updates: 1061752\n",
      "Seconds required for this iteration: 0.317\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 265.901442\n",
      "Improvement ratio: 0.191190\n",
      "Feature L2-norm: 119.172360\n",
      "Learning rate (eta): 0.049657\n",
      "Total number of feature updates: 1077366\n",
      "Seconds required for this iteration: 0.317\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 277.520521\n",
      "Improvement ratio: 0.054613\n",
      "Feature L2-norm: 119.507180\n",
      "Learning rate (eta): 0.049652\n",
      "Total number of feature updates: 1092980\n",
      "Seconds required for this iteration: 0.331\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 273.006836\n",
      "Improvement ratio: 0.119277\n",
      "Feature L2-norm: 119.839778\n",
      "Learning rate (eta): 0.049648\n",
      "Total number of feature updates: 1108594\n",
      "Seconds required for this iteration: 0.340\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 271.646457\n",
      "Improvement ratio: 0.104848\n",
      "Feature L2-norm: 120.171188\n",
      "Learning rate (eta): 0.049643\n",
      "Total number of feature updates: 1124208\n",
      "Seconds required for this iteration: 0.324\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 267.356775\n",
      "Improvement ratio: 0.117477\n",
      "Feature L2-norm: 120.496076\n",
      "Learning rate (eta): 0.049638\n",
      "Total number of feature updates: 1139822\n",
      "Seconds required for this iteration: 0.311\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 269.243356\n",
      "Improvement ratio: 0.080832\n",
      "Feature L2-norm: 120.813242\n",
      "Learning rate (eta): 0.049633\n",
      "Total number of feature updates: 1155436\n",
      "Seconds required for this iteration: 0.308\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 252.627848\n",
      "Improvement ratio: 0.149328\n",
      "Feature L2-norm: 121.123137\n",
      "Learning rate (eta): 0.049628\n",
      "Total number of feature updates: 1171050\n",
      "Seconds required for this iteration: 0.309\n",
      "\n",
      "***** Epoch #76 *****\n",
      "Loss: 254.824329\n",
      "Improvement ratio: 0.074523\n",
      "Feature L2-norm: 121.441591\n",
      "Learning rate (eta): 0.049623\n",
      "Total number of feature updates: 1186664\n",
      "Seconds required for this iteration: 0.309\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 264.733168\n",
      "Improvement ratio: 0.127077\n",
      "Feature L2-norm: 121.751298\n",
      "Learning rate (eta): 0.049618\n",
      "Total number of feature updates: 1202278\n",
      "Seconds required for this iteration: 0.310\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 268.320192\n",
      "Improvement ratio: 0.049972\n",
      "Feature L2-norm: 122.063501\n",
      "Learning rate (eta): 0.049613\n",
      "Total number of feature updates: 1217892\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #79 *****\n",
      "Loss: 257.172419\n",
      "Improvement ratio: 0.033942\n",
      "Feature L2-norm: 122.360337\n",
      "Learning rate (eta): 0.049608\n",
      "Total number of feature updates: 1233506\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 256.815420\n",
      "Improvement ratio: 0.080622\n",
      "Feature L2-norm: 122.651758\n",
      "Learning rate (eta): 0.049603\n",
      "Total number of feature updates: 1249120\n",
      "Seconds required for this iteration: 0.306\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 252.947688\n",
      "Improvement ratio: 0.079302\n",
      "Feature L2-norm: 122.946091\n",
      "Learning rate (eta): 0.049598\n",
      "Total number of feature updates: 1264734\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 248.629462\n",
      "Improvement ratio: 0.092575\n",
      "Feature L2-norm: 123.236044\n",
      "Learning rate (eta): 0.049593\n",
      "Total number of feature updates: 1280348\n",
      "Seconds required for this iteration: 0.304\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 250.189244\n",
      "Improvement ratio: 0.068618\n",
      "Feature L2-norm: 123.517691\n",
      "Learning rate (eta): 0.049588\n",
      "Total number of feature updates: 1295962\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 247.809422\n",
      "Improvement ratio: 0.086494\n",
      "Feature L2-norm: 123.794062\n",
      "Learning rate (eta): 0.049583\n",
      "Total number of feature updates: 1311576\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 238.594537\n",
      "Improvement ratio: 0.058817\n",
      "Feature L2-norm: 124.074006\n",
      "Learning rate (eta): 0.049579\n",
      "Total number of feature updates: 1327190\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 244.514244\n",
      "Improvement ratio: 0.042166\n",
      "Feature L2-norm: 124.351297\n",
      "Learning rate (eta): 0.049574\n",
      "Total number of feature updates: 1342804\n",
      "Seconds required for this iteration: 0.304\n",
      "\n",
      "***** Epoch #87 *****\n",
      "Loss: 240.613330\n",
      "Improvement ratio: 0.100243\n",
      "Feature L2-norm: 124.624148\n",
      "Learning rate (eta): 0.049569\n",
      "Total number of feature updates: 1358418\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #88 *****\n",
      "Loss: 241.499745\n",
      "Improvement ratio: 0.111058\n",
      "Feature L2-norm: 124.888460\n",
      "Learning rate (eta): 0.049564\n",
      "Total number of feature updates: 1374032\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #89 *****\n",
      "Loss: 239.839344\n",
      "Improvement ratio: 0.072270\n",
      "Feature L2-norm: 125.151238\n",
      "Learning rate (eta): 0.049559\n",
      "Total number of feature updates: 1389646\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #90 *****\n",
      "Loss: 234.532774\n",
      "Improvement ratio: 0.095009\n",
      "Feature L2-norm: 125.412198\n",
      "Learning rate (eta): 0.049554\n",
      "Total number of feature updates: 1405260\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #91 *****\n",
      "Loss: 231.835902\n",
      "Improvement ratio: 0.091063\n",
      "Feature L2-norm: 125.672543\n",
      "Learning rate (eta): 0.049549\n",
      "Total number of feature updates: 1420874\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #92 *****\n",
      "Loss: 234.682662\n",
      "Improvement ratio: 0.059428\n",
      "Feature L2-norm: 125.923294\n",
      "Learning rate (eta): 0.049544\n",
      "Total number of feature updates: 1436488\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #93 *****\n",
      "Loss: 227.972561\n",
      "Improvement ratio: 0.097453\n",
      "Feature L2-norm: 126.176839\n",
      "Learning rate (eta): 0.049539\n",
      "Total number of feature updates: 1452102\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #94 *****\n",
      "Loss: 219.124792\n",
      "Improvement ratio: 0.130905\n",
      "Feature L2-norm: 126.423919\n",
      "Learning rate (eta): 0.049534\n",
      "Total number of feature updates: 1467716\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #95 *****\n",
      "Loss: 237.111924\n",
      "Improvement ratio: 0.006253\n",
      "Feature L2-norm: 126.676266\n",
      "Learning rate (eta): 0.049529\n",
      "Total number of feature updates: 1483330\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #96 *****\n",
      "Loss: 225.818811\n",
      "Improvement ratio: 0.082790\n",
      "Feature L2-norm: 126.923616\n",
      "Learning rate (eta): 0.049525\n",
      "Total number of feature updates: 1498944\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #97 *****\n",
      "Loss: 224.692387\n",
      "Improvement ratio: 0.070857\n",
      "Feature L2-norm: 127.165996\n",
      "Learning rate (eta): 0.049520\n",
      "Total number of feature updates: 1514558\n",
      "Seconds required for this iteration: 0.306\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #98 *****\n",
      "Loss: 227.076789\n",
      "Improvement ratio: 0.063516\n",
      "Feature L2-norm: 127.406215\n",
      "Learning rate (eta): 0.049515\n",
      "Total number of feature updates: 1530172\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #99 *****\n",
      "Loss: 208.020045\n",
      "Improvement ratio: 0.152963\n",
      "Feature L2-norm: 127.642771\n",
      "Learning rate (eta): 0.049510\n",
      "Total number of feature updates: 1545786\n",
      "Seconds required for this iteration: 0.304\n",
      "\n",
      "***** Epoch #100 *****\n",
      "Loss: 223.668018\n",
      "Improvement ratio: 0.048575\n",
      "Feature L2-norm: 127.882465\n",
      "Learning rate (eta): 0.049505\n",
      "Total number of feature updates: 1561400\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #101 *****\n",
      "Loss: 222.577811\n",
      "Improvement ratio: 0.041595\n",
      "Feature L2-norm: 128.113796\n",
      "Learning rate (eta): 0.049500\n",
      "Total number of feature updates: 1577014\n",
      "Seconds required for this iteration: 0.304\n",
      "\n",
      "***** Epoch #102 *****\n",
      "Loss: 220.763008\n",
      "Improvement ratio: 0.063052\n",
      "Feature L2-norm: 128.343379\n",
      "Learning rate (eta): 0.049495\n",
      "Total number of feature updates: 1592628\n",
      "Seconds required for this iteration: 0.305\n",
      "\n",
      "***** Epoch #103 *****\n",
      "Loss: 217.953753\n",
      "Improvement ratio: 0.045968\n",
      "Feature L2-norm: 128.572457\n",
      "Learning rate (eta): 0.049490\n",
      "Total number of feature updates: 1608242\n",
      "Seconds required for this iteration: 0.310\n",
      "\n",
      "***** Epoch #104 *****\n",
      "Loss: 209.287708\n",
      "Improvement ratio: 0.047003\n",
      "Feature L2-norm: 128.798784\n",
      "Learning rate (eta): 0.049485\n",
      "Total number of feature updates: 1623856\n",
      "Seconds required for this iteration: 0.310\n",
      "\n",
      "***** Epoch #105 *****\n",
      "Loss: 230.025724\n",
      "Improvement ratio: 0.030806\n",
      "Feature L2-norm: 129.024689\n",
      "Learning rate (eta): 0.049480\n",
      "Total number of feature updates: 1639470\n",
      "Seconds required for this iteration: 0.309\n",
      "\n",
      "***** Epoch #106 *****\n",
      "Loss: 210.303450\n",
      "Improvement ratio: 0.073776\n",
      "Feature L2-norm: 129.247616\n",
      "Learning rate (eta): 0.049476\n",
      "Total number of feature updates: 1655084\n",
      "Seconds required for this iteration: 0.310\n",
      "\n",
      "***** Epoch #107 *****\n",
      "Loss: 215.428447\n",
      "Improvement ratio: 0.043002\n",
      "Feature L2-norm: 129.465195\n",
      "Learning rate (eta): 0.049471\n",
      "Total number of feature updates: 1670698\n",
      "Seconds required for this iteration: 0.307\n",
      "\n",
      "***** Epoch #108 *****\n",
      "Loss: 198.075392\n",
      "Improvement ratio: 0.146416\n",
      "Feature L2-norm: 129.680794\n",
      "Learning rate (eta): 0.049466\n",
      "Total number of feature updates: 1686312\n",
      "Seconds required for this iteration: 0.307\n",
      "\n",
      "***** Epoch #109 *****\n",
      "Loss: 231.579533\n",
      "Improvement ratio: -0.101734\n",
      "Feature L2-norm: 129.900210\n",
      "Learning rate (eta): 0.049461\n",
      "Total number of feature updates: 1701926\n",
      "Seconds required for this iteration: 0.309\n",
      "\n",
      "SGD terminated with the stopping criteria\n",
      "Loss: 198.075392\n",
      "Total seconds required for training: 35.129\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 345801 (345801)\n",
      "Number of active attributes: 312579 (312579)\n",
      "Number of active labels: 11 (11)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.957\n",
      "\n",
      "(!) NerTagger training done\n",
      "\n",
      "(!) Tagging...\n",
      "(!) Tagging Word Level NER\n",
      "1. Tagged file V6ru_R6uge_Saaluse_id8753_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "2. Tagged file Viljandi_Helme_Leebiku_id14149_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "3. Tagged file L22ne_Martna_Martna_id14159_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "4. Tagged file V6ru_Vastseliina_Misso_id24907_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "5. Tagged file V6ru_R2pina_R2pina_id10213_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "6. Tagged file J2rva_Tyri_V22tsa_id16362_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "7. Tagged file J2rva_Tyri_S2revere_id5550_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "8. Tagged file Tartu_Kodavere_Alatskivi_id10860_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "9. Tagged file Harju_Juuru_Kaiu_id16280_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "10. Tagged file Tartu_Kodavere_Alatskivi_id1271_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "11. Tagged file L22ne_Reigi_K6rgessaare_id23306_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "12. Tagged file L22ne_Ridala_Sinalepa_id25437_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "13. Tagged file J2rva_Tyri_Tyri-Alliku_id3082_1900a.json\n",
      "(!) Tagging Word Level NER\n",
      "14. Tagged file V6ru_R6uge_Saaluse_id10962_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "15. Tagged file V6ru_Vastseliina_Misso_id22085_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "16. Tagged file Tartu_V6nnu_Ahja_id13957_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "17. Tagged file Harju_Kose_Palvere_id16729_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "18. Tagged file Viljandi_K6pu_Suure-K6pu_id4665_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "19. Tagged file P2rnu_Tori_Tori_id25337_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "20. Tagged file Tartu_V6nnu_Ahja_id22380_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "21. Tagged file Harju_Kose_Triigi_id9421_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "22. Tagged file Tartu_Kodavere_Ranna_id15035_1862a.json\n",
      "(!) Tagging Word Level NER\n",
      "23. Tagged file Harju_Kose_Triigi_id9938_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "24. Tagged file Viru_Rakvere_S6meru_id5673_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "25. Tagged file Tartu_Otep22_Pyhaj2rve_id1540_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "26. Tagged file J2rva_Tyri_V22tsa_id22178_1912a.json\n",
      "(!) Tagging Word Level NER\n",
      "27. Tagged file Harju_Juuru_Kaiu_id9874_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "28. Tagged file Tartu_Otep22_Pyhaj2rve_id7840_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "29. Tagged file V6ru_R2pina_Kahkva_id8869_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "30. Tagged file Tartu_R6ngu_Aakre_id9106_1827a.json\n",
      "(!) Tagging Word Level NER\n",
      "31. Tagged file V6ru_Vastseliina_Misso_id8101_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "32. Tagged file V6ru_Vastseliina_Misso_id13681_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "33. Tagged file Tartu_N6o_Pangodi_id5262_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "34. Tagged file Harju_Keila_Saue_id13436_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "35. Tagged file Harju_Kose_Triigi_id9536_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "36. Tagged file Tartu_Torma_Avinurme_id21275_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "37. Tagged file Tartu_Otep22_Pyhaj2rve_id12075_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "38. Tagged file L22ne_Martna_Martna_id23117_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "39. Tagged file L22ne_Kullamaa_Piirsalu_id6881_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "40. Tagged file Viru_Haljala_Vihula_id4974_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "41. Tagged file P2rnu_Tori_Tori_id25322_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "42. Tagged file Tartu_Kodavere_Ranna_id19673_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "43. Tagged file J2rva_Tyri_S2revere_id9244_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "44. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id22818_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "45. Tagged file Tartu_V6nnu_Ahja_id16349_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "46. Tagged file Harju_Kuusalu_Kolga_id11902_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "47. Tagged file J2rva_Peetri_V2ike-Kareda_id22150_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "48. Tagged file Tartu_Kodavere_Pala_id22870_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "49. Tagged file Tartu_V6nnu_Ahja_id13565_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "50. Tagged file Harju_Juuru_Juuru_id17866_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "51. Tagged file Harju_Juuru_Kaiu_id931_1912a.json\n",
      "(!) Tagging Word Level NER\n",
      "52. Tagged file J2rva_Anna_Eivere_id6607_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "53. Tagged file L22ne_Kullamaa_Piirsalu_id16723_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "54. Tagged file J2rva_Tyri_V22tsa_id17604_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "55. Tagged file Tartu_V6nnu_Ahja_id14708_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "56. Tagged file Tartu_Kodavere_Alatskivi_id9914_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "57. Tagged file L22ne_Pyhalepa_K2rdla_id23461_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "58. Tagged file Tartu_V6nnu_Ahja_id21842_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "59. Tagged file Harju_J6el2htme_J6el2htme_id7633_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "60. Tagged file Tartu_Kodavere_Alatskivi_id13040_1856a.json\n",
      "(!) Tagging Word Level NER\n",
      "61. Tagged file Saare_P8ide_Laimjala_id6577_1917a.json\n",
      "(!) Tagging Word Level NER\n",
      "62. Tagged file J2rva_Tyri_Kirna_id24066_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "63. Tagged file L22ne_Ridala_Sinalepa_id25489_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "64. Tagged file Tartu_V6nnu_Ahja_id11349_1872a.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(!) Tagging Word Level NER\n",
      "65. Tagged file Tartu_Kodavere_Ranna_id14234_1857a.json\n",
      "(!) Tagging Word Level NER\n",
      "66. Tagged file V6ru_P6lva_K2hri_id21791_1851a.json\n",
      "(!) Tagging Word Level NER\n",
      "67. Tagged file Tartu_V6nnu_Ahja_id23744_1896a.json\n",
      "(!) Tagging Word Level NER\n",
      "68. Tagged file V6ru_R2pina_Kahkva_id21602_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "69. Tagged file Tartu_Kodavere_Ranna_id19767_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "70. Tagged file Tartu_Torma_Avinurme_id23582_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "71. Tagged file Tartu_R6ngu_Aakre_id2550_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "72. Tagged file J2rva_Tyri_Kirna_id24064_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "73. Tagged file Tartu_V6nnu_Ahja_id19682_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "74. Tagged file Viljandi_Paistu_Holstre_id10573_1900a.json\n",
      "(!) Tagging Word Level NER\n",
      "75. Tagged file Tartu_Kodavere_Ranna_id355_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "76. Tagged file Harju_Hageri_Kohila_id4930_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "77. Tagged file Tartu_Kodavere_Alatskivi_id23960_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "78. Tagged file L22ne_Hanila_Massu_id361_1891a.json\n",
      "(!) Tagging Word Level NER\n",
      "79. Tagged file Tartu_V6nnu_Kiidj2rve_id24846_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "80. Tagged file Saare_P8ide_Laimjala_id8967_1915a.json\n",
      "(!) Tagging Word Level NER\n",
      "81. Tagged file V6ru_Vastseliina_Misso_id20237_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "82. Tagged file Harju_Hageri_Kohila_id11175_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "83. Tagged file Harju_Hageri_Kohila_id23811_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "84. Tagged file Tartu_V6nnu_Ahja_id19411_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "85. Tagged file Tartu_Kodavere_Pala_id22605_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "86. Tagged file Harju_Hageri_Kohila_id22513_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "87. Tagged file Harju_Hageri_Kohila_id11216_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "88. Tagged file Viljandi_K6pu_Suure-K6pu_id12875_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "89. Tagged file Harju_Harju-Madise_Padise-Kloostri_id3009_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "90. Tagged file Tartu_Kodavere_Pala_id21335_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "91. Tagged file Viljandi_Pilistvere_Arussaare_id23692_1850a.json\n",
      "(!) Tagging Word Level NER\n",
      "92. Tagged file Harju_J6el2htme_J6el2htme_id1558_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "93. Tagged file Tartu_Kodavere_Ranna_id15169_1864a.json\n",
      "(!) Tagging Word Level NER\n",
      "94. Tagged file Tartu_Kambja_Vana-Prangli_id2070_1905a.json\n",
      "(!) Tagging Word Level NER\n",
      "95. Tagged file Tartu_Laiuse_Kivij2rve_id1089_1854a.json\n",
      "(!) Tagging Word Level NER\n",
      "96. Tagged file Harju_Hageri_Kohila_id2805_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "97. Tagged file Tartu_Otep22_Pyhaj2rve_id1510_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "98. Tagged file Tartu_R6ngu_Aakre_id6388_1826a.json\n",
      "(!) Tagging Word Level NER\n",
      "99. Tagged file Harju_Juuru_Juuru_id20490_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "100. Tagged file P2rnu_Halliste_Penuja_id416_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "101. Tagged file Tartu_Kodavere_Alatskivi_id2041_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "102. Tagged file L22ne_Ridala_Sinalepa_id24333_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "103. Tagged file Harju_Kose_Kose-Uuem6isa_id5292_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "104. Tagged file V6ru_R6uge_Leevi_id24491_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "105. Tagged file Harju_Rapla_Rapla_id19152_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "106. Tagged file L22ne_Pyhalepa_Kassari_id23159_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "107. Tagged file Harju_Kose_Palvere_id13236_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "108. Tagged file Tartu_Kodavere_Pala_id20761_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "109. Tagged file J2rva_Peetri_V2ike-Kareda_id20031_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "110. Tagged file Tartu_V6nnu_Ahja_id9655_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "111. Tagged file Tartu_Kodavere_Pala_id21194_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "112. Tagged file Harju_J6el2htme_J6el2htme_id8154_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "113. Tagged file Tartu_V6nnu_Ahja_id15090_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "114. Tagged file Harju_Kose_Palvere_id24675_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "115. Tagged file L22ne_Kullamaa_Piirsalu_id7871_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "116. Tagged file Tartu_Otep22_Pyhaj2rve_id4314_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "117. Tagged file Tartu_V6nnu_Ahja_id13524_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "118. Tagged file L22ne_Ridala_Sinalepa_id25163_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "119. Tagged file P2rnu_Tori_Sindi_id12783_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "120. Tagged file Tartu_N6o_Pangodi_id2812_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "121. Tagged file Tartu_V6nnu_Ahja_id17623_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "122. Tagged file Harju_Kose_Palvere_id20123_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "123. Tagged file J2rva_Tyri_Tyri-Alliku_id1866_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "124. Tagged file P2rnu_Tori_Sindi_id7721_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "125. Tagged file Tartu_V6nnu_Ahja_id16313_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "126. Tagged file Tartu_V6nnu_Ahja_id17919_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "127. Tagged file J2rva_Tyri_V22tsa_id18360_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "128. Tagged file Tartu_V6nnu_Ahja_id17535_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "129. Tagged file Harju_Rapla_Rapla_id17967_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "130. Tagged file Harju_Hageri_Kohila_id20604_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "131. Tagged file J2rva_Tyri_V22tsa_id22542_1915a.json\n",
      "(!) Tagging Word Level NER\n",
      "132. Tagged file Tartu_V6nnu_Ahja_id23913_1898a.json\n",
      "(!) Tagging Word Level NER\n",
      "133. Tagged file J2rva_Tyri_S2revere_id6037_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "134. Tagged file V6ru_R6uge_Saaluse_id9257_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "135. Tagged file Harju_Kose_Kose-Uuem6isa_id3179_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "136. Tagged file J2rva_Anna_Purdi_id23132_1870a.json\n",
      "(!) Tagging Word Level NER\n",
      "137. Tagged file Tartu_V6nnu_Ahja_id21074_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "138. Tagged file L22ne_Emmaste_Emmaste_id17875_1898a.json\n",
      "(!) Tagging Word Level NER\n",
      "139. Tagged file Tartu_V6nnu_Ahja_id18479_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "140. Tagged file P2rnu_Audru_V6lla_id5156_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "141. Tagged file Viljandi_Paistu_Holstre_id10727_1905a.json\n",
      "(!) Tagging Word Level NER\n",
      "142. Tagged file J2rva_Ambla_Ambla_id6086_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "143. Tagged file J2rva_Tyri_V22tsa_id17663_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "144. Tagged file Tartu_V6nnu_Ahja_id11306_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "145. Tagged file Tartu_V6nnu_Ahja_id11374_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "146. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id18022_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "147. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id18055_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "148. Tagged file Harju_Juuru_Kaiu_id1087_1909a.json\n",
      "(!) Tagging Word Level NER\n",
      "149. Tagged file Harju_Hageri_Kohila_id2480_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "150. Tagged file V6ru_R6uge_Saaluse_id8830_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "151. Tagged file Tartu_Torma_Avinurme_id21473_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "152. Tagged file L22ne_Kullamaa_Sooniste_id2085_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "153. Tagged file Harju_Kuusalu_Kolga_id11652_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "154. Tagged file J2rva_Ambla_Ambla_id11857_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "155. Tagged file Viljandi_K6pu_Suure-K6pu_id7180_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "156. Tagged file J2rva_Tyri_S2revere_id8880_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "157. Tagged file Tartu_V6nnu_Ahja_id21240_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "158. Tagged file Harju_Kose_Palvere_id21893_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "159. Tagged file Saare_P8ide_Laimjala_id5898_1914a.json\n",
      "(!) Tagging Word Level NER\n",
      "160. Tagged file V6ru_R2pina_Kahkva_id7463_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "161. Tagged file Tartu_V6nnu_Ahja_id14891_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "162. Tagged file Harju_Kose_Kose-Uuem6isa_id6353_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "163. Tagged file J2rva_Tyri_V22tsa_id17496_1888a.json\n",
      "(!) Tagging Word Level NER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id18745_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "165. Tagged file Tartu_V6nnu_Ahja_id18234_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "166. Tagged file Tartu_Torma_Avinurme_id20454_1871a.json\n",
      "(!) Tagging Word Level NER\n",
      "167. Tagged file Harju_Rapla_Rapla_id18671_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "168. Tagged file Tartu_V6nnu_Ahja_id18214_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "169. Tagged file Tartu_Laiuse_Kivij2rve_id1436_1856a.json\n",
      "(!) Tagging Word Level NER\n",
      "170. Tagged file Tartu_V6nnu_Ahja_id22561_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "171. Tagged file Tartu_Kodavere_Ranna_id14286_1858a.json\n",
      "(!) Tagging Word Level NER\n",
      "172. Tagged file P2rnu_Halliste_Penuja_id758_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "173. Tagged file Saare_Kihelkonna_Atla_id6893_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "174. Tagged file Harju_Hageri_Kohila_id10769_1873a.json\n",
      "(!) Tagging Word Level NER\n",
      "175. Tagged file Tartu_V6nnu_Ahja_id16318_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "176. Tagged file J2rva_Anna_Eivere_id6239_1879a.json\n",
      "(!) Tagging Word Level NER\n",
      "177. Tagged file Tartu_Kodavere_Alatskivi_id12871_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "178. Tagged file J2rva_Tyri_V22tsa_id16931_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "179. Tagged file Harju_Harju-Madise_Padise-Kloostri_id2778_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "180. Tagged file Viljandi_K6pu_Suure-K6pu_id4977_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "181. Tagged file J2rva_Tyri_S2revere_id8673_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "182. Tagged file V6ru_R2pina_Kahkva_id14118_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "183. Tagged file L22ne_Pyhalepa_K2rdla_id22309_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "184. Tagged file L22ne_Pyhalepa_K2rdla_id25096_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "185. Tagged file Tartu_Kodavere_Alatskivi_id7206_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "186. Tagged file V6ru_R2pina_Kahkva_id6348_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "187. Tagged file Tartu_N6o_Meeri_id4980_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "188. Tagged file Tartu_V6nnu_Ahja_id14731_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "189. Tagged file Tartu_Kodavere_Alatskivi_id23690_1866a.json\n",
      "(!) Tagging Word Level NER\n",
      "190. Tagged file Harju_Kose_Palvere_id17074_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "191. Tagged file Viljandi_Paistu_Holstre_id515_1843a.json\n",
      "(!) Tagging Word Level NER\n",
      "192. Tagged file Tartu_Otep22_Pyhaj2rve_id11749_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "193. Tagged file Harju_Harju-Madise_Padise-Kloostri_id3283_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "194. Tagged file Tartu_V6nnu_Ahja_id15058_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "195. Tagged file Tartu_Torma_Avinurme_id14255_1903a.json\n",
      "(!) Tagging Word Level NER\n",
      "196. Tagged file Tartu_Kodavere_Ranna_id15105_1863a.json\n",
      "(!) Tagging Word Level NER\n",
      "197. Tagged file Harju_Hageri_Kohila_id10294_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "198. Tagged file Tartu_Kodavere_Pala_id16727_1855a.json\n",
      "(!) Tagging Word Level NER\n",
      "199. Tagged file J2rva_Peetri_V2ike-Kareda_id22431_1880a.json\n",
      "(!) Tagging Word Level NER\n",
      "200. Tagged file Saare_Kihelkonna_Kotlandi_id21549_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "201. Tagged file J2rva_Tyri_V22tsa_id18782_1897a.json\n",
      "(!) Tagging Word Level NER\n",
      "202. Tagged file J2rva_Tyri_V22tsa_id16955_1887a.json\n",
      "(!) Tagging Word Level NER\n",
      "203. Tagged file J2rva_J2rva-Jaani_Einmanni_id9007_1868a.json\n",
      "(!) Tagging Word Level NER\n",
      "204. Tagged file Tartu_V6nnu_Ahja_id23568_1895a.json\n",
      "(!) Tagging Word Level NER\n",
      "205. Tagged file Tartu_Kodavere_Alatskivi_id1504_1865a.json\n",
      "(!) Tagging Word Level NER\n",
      "206. Tagged file P2rnu_P2rnu-Elisabethi_Sauga_id18104_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "207. Tagged file L22ne_Emmaste_Emmaste_id8296_1894a.json\n",
      "(!) Tagging Word Level NER\n",
      "208. Tagged file Tartu_V6nnu_Ahja_id13380_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "209. Tagged file Tartu_Otep22_Pyhaj2rve_id9556_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "210. Tagged file Tartu_V6nnu_Ahja_id22940_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "211. Tagged file Viljandi_K6pu_Suure-K6pu_id4128_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "212. Tagged file J2rva_Tyri_S2revere_id16068_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "213. Tagged file Tartu_Kodavere_Pala_id23072_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "214. Tagged file Harju_Kose_Triigi_id11698_1876a.json\n",
      "(!) Tagging Word Level NER\n",
      "215. Tagged file V6ru_P6lva_Peri_id10140_1891a.json\n",
      "(!) Tagging Word Level NER\n",
      "216. Tagged file Viljandi_K6pu_Suure-K6pu_id12747_1884a.json\n",
      "(!) Tagging Word Level NER\n",
      "217. Tagged file J2rva_Tyri_S2revere_id12373_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "218. Tagged file Viljandi_Pilistvere_K6o_id24950_1843a.json\n",
      "(!) Tagging Word Level NER\n",
      "219. Tagged file J2rva_Tyri_Kirna_id24928_1881a.json\n",
      "(!) Tagging Word Level NER\n",
      "220. Tagged file P2rnu_Audru_V6lla_id5153_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "221. Tagged file J2rva_Ambla_Uudekyla_id13881_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "222. Tagged file Tartu_Kodavere_Alatskivi_id12243_1856a.json\n",
      "(!) Tagging Word Level NER\n",
      "223. Tagged file J2rva_Tyri_S2revere_id13997_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "224. Tagged file Tartu_V6nnu_Ahja_id21303_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "225. Tagged file J2rva_Tyri_Kirna_id22874_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "226. Tagged file V6ru_Vastseliina_Misso_id23231_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "227. Tagged file Viljandi_Pilistvere_Arussaare_id23597_1845a.json\n",
      "(!) Tagging Word Level NER\n",
      "228. Tagged file J2rva_Tyri_V22tsa_id16836_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "229. Tagged file Tartu_V6nnu_Ahja_id14833_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "230. Tagged file Harju_Juuru_Juuru_id556_1877a.json\n",
      "(!) Tagging Word Level NER\n",
      "231. Tagged file Harju_Kose_Triigi_id9684_1869a.json\n",
      "(!) Tagging Word Level NER\n",
      "232. Tagged file Tartu_R6ngu_Aakre_id6568_1826a.json\n",
      "(!) Tagging Word Level NER\n",
      "233. Tagged file L22ne_Kullamaa_Kuij6e_id15492_1878a.json\n",
      "(!) Tagging Word Level NER\n",
      "234. Tagged file Harju_Jyri_Rae_id5366_1890a.json\n",
      "(!) Tagging Word Level NER\n",
      "235. Tagged file Tartu_V6nnu_Ahja_id17583_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "236. Tagged file Viljandi_Paistu_Holstre_id517_1843a.json\n",
      "(!) Tagging Word Level NER\n",
      "237. Tagged file Viljandi_Viljandi_Karula_id19358_1867a.json\n",
      "(!) Tagging Word Level NER\n",
      "238. Tagged file Tartu_Torma_Avinurme_id25282_1843a.json\n",
      "(!) Tagging Word Level NER\n",
      "239. Tagged file Harju_Hageri_Kohila_id2728_1882a.json\n",
      "(!) Tagging Word Level NER\n",
      "240. Tagged file Tartu_V6nnu_Ahja_id21069_1889a.json\n",
      "(!) Tagging Word Level NER\n",
      "241. Tagged file Tartu_V6nnu_Ahja_id15593_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "242. Tagged file Tartu_V6nnu_Ahja_id16339_1883a.json\n",
      "(!) Tagging Word Level NER\n",
      "243. Tagged file Tartu_V6nnu_Ahja_id18761_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "244. Tagged file Tartu_V6nnu_Ahja_id17568_1885a.json\n",
      "(!) Tagging Word Level NER\n",
      "245. Tagged file Viljandi_P6ltsamaa_Adavere_id19178_1892a.json\n",
      "(!) Tagging Word Level NER\n",
      "246. Tagged file Tartu_Kodavere_Kokora_id1129_1872a.json\n",
      "(!) Tagging Word Level NER\n",
      "247. Tagged file L22ne_Kullamaa_Piirsalu_id16706_1888a.json\n",
      "(!) Tagging Word Level NER\n",
      "248. Tagged file J2rva_Ambla_Ambla_id7313_1886a.json\n",
      "(!) Tagging Word Level NER\n",
      "249. Tagged file Tartu_V6nnu_Ahja_id12439_1875a.json\n",
      "(!) Tagging Word Level NER\n",
      "250. Tagged file Tartu_Kodavere_Alatskivi_id11794_1856a.json\n",
      "(!) Files tagged\n",
      "Results have been saved to models/model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features/model_gaz_loc_variants/results.txt\n",
      "(!) Model model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features/model_gaz_loc_variants trained\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_gaz_loc_variants')\n",
    "\n",
    "train_model(path, tag_wordner = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

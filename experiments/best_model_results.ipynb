{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "from modules.preprocessing_protocols import preprocess_text\n",
    "from modules.results_extraction import extract_results, results_by_subdistribution,\\\n",
    "                                    results_by_named_entity, confusion_matrix\n",
    "from contemporary_ner_training.conll_ner_importer import conll_to_ner_labelling  \n",
    "from estnltk import Text\n",
    "from estnltk.taggers import NerTagger\n",
    "from estnltk.taggers import WordLevelNerTagger\n",
    "from estnltk.converters import text_to_json\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.layer_operations import flatten\n",
    "\n",
    "from estnltk.taggers.estner.ner_trainer import NerTrainer\n",
    "from estnltk.taggers.estner.model_storage_util import ModelStorageUtil\n",
    "\n",
    "from estnltk.taggers import VabamorfCorpusTagger\n",
    "vm_corpus_tagger = VabamorfCorpusTagger()\n",
    "\n",
    "import sklearn_crfsuite\n",
    "import pandas as pd\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "files_not_working = ['J2rva_Tyri_V22tsa_id22177_1911a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id18538_1894a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id22155_1911a.json', \\\n",
    "                     'Saare_Kihelkonna_Kotlandi_id18845_1865a.json', \\\n",
    "                     'P2rnu_Halliste_Abja_id257_1844a.json', \\\n",
    "                     'Saare_Kaarma_Loona_id7575_1899a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id22266_1913a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id22178_1912a.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_results(model_dir, files):\n",
    "    gold_ner = []\n",
    "    test_ner = []\n",
    "\n",
    "    for file in [key for key, value in files.items()]:\n",
    "        appendable_gold_ner = []\n",
    "        appendable_test_ner = []\n",
    "\n",
    "        if not file.endswith(\".json\") or file in files_not_working:\n",
    "            continue\n",
    "        else:\n",
    "            with open(os.path.join('models', model_dir, 'vallakohtufailid-trained-nertagger', file), 'r', encoding='UTF-8') as f_test, \\\n",
    "                 open(os.path.join('..', 'data', 'vallakohtufailid-json-flattened', file), 'r', encoding='UTF-8') as f_gold:\n",
    "                    test_import = json_to_text(f_test.read())\n",
    "                    gold_import = json_to_text(f_gold.read())\n",
    "\n",
    "                    # The commented part is needed for word-level-ner.\n",
    "                    '''\n",
    "                    for i in range(len(gold_import['flat_gold_wordner'])):\n",
    "                        tag = gold_import['flat_gold_wordner'][i].nertag[0]\n",
    "                        gold.append(tag)\n",
    "                    for i in range(len(test_import['flat_wordner'])):\n",
    "                        tag = test_import['flat_wordner'][i].nertag[0]\n",
    "                        test.append(tag)\n",
    "                    '''\n",
    "\n",
    "                    for i in range(len(gold_import['gold_ner'])):\n",
    "                        ner = gold_import['gold_ner'][i]\n",
    "                        label = ner.nertag\n",
    "                        start = int(ner.start)\n",
    "                        end = int(ner.end)\n",
    "                        appendable_gold_ner.append({\"label\": label, \"start\": start, \"end\": end})\n",
    "\n",
    "                    for i in range(len(test_import['flat_ner'])):\n",
    "                        ner = test_import['flat_ner'][i]\n",
    "                        label = ner.nertag[0]\n",
    "                        start = int(ner.start)\n",
    "                        end = int(ner.end)\n",
    "                        appendable_test_ner.append({\"label\": label, \"start\": start, \"end\": end})\n",
    "\n",
    "        gold_ner.append(appendable_gold_ner)\n",
    "        test_ner.append(appendable_test_ner)\n",
    "    evaluator = Evaluator(gold_ner, test_ner, tags=['ORG', 'PER', 'MISC', 'LOC', 'LOC_ORG'])\n",
    "    results, results_per_tag = evaluator.evaluate()\n",
    "    all_results = (results, results_per_tag)\n",
    "    \n",
    "    print(\"Tulemuste ammutamine on lõpetatud.\")\n",
    "    \n",
    "    with open(os.path.join('models', model_dir, 'results.txt'), 'w+') as results_file:\n",
    "        results_file.write(json.dumps(all_results))\n",
    "    \n",
    "    return (results, results_per_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_by_named_entity(results_json):\n",
    "    df = dict()\n",
    "    totals = dict()\n",
    "    by_kind = dict()\n",
    "\n",
    "    for key in list(results_json[1].keys()):\n",
    "        correct_all = 0\n",
    "        actual_all = 0\n",
    "        possible_all = 0\n",
    "        correct = results_json[1][str(key)]['strict']['correct']\n",
    "        correct_all += correct\n",
    "        actual = results_json[1][str(key)]['strict']['actual']\n",
    "        actual_all += actual\n",
    "        possible = results_json[1][str(key)]['strict']['possible']\n",
    "        possible_all += possible\n",
    "\n",
    "        precision = (correct / actual)\n",
    "        recall = (correct / possible)\n",
    "        f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "        precisionname = str(key) + \"_precision\"\n",
    "        recallname = str(key) + \"_recall\"\n",
    "        f1scorename = str(key) + \"_f1score\"\n",
    "\n",
    "        by_kind[precisionname] = precision\n",
    "        by_kind[recallname] = recall\n",
    "        by_kind[f1scorename] = f1\n",
    "\n",
    "    df['Total'] = by_kind\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vabamorfcorpustagger = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "\n",
    "with open(os.path.join('..', 'data', 'divided_corpus.txt'), 'r', encoding = 'UTF-8') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "for fileName in txt:\n",
    "    file, subdistribution = fileName.split(\":\")\n",
    "    files[file] = subdistribution.rstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_texts(filenames):\n",
    "    print(\"(!) Valmistan ette treenimistekste\")\n",
    "    \n",
    "    start = time.time()\n",
    "    training_texts = []\n",
    "    for filename in filenames:\n",
    "        with open(os.path.join('..', 'data', 'vallakohtufailid-json-flattened', filename), 'r', encoding='UTF-8') as file:\n",
    "            if filename in files_not_working:\n",
    "                continue\n",
    "            else:\n",
    "                tagged_text = preprocess_text(json_to_text(file.read()))\n",
    "                if use_vabamorfcorpustagger:\n",
    "                    tagged_text.pop_layer('morph_analysis')\n",
    "                    vm_corpus_tagger.tag([tagged_text])\n",
    "                training_texts.append(tagged_text)\n",
    "    print(f\"(!) Treenimistekstid ette valmistatud {time.time() - start} sekundiga\")\n",
    "    return training_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nertagger(training_texts, new_model_dir):\n",
    "    print(\"(!) Treenin NerTaggerit\")\n",
    "    start = time.time()\n",
    "    \n",
    "    modelUtil = ModelStorageUtil( new_model_dir )\n",
    "    nersettings = modelUtil.load_settings()\n",
    "    trainer = NerTrainer(nersettings)\n",
    "    trainer.train( training_texts, layer='gold_wordner', model_dir=new_model_dir )\n",
    "    print(f\"(!) NerTagger treenitud {time.time() - start} sekundiga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_files(model_dir, testing_files, use_vabamorfcorpustagger):\n",
    "    removed_layers = ['sentences', 'morph_analysis', 'compound_tokens', 'ner', 'words', 'tokens']\n",
    "    nertagger = NerTagger(model_dir)\n",
    "    \n",
    "    print(\"(!) Märgendan\")\n",
    "    start = time.time()\n",
    "    iterator = 1\n",
    "    for test_file in testing_files:\n",
    "        with open(find(test_file.replace(\".json\", \".txt\"), os.path.join('..', 'data', 'vallakohtufailid')), 'r', encoding='UTF-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        if test_file == \"Tartu_V6nnu_Ahja_id3502_1882a.json\":\n",
    "            text = text.replace('..', '. .')\n",
    "        text = preprocess_text(Text(text))\n",
    "\n",
    "        if use_vabamorfcorpustagger or \"vabamorf\" in model_dir:\n",
    "            text.pop_layer('morph_analysis')\n",
    "            text = [text]\n",
    "            vm_corpus_tagger.tag( text )\n",
    "            text = text[0]\n",
    "        nertagger.tag(text)\n",
    "        text.add_layer(flatten(text['ner'], 'flat_ner'))\n",
    "\n",
    "        for x in removed_layers:\n",
    "            text.pop_layer(x)\n",
    "\n",
    "        path = os.path.join(model_dir, 'vallakohtufailid-trained-nertagger')\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "            \n",
    "        text_to_json(text, file=os.path.join(model_dir, 'vallakohtufailid-trained-nertagger', test_file))\n",
    "        \n",
    "        print(f'{iterator}. Märgendatud fail {test_file}')\n",
    "        iterator += 1\n",
    "    print(f\"(!) Failid märgendatud {time.time() - start} sekundiga\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = {}\n",
    "\n",
    "with open(os.path.join('..', 'data', 'corpus_subdistribution_without_hand_tagged.txt'), 'r', encoding = 'UTF-8') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "for fileName in txt:\n",
    "    file, subdistribution = fileName.split(\":\")\n",
    "    test_files[file] = subdistribution.rstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_directory):\n",
    "\n",
    "    # Get the filenames to be trained on from the files dictionary\n",
    "    filenames = [key for key, value in files.items()]\n",
    "\n",
    "    # Create training_texts from the aforementioned filenames\n",
    "    training_texts = create_training_texts(filenames)\n",
    "\n",
    "    # Set up the trainer and training\n",
    "    new_model_dir = os.path.join('models', model_directory)\n",
    "    train_nertagger(training_texts, new_model_dir)\n",
    "\n",
    "    # Set up the new trained nertagger and defining layers to be removed later on\n",
    "    tagger = NerTagger(model_dir = new_model_dir)\n",
    "    #print(tagger.nersettings)\n",
    "    # Tag the files using the new nertagger\n",
    "    testing_files = [key for key, value in test_files.items()]\n",
    "    tag_files(new_model_dir, testing_files, use_vabamorfcorpustagger)\n",
    "            \n",
    "    # Get results of model\n",
    "    extract_results(model_directory, test_files)\n",
    "    \n",
    "    print(f\"(!) Mudel {model_directory} treenitud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tulemuste ammutamine on lõpetatud.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'ent_type': {'correct': 3894,\n",
       "   'incorrect': 110,\n",
       "   'partial': 0,\n",
       "   'missed': 235,\n",
       "   'spurious': 86,\n",
       "   'possible': 4239,\n",
       "   'actual': 4090,\n",
       "   'precision': 0.952078239608802,\n",
       "   'recall': 0.9186128803963199,\n",
       "   'f1': 0.935046224036499},\n",
       "  'partial': {'correct': 3833,\n",
       "   'incorrect': 0,\n",
       "   'partial': 171,\n",
       "   'missed': 235,\n",
       "   'spurious': 86,\n",
       "   'possible': 4239,\n",
       "   'actual': 4090,\n",
       "   'precision': 0.9580684596577017,\n",
       "   'recall': 0.9243925454116537,\n",
       "   'f1': 0.9409292832272783},\n",
       "  'strict': {'correct': 3782,\n",
       "   'incorrect': 222,\n",
       "   'partial': 0,\n",
       "   'missed': 235,\n",
       "   'spurious': 86,\n",
       "   'possible': 4239,\n",
       "   'actual': 4090,\n",
       "   'precision': 0.9246943765281174,\n",
       "   'recall': 0.8921915546119368,\n",
       "   'f1': 0.9081522391643656},\n",
       "  'exact': {'correct': 3833,\n",
       "   'incorrect': 171,\n",
       "   'partial': 0,\n",
       "   'missed': 235,\n",
       "   'spurious': 86,\n",
       "   'possible': 4239,\n",
       "   'actual': 4090,\n",
       "   'precision': 0.9371638141809291,\n",
       "   'recall': 0.9042226940316113,\n",
       "   'f1': 0.9203986072757834}},\n",
       " {'ORG': {'ent_type': {'correct': 57,\n",
       "    'incorrect': 11,\n",
       "    'partial': 0,\n",
       "    'missed': 5,\n",
       "    'spurious': 0,\n",
       "    'possible': 73,\n",
       "    'actual': 68,\n",
       "    'precision': 0.8382352941176471,\n",
       "    'recall': 0.7808219178082192,\n",
       "    'f1': 0.8085106382978724},\n",
       "   'partial': {'correct': 59,\n",
       "    'incorrect': 0,\n",
       "    'partial': 9,\n",
       "    'missed': 5,\n",
       "    'spurious': 0,\n",
       "    'possible': 73,\n",
       "    'actual': 68,\n",
       "    'precision': 0.9338235294117647,\n",
       "    'recall': 0.8698630136986302,\n",
       "    'f1': 0.9007092198581561},\n",
       "   'strict': {'correct': 57,\n",
       "    'incorrect': 11,\n",
       "    'partial': 0,\n",
       "    'missed': 5,\n",
       "    'spurious': 0,\n",
       "    'possible': 73,\n",
       "    'actual': 68,\n",
       "    'precision': 0.8382352941176471,\n",
       "    'recall': 0.7808219178082192,\n",
       "    'f1': 0.8085106382978724},\n",
       "   'exact': {'correct': 59,\n",
       "    'incorrect': 9,\n",
       "    'partial': 0,\n",
       "    'missed': 5,\n",
       "    'spurious': 0,\n",
       "    'possible': 73,\n",
       "    'actual': 68,\n",
       "    'precision': 0.8676470588235294,\n",
       "    'recall': 0.8082191780821918,\n",
       "    'f1': 0.8368794326241135}},\n",
       "  'PER': {'ent_type': {'correct': 3441,\n",
       "    'incorrect': 17,\n",
       "    'partial': 0,\n",
       "    'missed': 121,\n",
       "    'spurious': 57,\n",
       "    'possible': 3579,\n",
       "    'actual': 3515,\n",
       "    'precision': 0.9789473684210527,\n",
       "    'recall': 0.961441743503772,\n",
       "    'f1': 0.9701155906399774},\n",
       "   'partial': {'correct': 3357,\n",
       "    'incorrect': 0,\n",
       "    'partial': 101,\n",
       "    'missed': 121,\n",
       "    'spurious': 57,\n",
       "    'possible': 3579,\n",
       "    'actual': 3515,\n",
       "    'precision': 0.9694167852062588,\n",
       "    'recall': 0.9520815870354847,\n",
       "    'f1': 0.9606709895686495},\n",
       "   'strict': {'correct': 3352,\n",
       "    'incorrect': 106,\n",
       "    'partial': 0,\n",
       "    'missed': 121,\n",
       "    'spurious': 57,\n",
       "    'possible': 3579,\n",
       "    'actual': 3515,\n",
       "    'precision': 0.9536273115220484,\n",
       "    'recall': 0.9365744621402626,\n",
       "    'f1': 0.9450239639131661},\n",
       "   'exact': {'correct': 3357,\n",
       "    'incorrect': 101,\n",
       "    'partial': 0,\n",
       "    'missed': 121,\n",
       "    'spurious': 57,\n",
       "    'possible': 3579,\n",
       "    'actual': 3515,\n",
       "    'precision': 0.955049786628734,\n",
       "    'recall': 0.9379715004191115,\n",
       "    'f1': 0.9464336058641104}},\n",
       "  'MISC': {'ent_type': {'correct': 27,\n",
       "    'incorrect': 8,\n",
       "    'partial': 0,\n",
       "    'missed': 10,\n",
       "    'spurious': 3,\n",
       "    'possible': 45,\n",
       "    'actual': 38,\n",
       "    'precision': 0.7105263157894737,\n",
       "    'recall': 0.6,\n",
       "    'f1': 0.6506024096385543},\n",
       "   'partial': {'correct': 31,\n",
       "    'incorrect': 0,\n",
       "    'partial': 4,\n",
       "    'missed': 10,\n",
       "    'spurious': 3,\n",
       "    'possible': 45,\n",
       "    'actual': 38,\n",
       "    'precision': 0.868421052631579,\n",
       "    'recall': 0.7333333333333333,\n",
       "    'f1': 0.7951807228915663},\n",
       "   'strict': {'correct': 26,\n",
       "    'incorrect': 9,\n",
       "    'partial': 0,\n",
       "    'missed': 10,\n",
       "    'spurious': 3,\n",
       "    'possible': 45,\n",
       "    'actual': 38,\n",
       "    'precision': 0.6842105263157895,\n",
       "    'recall': 0.5777777777777777,\n",
       "    'f1': 0.6265060240963854},\n",
       "   'exact': {'correct': 31,\n",
       "    'incorrect': 4,\n",
       "    'partial': 0,\n",
       "    'missed': 10,\n",
       "    'spurious': 3,\n",
       "    'possible': 45,\n",
       "    'actual': 38,\n",
       "    'precision': 0.8157894736842105,\n",
       "    'recall': 0.6888888888888889,\n",
       "    'f1': 0.746987951807229}},\n",
       "  'LOC': {'ent_type': {'correct': 74,\n",
       "    'incorrect': 38,\n",
       "    'partial': 0,\n",
       "    'missed': 33,\n",
       "    'spurious': 6,\n",
       "    'possible': 145,\n",
       "    'actual': 118,\n",
       "    'precision': 0.6271186440677966,\n",
       "    'recall': 0.5103448275862069,\n",
       "    'f1': 0.5627376425855514},\n",
       "   'partial': {'correct': 94,\n",
       "    'incorrect': 0,\n",
       "    'partial': 18,\n",
       "    'missed': 33,\n",
       "    'spurious': 6,\n",
       "    'possible': 145,\n",
       "    'actual': 118,\n",
       "    'precision': 0.8728813559322034,\n",
       "    'recall': 0.7103448275862069,\n",
       "    'f1': 0.7832699619771863},\n",
       "   'strict': {'correct': 71,\n",
       "    'incorrect': 41,\n",
       "    'partial': 0,\n",
       "    'missed': 33,\n",
       "    'spurious': 6,\n",
       "    'possible': 145,\n",
       "    'actual': 118,\n",
       "    'precision': 0.6016949152542372,\n",
       "    'recall': 0.4896551724137931,\n",
       "    'f1': 0.5399239543726235},\n",
       "   'exact': {'correct': 94,\n",
       "    'incorrect': 18,\n",
       "    'partial': 0,\n",
       "    'missed': 33,\n",
       "    'spurious': 6,\n",
       "    'possible': 145,\n",
       "    'actual': 118,\n",
       "    'precision': 0.7966101694915254,\n",
       "    'recall': 0.6482758620689655,\n",
       "    'f1': 0.7148288973384029}},\n",
       "  'LOC_ORG': {'ent_type': {'correct': 295,\n",
       "    'incorrect': 36,\n",
       "    'partial': 0,\n",
       "    'missed': 66,\n",
       "    'spurious': 20,\n",
       "    'possible': 397,\n",
       "    'actual': 351,\n",
       "    'precision': 0.8404558404558404,\n",
       "    'recall': 0.743073047858942,\n",
       "    'f1': 0.7887700534759358},\n",
       "   'partial': {'correct': 292,\n",
       "    'incorrect': 0,\n",
       "    'partial': 39,\n",
       "    'missed': 66,\n",
       "    'spurious': 20,\n",
       "    'possible': 397,\n",
       "    'actual': 351,\n",
       "    'precision': 0.8874643874643875,\n",
       "    'recall': 0.7846347607052897,\n",
       "    'f1': 0.8328877005347594},\n",
       "   'strict': {'correct': 276,\n",
       "    'incorrect': 55,\n",
       "    'partial': 0,\n",
       "    'missed': 66,\n",
       "    'spurious': 20,\n",
       "    'possible': 397,\n",
       "    'actual': 351,\n",
       "    'precision': 0.7863247863247863,\n",
       "    'recall': 0.6952141057934509,\n",
       "    'f1': 0.7379679144385027},\n",
       "   'exact': {'correct': 292,\n",
       "    'incorrect': 39,\n",
       "    'partial': 0,\n",
       "    'missed': 66,\n",
       "    'spurious': 20,\n",
       "    'possible': 397,\n",
       "    'actual': 351,\n",
       "    'precision': 0.8319088319088319,\n",
       "    'recall': 0.7355163727959698,\n",
       "    'f1': 0.7807486631016043}}})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_gaz_loc_variants_best'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict()\n",
    "with open(os.path.join('models','model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_gaz_loc_variants_best', 'results.txt'), 'r', encoding='UTF-8') as in_f:\n",
    "    results_json = json.loads(in_f.read())\n",
    "\n",
    "correct = results_json[0]['strict']['correct']\n",
    "actual = results_json[0]['strict']['actual']\n",
    "possible = results_json[0]['strict']['possible']\n",
    "\n",
    "precision = (correct / actual)\n",
    "recall = (correct / possible)\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "df['model_gaz_loc_variants'] = [precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('models','model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', 'model_gaz_loc_variants_best', 'results.txt'), 'r', encoding='UTF-8') as in_f:\n",
    "    results_json = json.loads(in_f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC_ORG_f1score</th>\n",
       "      <td>0.737968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC_ORG_precision</th>\n",
       "      <td>0.786325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC_ORG_recall</th>\n",
       "      <td>0.695214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC_f1score</th>\n",
       "      <td>0.539924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC_precision</th>\n",
       "      <td>0.601695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC_recall</th>\n",
       "      <td>0.489655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC_f1score</th>\n",
       "      <td>0.626506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC_precision</th>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC_recall</th>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG_f1score</th>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG_precision</th>\n",
       "      <td>0.838235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG_recall</th>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER_f1score</th>\n",
       "      <td>0.945024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER_precision</th>\n",
       "      <td>0.953627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER_recall</th>\n",
       "      <td>0.936574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Total\n",
       "LOC_ORG_f1score    0.737968\n",
       "LOC_ORG_precision  0.786325\n",
       "LOC_ORG_recall     0.695214\n",
       "LOC_f1score        0.539924\n",
       "LOC_precision      0.601695\n",
       "LOC_recall         0.489655\n",
       "MISC_f1score       0.626506\n",
       "MISC_precision     0.684211\n",
       "MISC_recall        0.577778\n",
       "ORG_f1score        0.808511\n",
       "ORG_precision      0.838235\n",
       "ORG_recall         0.780822\n",
       "PER_f1score        0.945024\n",
       "PER_precision      0.953627\n",
       "PER_recall         0.936574"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results_by_named_entity(results_json)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_gaz_loc_variants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.924694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.892192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.908152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_gaz_loc_variants\n",
       "Precision                0.924694\n",
       "Recall                   0.892192\n",
       "F1                       0.908152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(df, index=['Precision', 'Recall', 'F1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

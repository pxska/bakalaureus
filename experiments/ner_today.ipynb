{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import sklearn_crfsuite\n",
    "import re\n",
    "import nereval\n",
    "import pandas as pd\n",
    "\n",
    "from estnltk import Text\n",
    "from estnltk.taggers import NerTagger\n",
    "from estnltk.taggers import WordLevelNerTagger\n",
    "from estnltk.converters import text_to_json\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.layer_operations import flatten\n",
    "from sklearn.metrics import classification_report\n",
    "from estnltk.taggers import Retagger\n",
    "from estnltk.taggers import CompoundTokenTagger\n",
    "from sklearn_crfsuite import metrics\n",
    "from estnltk.converters import json_to_text\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "\n",
    "nertagger = NerTagger()\n",
    "word_level_ner = WordLevelNerTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenSplitter( Retagger ):\n",
    "    \"\"\"Splits tokens into smaller tokens based on regular expression patterns.\"\"\" \n",
    "    conf_param = ['patterns', 'break_group_name']\n",
    "    \n",
    "    def __init__(self, patterns, break_group_name:str='end'):\n",
    "        # Set input/output layers\n",
    "        self.input_layers = ['tokens']\n",
    "        self.output_layer = 'tokens'\n",
    "        self.output_attributes = ()\n",
    "        # Set other configuration parameters\n",
    "        if not (isinstance(break_group_name, str) and len(break_group_name) > 0):\n",
    "            raise TypeError('(!) break_group_name should be a non-empty string.')\n",
    "        self.break_group_name = break_group_name\n",
    "        # Assert that all patterns are regular expressions in the valid format\n",
    "        if not isinstance(patterns, list):\n",
    "            raise TypeError('(!) patterns should be a list of compiled regular expressions.')\n",
    "        # TODO: we use an adhoc way to verify that patterns are regular expressions \n",
    "        #       because there seems to be no common way of doing it both in py35 \n",
    "        #       and py36\n",
    "        for pat in patterns:\n",
    "            # Check for the existence of methods/attributes\n",
    "            has_match   = callable(getattr(pat, \"match\", None))\n",
    "            has_search  = callable(getattr(pat, \"search\", None))\n",
    "            has_pattern = getattr(pat, \"pattern\", None) is not None\n",
    "            for (k,v) in (('method match()',has_match),\\\n",
    "                          ('method search()',has_search),\\\n",
    "                          ('attribute pattern',has_pattern)):\n",
    "                if v is False:\n",
    "                    raise TypeError('(!) Unexpected regex pattern: {!r} is missing {}.'.format(pat, k))\n",
    "            symbolic_groups = pat.groupindex\n",
    "            if self.break_group_name not in symbolic_groups.keys():\n",
    "                raise TypeError('(!) Pattern {!r} is missing symbolic group named {!r}.'.format(pat, self.break_group_name))\n",
    "        self.patterns = patterns\n",
    "\n",
    "    def _change_layer(self, text, layers, status):\n",
    "        # Get changeble layer\n",
    "        changeble_layer = layers[self.output_layer]\n",
    "        # Iterate over tokens\n",
    "        add_spans    = []\n",
    "        remove_spans = []\n",
    "        for span in changeble_layer:\n",
    "            token_str = text.text[span.start:span.end]\n",
    "            for pat in self.patterns:\n",
    "                m = pat.search(token_str)\n",
    "                if m:\n",
    "                    break_group_end = m.end( self.break_group_name )\n",
    "                    if break_group_end > -1 and \\\n",
    "                       break_group_end > 0  and \\\n",
    "                       break_group_end < len(token_str):\n",
    "                        # Make the split\n",
    "                        add_spans.append( (span.start, span.start+break_group_end) )\n",
    "                        add_spans.append( (span.start+break_group_end, span.end) )\n",
    "                        remove_spans.append( span )\n",
    "                        # Once a token has been split, then break and move on to \n",
    "                        # the next token ...\n",
    "                        break\n",
    "        if add_spans:\n",
    "            assert len(remove_spans) > 0\n",
    "            for old_span in remove_spans:\n",
    "                changeble_layer.remove_span( old_span )\n",
    "            for new_span in add_spans:\n",
    "                changeble_layer.add_annotation( new_span )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = TokenSplitter(patterns=[re.compile(r'(?P<end>[A-ZÕÄÖÜ]{1}\\w+)[A-ZÕÄÖÜ]{1}\\w+'),\\\n",
    "                                         re.compile(r'(?P<end>Piebenomme)metsawaht'),\\\n",
    "                                         re.compile(r'(?P<end>maa)peal'),\\\n",
    "                                         re.compile(r'(?P<end>reppi)käest'),\\\n",
    "                                         re.compile(r'(?P<end>Kiidjerwelt)J'),\\\n",
    "                                         re.compile(r'(?P<end>Ameljanow)Persitski'),\\\n",
    "                                         re.compile(r'(?P<end>mõistmas)Mihkel'),\\\n",
    "                                         re.compile(r'(?P<end>tema)Käkk'),\\\n",
    "                                         re.compile(r'(?P<end>Ahjawalla)liikmed'),\\\n",
    "                                         re.compile(r'(?P<end>kohtumees)A'),\\\n",
    "                                         re.compile(r'(?P<end>Pechmann)x'),\\\n",
    "                                         re.compile(r'(?P<end>pölli)Anni'),\\\n",
    "                                         re.compile(r'(?P<end>külla)Rauba'),\\\n",
    "                                         re.compile(r'(?P<end>kohtowannem)Jaak'),\\\n",
    "                                         re.compile(r'(?P<end>rannast)Leno'),\\\n",
    "                                         re.compile(r'(?P<end>wallast)Kiiwita'),\\\n",
    "                                         re.compile(r'(?P<end>wallas)Kristjan'),\\\n",
    "                                         re.compile(r'(?P<end>Pedoson)rahul'),\\\n",
    "                                         re.compile(r'(?P<end>pere)Jaan'),\\\n",
    "                                         re.compile(r'(?P<end>kohtu)poolest'),\\\n",
    "                                         re.compile(r'(?P<end>Kurrista)kaudo'),\\\n",
    "                                         re.compile(r'(?P<end>mölder)Gottlieb'),\\\n",
    "                                         re.compile(r'(?P<end>wöörmündri)Jaan'),\\\n",
    "                                         re.compile(r'(?P<end>Oinas)ja'),\\\n",
    "                                         re.compile(r'(?P<end>ette)Leenu'),\\\n",
    "                                         re.compile(r'(?P<end>Tommingas)peab'),\\\n",
    "                                         re.compile(r'(?P<end>wäljaja)Kotlep'),\\\n",
    "                                         re.compile(r'(?P<end>pea)A'),\\\n",
    "                                         re.compile(r'(?P<end>talumees)Nikolai')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files from the distributed corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open(os.path.join('..', 'data', 'corpus_subdistribution_without_hand_tagged.txt'), 'r', encoding='UTF-8') as f:\\n    txt = f.readlines()\\n\\nfor filename in txt:\\n    file, subdistribution = filename.split(':')\\n    files[file] = subdistribution.rstrip('\\n')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = {}\n",
    "\n",
    "with open(os.path.join('..', 'data', 'divided_corpus.txt'), 'r', encoding = 'UTF-8') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "for fileName in txt:\n",
    "    file, subdistribution = fileName.split(':')\n",
    "    files[file] = subdistribution.rstrip('\\n')\n",
    "\n",
    "'''\n",
    "with open(os.path.join('..', 'data', 'corpus_subdistribution_without_hand_tagged.txt'), 'r', encoding='UTF-8') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "for filename in txt:\n",
    "    file, subdistribution = filename.split(':')\n",
    "    files[file] = subdistribution.rstrip('\\n')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make `ner` and `wordner` layers from goldstandard files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove layers to keep file sizes low\n",
    "removed_layers = ['sentences', 'morph_analysis', 'compound_tokens', 'ner', 'words', 'tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with open(os.path.join('..', 'data', 'vallakohtufailid-json-flattened', file), 'r', encoding='UTF-8') as f:\n",
    "        text = json_to_text(f.read()).text\n",
    "        \n",
    "        if file == \"Tartu_V6nnu_Ahja_id3502_1882a.json\":\n",
    "            text.replace('..', '. .')\n",
    "            \n",
    "        text = Text(text)\n",
    "        text.tag_layer(['tokens'])\n",
    "        token_splitter.retag(text)\n",
    "        CompoundTokenTagger(tag_initials = False, tag_abbreviations = False, tag_hyphenations = False).tag(text)\n",
    "        text.tag_layer('morph_analysis')\n",
    "        \n",
    "        nertagger.tag(text)\n",
    "        text.add_layer(flatten(text['ner'], 'flat_ner'))\n",
    "        \n",
    "        word_level_ner.tag(text)\n",
    "        text.add_layer(flatten(text['wordner'], 'flat_wordner'))\n",
    "        \n",
    "        for x in removed_layers:\n",
    "            text.pop_layer(x)\n",
    "        \n",
    "        text_to_json(text, file=os.path.join('..', 'data', 'vallakohtufailid_nertagger_baseline', file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_not_working = [\n",
    "                    'J2rva_Tyri_V22tsa_id22177_1911a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id18538_1894a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id22155_1911a.json', \\\n",
    "                     'Saare_Kihelkonna_Kotlandi_id18845_1865a.json', \\\n",
    "                     'P2rnu_Halliste_Abja_id257_1844a.json', \\\n",
    "                     'Saare_Kaarma_Loona_id7575_1899a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id22178_1912a.json', \\\n",
    "                     'J2rva_Tyri_V22tsa_id22266_1913a.json'\n",
    "                    ]\n",
    "# These files don't work because the protocols are written in a different language, which the goldstandard didn't\n",
    "# recognise, hence have no goldstandard tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#LOC and ORG separately\n",
    "gold_ner_loc = []\n",
    "gold_ner_org = []\n",
    "\n",
    "#LOC_ORG\n",
    "gold = []\n",
    "test = []\n",
    "gold_ner = []\n",
    "test_ner = []\n",
    "\n",
    "for file in sorted(os.listdir(os.path.join('..', 'data', 'vallakohtufailid_nertagger_baseline'))):\n",
    "    appendable_gold_ner = []\n",
    "    appendable_test_ner = []\n",
    "    appendable_gold_ner_loc = []\n",
    "    appendable_gold_ner_org = []\n",
    "    \n",
    "    if file.endswith(\".json\"):\n",
    "        if file in files_not_working:\n",
    "            continue\n",
    "        else:\n",
    "            with open(os.path.join('..', 'data', 'vallakohtufailid_nertagger_baseline', file), 'r', encoding='UTF-8') as f_test, \\\n",
    "                open(os.path.join('..', 'data', 'vallakohtufailid-json-flattened', file), 'r', encoding='UTF-8') as f_gold:\n",
    "                    test_import = json_to_text(f_test.read())\n",
    "                    gold_import = json_to_text(f_gold.read())\n",
    "                    \n",
    "            if len(gold_import['gold_wordner']) != len(test_import['flat_wordner']):\n",
    "                print(file, len(gold_import['gold_wordner']), len(test_import['flat_wordner']))\n",
    "            \n",
    "            for i in range(len(gold_import['gold_wordner'])):\n",
    "                tag = gold_import['gold_wordner'][i].nertag\n",
    "                gold.append(tag)\n",
    "            for i in range(len(test_import['flat_wordner'])):\n",
    "                tag = test_import['flat_wordner'][i].nertag\n",
    "                test.append(tag)\n",
    "\n",
    "            for i in range(len(gold_import['gold_ner'])):\n",
    "                ner = gold_import['gold_ner'][i]\n",
    "                label = ner.nertag\n",
    "                start = int(ner.start)\n",
    "                end = int(ner.end)\n",
    "                if label == 'LOC_ORG':\n",
    "                    appendable_gold_ner.append({\"label\": label, \"start\": start, \"end\": end})\n",
    "                    appendable_gold_ner_loc.append({\"label\": 'LOC', \"start\": start, \"end\": end})\n",
    "                    appendable_gold_ner_org.append({\"label\": 'ORG', \"start\": start, \"end\": end})\n",
    "                else:\n",
    "                    appendable_gold_ner.append({\"label\": label, \"start\": start, \"end\": end})\n",
    "                    appendable_gold_ner_loc.append({\"label\": label, \"start\": start, \"end\": end})\n",
    "                    appendable_gold_ner_org.append({\"label\": label, \"start\": start, \"end\": end})\n",
    "\n",
    "            for i in range(len(test_import['flat_ner'])):\n",
    "                ner = test_import['flat_ner'][i]\n",
    "                label = ner.nertag[0]\n",
    "                start = int(ner.start)\n",
    "                end = int(ner.end)\n",
    "                appendable_test_ner.append({\"label\": label, \"start\": start, \"end\": end})\n",
    "\n",
    "    gold_ner.append(appendable_gold_ner)\n",
    "    gold_ner_loc.append(appendable_gold_ner_loc)\n",
    "    gold_ner_org.append(appendable_gold_ner_org)\n",
    "    test_ner.append(appendable_test_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_loc = []\n",
    "gold_org = []\n",
    "for item in gold:\n",
    "    if item == \"B-LOC_ORG\":\n",
    "        gold_loc.append(\"B-LOC\")\n",
    "        gold_org.append(\"B-ORG\")\n",
    "    elif item == \"I-LOC_ORG\":\n",
    "        gold_loc.append(\"I-LOC\")\n",
    "        gold_org.append(\"B-ORG\")\n",
    "    else:\n",
    "        gold_loc.append(item)\n",
    "        gold_org.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_locorg = set(gold)\n",
    "labels_loc = set(gold_loc)\n",
    "labels_org = set(gold_org)\n",
    "\n",
    "sorted_labels_locorg = sorted(labels_locorg,key=lambda name: (name[1:], name[0]))\n",
    "sorted_labels_loc = sorted(labels_loc,key=lambda name: (name[1:], name[0]))\n",
    "sorted_labels_org = sorted(labels_org,key=lambda name: (name[1:], name[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for LOC_ORG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.96      0.98      0.97    270018\n",
      "       B-LOC       0.16      0.27      0.20      1008\n",
      "       I-LOC       0.04      0.02      0.03       395\n",
      "   B-LOC_ORG       0.00      0.00      0.00      2733\n",
      "   I-LOC_ORG       0.00      0.00      0.00      1592\n",
      "      B-MISC       0.00      0.00      0.00       254\n",
      "      I-MISC       0.00      0.00      0.00       815\n",
      "       B-ORG       0.03      0.29      0.06       419\n",
      "       I-ORG       0.05      0.19      0.08       974\n",
      "       B-PER       0.79      0.73      0.76     23126\n",
      "       I-PER       0.85      0.67      0.75     21943\n",
      "\n",
      "    accuracy                           0.91    323277\n",
      "   macro avg       0.26      0.29      0.26    323277\n",
      "weighted avg       0.92      0.91      0.91    323277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gold, test, labels=sorted_labels_locorg, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(gold_ner, test_ner, tags=['ORG', 'PER', 'MISC', 'LOC', 'LOC_ORG'])\n",
    "results, results_per_tag = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_type</th>\n",
       "      <th>partial</th>\n",
       "      <th>strict</th>\n",
       "      <th>exact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>18331.000000</td>\n",
       "      <td>16817.000000</td>\n",
       "      <td>15332.000000</td>\n",
       "      <td>16817.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incorrect</th>\n",
       "      <td>4327.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7326.000000</td>\n",
       "      <td>5841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5841.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>4886.000000</td>\n",
       "      <td>4886.000000</td>\n",
       "      <td>4886.000000</td>\n",
       "      <td>4886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>possible</th>\n",
       "      <td>27544.000000</td>\n",
       "      <td>27544.000000</td>\n",
       "      <td>27544.000000</td>\n",
       "      <td>27544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.686940</td>\n",
       "      <td>0.739648</td>\n",
       "      <td>0.574555</td>\n",
       "      <td>0.630204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.665517</td>\n",
       "      <td>0.716581</td>\n",
       "      <td>0.556637</td>\n",
       "      <td>0.610550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.676059</td>\n",
       "      <td>0.727932</td>\n",
       "      <td>0.565454</td>\n",
       "      <td>0.620222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ent_type       partial        strict         exact\n",
       "correct    18331.000000  16817.000000  15332.000000  16817.000000\n",
       "incorrect   4327.000000      0.000000   7326.000000   5841.000000\n",
       "partial        0.000000   5841.000000      0.000000      0.000000\n",
       "missed      4886.000000   4886.000000   4886.000000   4886.000000\n",
       "spurious    4027.000000   4027.000000   4027.000000   4027.000000\n",
       "possible   27544.000000  27544.000000  27544.000000  27544.000000\n",
       "actual     26685.000000  26685.000000  26685.000000  26685.000000\n",
       "precision      0.686940      0.739648      0.574555      0.630204\n",
       "recall         0.665517      0.716581      0.556637      0.610550\n",
       "f1             0.676059      0.727932      0.565454      0.620222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "      <th>MISC</th>\n",
       "      <th>LOC</th>\n",
       "      <th>LOC_ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ent_type</th>\n",
       "      <td>{'correct': 145, 'incorrect': 175, 'partial': 0, 'missed': 99, 'spurious': 1312, 'possible': 419, 'actual': 1632, 'precision': 0.08884803921568628, 'recall': 0.3460620525059666, 'f1': 0.14139444173573865}</td>\n",
       "      <td>{'correct': 17911, 'incorrect': 1901, 'partial': 0, 'missed': 3318, 'spurious': 2139, 'possible': 23130, 'actual': 21951, 'precision': 0.8159537150927065, 'recall': 0.7743623000432339, 'f1': 0.7946141389942548}</td>\n",
       "      <td>{'correct': 0, 'incorrect': 143, 'partial': 0, 'missed': 111, 'spurious': 0, 'possible': 254, 'actual': 143, 'precision': 0.0, 'recall': 0.0, 'f1': 0}</td>\n",
       "      <td>{'correct': 275, 'incorrect': 312, 'partial': 0, 'missed': 421, 'spurious': 576, 'possible': 1008, 'actual': 1163, 'precision': 0.236457437661221, 'recall': 0.2728174603174603, 'f1': 0.2533394748963611}</td>\n",
       "      <td>{'correct': 0, 'incorrect': 1796, 'partial': 0, 'missed': 937, 'spurious': 0, 'possible': 2733, 'actual': 1796, 'precision': 0.0, 'recall': 0.0, 'f1': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>{'correct': 67, 'incorrect': 0, 'partial': 253, 'missed': 99, 'spurious': 1312, 'possible': 419, 'actual': 1632, 'precision': 0.11856617647058823, 'recall': 0.4618138424821002, 'f1': 0.1886884446611409}</td>\n",
       "      <td>{'correct': 15810, 'incorrect': 0, 'partial': 4002, 'missed': 3318, 'spurious': 2139, 'possible': 23130, 'actual': 21951, 'precision': 0.8113981139811398, 'recall': 0.7700389105058366, 'f1': 0.7901776801756837}</td>\n",
       "      <td>{'correct': 15, 'incorrect': 0, 'partial': 128, 'missed': 111, 'spurious': 0, 'possible': 254, 'actual': 143, 'precision': 0.5524475524475524, 'recall': 0.3110236220472441, 'f1': 0.3979848866498741}</td>\n",
       "      <td>{'correct': 371, 'incorrect': 0, 'partial': 216, 'missed': 421, 'spurious': 576, 'possible': 1008, 'actual': 1163, 'precision': 0.411865864144454, 'recall': 0.4751984126984127, 'f1': 0.4412713035467526}</td>\n",
       "      <td>{'correct': 554, 'incorrect': 0, 'partial': 1242, 'missed': 937, 'spurious': 0, 'possible': 2733, 'actual': 1796, 'precision': 0.6542316258351893, 'recall': 0.42993047932674716, 'f1': 0.5188783395893133}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>{'correct': 64, 'incorrect': 256, 'partial': 0, 'missed': 99, 'spurious': 1312, 'possible': 419, 'actual': 1632, 'precision': 0.0392156862745098, 'recall': 0.15274463007159905, 'f1': 0.062408581179912236}</td>\n",
       "      <td>{'correct': 15039, 'incorrect': 4773, 'partial': 0, 'missed': 3318, 'spurious': 2139, 'possible': 23130, 'actual': 21951, 'precision': 0.6851168511685117, 'recall': 0.6501945525291829, 'f1': 0.6671990417248952}</td>\n",
       "      <td>{'correct': 0, 'incorrect': 143, 'partial': 0, 'missed': 111, 'spurious': 0, 'possible': 254, 'actual': 143, 'precision': 0.0, 'recall': 0.0, 'f1': 0}</td>\n",
       "      <td>{'correct': 229, 'incorrect': 358, 'partial': 0, 'missed': 421, 'spurious': 576, 'possible': 1008, 'actual': 1163, 'precision': 0.19690455717970765, 'recall': 0.22718253968253968, 'f1': 0.21096269000460616}</td>\n",
       "      <td>{'correct': 0, 'incorrect': 1796, 'partial': 0, 'missed': 937, 'spurious': 0, 'possible': 2733, 'actual': 1796, 'precision': 0.0, 'recall': 0.0, 'f1': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>{'correct': 67, 'incorrect': 253, 'partial': 0, 'missed': 99, 'spurious': 1312, 'possible': 419, 'actual': 1632, 'precision': 0.04105392156862745, 'recall': 0.15990453460620524, 'f1': 0.06533398342272062}</td>\n",
       "      <td>{'correct': 15810, 'incorrect': 4002, 'partial': 0, 'missed': 3318, 'spurious': 2139, 'possible': 23130, 'actual': 21951, 'precision': 0.7202405357386907, 'recall': 0.6835278858625162, 'f1': 0.7014041392160777}</td>\n",
       "      <td>{'correct': 15, 'incorrect': 128, 'partial': 0, 'missed': 111, 'spurious': 0, 'possible': 254, 'actual': 143, 'precision': 0.1048951048951049, 'recall': 0.05905511811023622, 'f1': 0.07556675062972291}</td>\n",
       "      <td>{'correct': 371, 'incorrect': 216, 'partial': 0, 'missed': 421, 'spurious': 576, 'possible': 1008, 'actual': 1163, 'precision': 0.31900257953568356, 'recall': 0.3680555555555556, 'f1': 0.3417779824965454}</td>\n",
       "      <td>{'correct': 554, 'incorrect': 1242, 'partial': 0, 'missed': 937, 'spurious': 0, 'possible': 2733, 'actual': 1796, 'precision': 0.30846325167037864, 'recall': 0.20270764727405782, 'f1': 0.2446456171340252}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                   ORG  \\\n",
       "ent_type  {'correct': 145, 'incorrect': 175, 'partial': 0, 'missed': 99, 'spurious': 1312, 'possible': 419, 'actual': 1632, 'precision': 0.08884803921568628, 'recall': 0.3460620525059666, 'f1': 0.14139444173573865}   \n",
       "partial     {'correct': 67, 'incorrect': 0, 'partial': 253, 'missed': 99, 'spurious': 1312, 'possible': 419, 'actual': 1632, 'precision': 0.11856617647058823, 'recall': 0.4618138424821002, 'f1': 0.1886884446611409}   \n",
       "strict    {'correct': 64, 'incorrect': 256, 'partial': 0, 'missed': 99, 'spurious': 1312, 'possible': 419, 'actual': 1632, 'precision': 0.0392156862745098, 'recall': 0.15274463007159905, 'f1': 0.062408581179912236}   \n",
       "exact     {'correct': 67, 'incorrect': 253, 'partial': 0, 'missed': 99, 'spurious': 1312, 'possible': 419, 'actual': 1632, 'precision': 0.04105392156862745, 'recall': 0.15990453460620524, 'f1': 0.06533398342272062}   \n",
       "\n",
       "                                                                                                                                                                                                                         PER  \\\n",
       "ent_type  {'correct': 17911, 'incorrect': 1901, 'partial': 0, 'missed': 3318, 'spurious': 2139, 'possible': 23130, 'actual': 21951, 'precision': 0.8159537150927065, 'recall': 0.7743623000432339, 'f1': 0.7946141389942548}   \n",
       "partial   {'correct': 15810, 'incorrect': 0, 'partial': 4002, 'missed': 3318, 'spurious': 2139, 'possible': 23130, 'actual': 21951, 'precision': 0.8113981139811398, 'recall': 0.7700389105058366, 'f1': 0.7901776801756837}   \n",
       "strict    {'correct': 15039, 'incorrect': 4773, 'partial': 0, 'missed': 3318, 'spurious': 2139, 'possible': 23130, 'actual': 21951, 'precision': 0.6851168511685117, 'recall': 0.6501945525291829, 'f1': 0.6671990417248952}   \n",
       "exact     {'correct': 15810, 'incorrect': 4002, 'partial': 0, 'missed': 3318, 'spurious': 2139, 'possible': 23130, 'actual': 21951, 'precision': 0.7202405357386907, 'recall': 0.6835278858625162, 'f1': 0.7014041392160777}   \n",
       "\n",
       "                                                                                                                                                                                                              MISC  \\\n",
       "ent_type                                                    {'correct': 0, 'incorrect': 143, 'partial': 0, 'missed': 111, 'spurious': 0, 'possible': 254, 'actual': 143, 'precision': 0.0, 'recall': 0.0, 'f1': 0}   \n",
       "partial     {'correct': 15, 'incorrect': 0, 'partial': 128, 'missed': 111, 'spurious': 0, 'possible': 254, 'actual': 143, 'precision': 0.5524475524475524, 'recall': 0.3110236220472441, 'f1': 0.3979848866498741}   \n",
       "strict                                                      {'correct': 0, 'incorrect': 143, 'partial': 0, 'missed': 111, 'spurious': 0, 'possible': 254, 'actual': 143, 'precision': 0.0, 'recall': 0.0, 'f1': 0}   \n",
       "exact     {'correct': 15, 'incorrect': 128, 'partial': 0, 'missed': 111, 'spurious': 0, 'possible': 254, 'actual': 143, 'precision': 0.1048951048951049, 'recall': 0.05905511811023622, 'f1': 0.07556675062972291}   \n",
       "\n",
       "                                                                                                                                                                                                                     LOC  \\\n",
       "ent_type      {'correct': 275, 'incorrect': 312, 'partial': 0, 'missed': 421, 'spurious': 576, 'possible': 1008, 'actual': 1163, 'precision': 0.236457437661221, 'recall': 0.2728174603174603, 'f1': 0.2533394748963611}   \n",
       "partial       {'correct': 371, 'incorrect': 0, 'partial': 216, 'missed': 421, 'spurious': 576, 'possible': 1008, 'actual': 1163, 'precision': 0.411865864144454, 'recall': 0.4751984126984127, 'f1': 0.4412713035467526}   \n",
       "strict    {'correct': 229, 'incorrect': 358, 'partial': 0, 'missed': 421, 'spurious': 576, 'possible': 1008, 'actual': 1163, 'precision': 0.19690455717970765, 'recall': 0.22718253968253968, 'f1': 0.21096269000460616}   \n",
       "exact       {'correct': 371, 'incorrect': 216, 'partial': 0, 'missed': 421, 'spurious': 576, 'possible': 1008, 'actual': 1163, 'precision': 0.31900257953568356, 'recall': 0.3680555555555556, 'f1': 0.3417779824965454}   \n",
       "\n",
       "                                                                                                                                                                                                               LOC_ORG  \n",
       "ent_type                                                     {'correct': 0, 'incorrect': 1796, 'partial': 0, 'missed': 937, 'spurious': 0, 'possible': 2733, 'actual': 1796, 'precision': 0.0, 'recall': 0.0, 'f1': 0}  \n",
       "partial    {'correct': 554, 'incorrect': 0, 'partial': 1242, 'missed': 937, 'spurious': 0, 'possible': 2733, 'actual': 1796, 'precision': 0.6542316258351893, 'recall': 0.42993047932674716, 'f1': 0.5188783395893133}  \n",
       "strict                                                       {'correct': 0, 'incorrect': 1796, 'partial': 0, 'missed': 937, 'spurious': 0, 'possible': 2733, 'actual': 1796, 'precision': 0.0, 'recall': 0.0, 'f1': 0}  \n",
       "exact     {'correct': 554, 'incorrect': 1242, 'partial': 0, 'missed': 937, 'spurious': 0, 'possible': 2733, 'actual': 1796, 'precision': 0.30846325167037864, 'recall': 0.20270764727405782, 'f1': 0.2446456171340252}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results_per_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for LOC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.96      0.98      0.97    270018\n",
      "       B-LOC       0.47      0.22      0.30      3741\n",
      "       I-LOC       0.70      0.07      0.12      1987\n",
      "      B-MISC       0.00      0.00      0.00       254\n",
      "      I-MISC       0.00      0.00      0.00       815\n",
      "       B-ORG       0.03      0.29      0.06       419\n",
      "       I-ORG       0.05      0.19      0.08       974\n",
      "       B-PER       0.79      0.73      0.76     23126\n",
      "       I-PER       0.85      0.67      0.75     21943\n",
      "\n",
      "    accuracy                           0.92    323277\n",
      "   macro avg       0.43      0.35      0.34    323277\n",
      "weighted avg       0.92      0.92      0.92    323277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gold_loc, test, labels=sorted_labels_loc, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(gold_ner, test_ner, tags=['ORG', 'PER', 'MISC', 'LOC'])\n",
    "results, results_per_tag = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_type</th>\n",
       "      <th>partial</th>\n",
       "      <th>strict</th>\n",
       "      <th>exact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>18748.000000</td>\n",
       "      <td>16263.000000</td>\n",
       "      <td>15332.000000</td>\n",
       "      <td>16263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incorrect</th>\n",
       "      <td>2680.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6096.000000</td>\n",
       "      <td>5165.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5165.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>5257.000000</td>\n",
       "      <td>5257.000000</td>\n",
       "      <td>5257.000000</td>\n",
       "      <td>5257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>possible</th>\n",
       "      <td>24813.000000</td>\n",
       "      <td>24813.000000</td>\n",
       "      <td>24813.000000</td>\n",
       "      <td>24813.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.702567</td>\n",
       "      <td>0.706221</td>\n",
       "      <td>0.574555</td>\n",
       "      <td>0.609444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.755572</td>\n",
       "      <td>0.759501</td>\n",
       "      <td>0.617902</td>\n",
       "      <td>0.655423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.728106</td>\n",
       "      <td>0.731893</td>\n",
       "      <td>0.595441</td>\n",
       "      <td>0.631597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ent_type       partial        strict         exact\n",
       "correct    18748.000000  16263.000000  15332.000000  16263.000000\n",
       "incorrect   2680.000000      0.000000   6096.000000   5165.000000\n",
       "partial        0.000000   5165.000000      0.000000      0.000000\n",
       "missed      3385.000000   3385.000000   3385.000000   3385.000000\n",
       "spurious    5257.000000   5257.000000   5257.000000   5257.000000\n",
       "possible   24813.000000  24813.000000  24813.000000  24813.000000\n",
       "actual     26685.000000  26685.000000  26685.000000  26685.000000\n",
       "precision      0.702567      0.706221      0.574555      0.609444\n",
       "recall         0.755572      0.759501      0.617902      0.655423\n",
       "f1             0.728106      0.731893      0.595441      0.631597"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "      <th>MISC</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ent_type</th>\n",
       "      <td>{'correct': 145, 'incorrect': 175, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.07863340563991324, 'recall': 0.3460620525059666, 'f1': 0.12814847547503314}</td>\n",
       "      <td>{'correct': 18328, 'incorrect': 2049, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.7975630983463882, 'recall': 0.7923223240532595, 'f1': 0.7949340735600278}</td>\n",
       "      <td>{'correct': 0, 'incorrect': 144, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.0, 'recall': 0.0, 'f1': 0}</td>\n",
       "      <td>{'correct': 275, 'incorrect': 312, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.16016307513104253, 'recall': 0.2728174603174603, 'f1': 0.2018348623853211}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>{'correct': 67, 'incorrect': 0, 'partial': 253, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.1049349240780911, 'recall': 0.4618138424821002, 'f1': 0.171011931064958}</td>\n",
       "      <td>{'correct': 15810, 'incorrect': 0, 'partial': 4567, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.7873585726718886, 'recall': 0.7821848521528618, 'f1': 0.7847631852879945}</td>\n",
       "      <td>{'correct': 15, 'incorrect': 0, 'partial': 129, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.5520833333333334, 'recall': 0.31299212598425197, 'f1': 0.39949748743718594}</td>\n",
       "      <td>{'correct': 371, 'incorrect': 0, 'partial': 216, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.2789749563191613, 'recall': 0.4751984126984127, 'f1': 0.3515596330275229}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>{'correct': 64, 'incorrect': 256, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.03470715835140998, 'recall': 0.15274463007159905, 'f1': 0.05656208572691118}</td>\n",
       "      <td>{'correct': 15039, 'incorrect': 5338, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.6544386422976501, 'recall': 0.6501383365035449, 'f1': 0.6522814018043025}</td>\n",
       "      <td>{'correct': 0, 'incorrect': 144, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.0, 'recall': 0.0, 'f1': 0}</td>\n",
       "      <td>{'correct': 229, 'incorrect': 358, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.1333721607454863, 'recall': 0.22718253968253968, 'f1': 0.16807339449541286}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>{'correct': 67, 'incorrect': 253, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.03633405639913232, 'recall': 0.15990453460620524, 'f1': 0.059213433495360145}</td>\n",
       "      <td>{'correct': 15810, 'incorrect': 4567, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.6879895561357703, 'recall': 0.6834687878263876, 'f1': 0.6857217210270645}</td>\n",
       "      <td>{'correct': 15, 'incorrect': 129, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.10416666666666667, 'recall': 0.05905511811023622, 'f1': 0.07537688442211056}</td>\n",
       "      <td>{'correct': 371, 'incorrect': 216, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.2160745486313337, 'recall': 0.3680555555555556, 'f1': 0.2722935779816514}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                    ORG  \\\n",
       "ent_type   {'correct': 145, 'incorrect': 175, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.07863340563991324, 'recall': 0.3460620525059666, 'f1': 0.12814847547503314}   \n",
       "partial        {'correct': 67, 'incorrect': 0, 'partial': 253, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.1049349240780911, 'recall': 0.4618138424821002, 'f1': 0.171011931064958}   \n",
       "strict     {'correct': 64, 'incorrect': 256, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.03470715835140998, 'recall': 0.15274463007159905, 'f1': 0.05656208572691118}   \n",
       "exact     {'correct': 67, 'incorrect': 253, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.03633405639913232, 'recall': 0.15990453460620524, 'f1': 0.059213433495360145}   \n",
       "\n",
       "                                                                                                                                                                                                                         PER  \\\n",
       "ent_type  {'correct': 18328, 'incorrect': 2049, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.7975630983463882, 'recall': 0.7923223240532595, 'f1': 0.7949340735600278}   \n",
       "partial   {'correct': 15810, 'incorrect': 0, 'partial': 4567, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.7873585726718886, 'recall': 0.7821848521528618, 'f1': 0.7847631852879945}   \n",
       "strict    {'correct': 15039, 'incorrect': 5338, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.6544386422976501, 'recall': 0.6501383365035449, 'f1': 0.6522814018043025}   \n",
       "exact     {'correct': 15810, 'incorrect': 4567, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.6879895561357703, 'recall': 0.6834687878263876, 'f1': 0.6857217210270645}   \n",
       "\n",
       "                                                                                                                                                                                                               MISC  \\\n",
       "ent_type                                                     {'correct': 0, 'incorrect': 144, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.0, 'recall': 0.0, 'f1': 0}   \n",
       "partial    {'correct': 15, 'incorrect': 0, 'partial': 129, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.5520833333333334, 'recall': 0.31299212598425197, 'f1': 0.39949748743718594}   \n",
       "strict                                                       {'correct': 0, 'incorrect': 144, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.0, 'recall': 0.0, 'f1': 0}   \n",
       "exact     {'correct': 15, 'incorrect': 129, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.10416666666666667, 'recall': 0.05905511811023622, 'f1': 0.07537688442211056}   \n",
       "\n",
       "                                                                                                                                                                                                                     LOC  \n",
       "ent_type   {'correct': 275, 'incorrect': 312, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.16016307513104253, 'recall': 0.2728174603174603, 'f1': 0.2018348623853211}  \n",
       "partial     {'correct': 371, 'incorrect': 0, 'partial': 216, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.2789749563191613, 'recall': 0.4751984126984127, 'f1': 0.3515596330275229}  \n",
       "strict    {'correct': 229, 'incorrect': 358, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.1333721607454863, 'recall': 0.22718253968253968, 'f1': 0.16807339449541286}  \n",
       "exact       {'correct': 371, 'incorrect': 216, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.2160745486313337, 'recall': 0.3680555555555556, 'f1': 0.2722935779816514}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results_per_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for ORG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.96      0.98      0.97    270018\n",
      "       B-LOC       0.16      0.27      0.20      1008\n",
      "       I-LOC       0.04      0.02      0.03       395\n",
      "      B-MISC       0.00      0.00      0.00       254\n",
      "      I-MISC       0.00      0.00      0.00       815\n",
      "       B-ORG       0.12      0.10      0.11      4744\n",
      "       I-ORG       0.05      0.19      0.08       974\n",
      "       B-PER       0.79      0.73      0.76     23126\n",
      "       I-PER       0.85      0.67      0.75     21943\n",
      "\n",
      "    accuracy                           0.92    323277\n",
      "   macro avg       0.33      0.33      0.32    323277\n",
      "weighted avg       0.92      0.92      0.92    323277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gold_org, test, labels=sorted_labels_org, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(gold_ner, test_ner, tags=['ORG', 'PER', 'MISC', 'LOC'])\n",
    "results, results_per_tag = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_type</th>\n",
       "      <th>partial</th>\n",
       "      <th>strict</th>\n",
       "      <th>exact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>18748.000000</td>\n",
       "      <td>16263.000000</td>\n",
       "      <td>15332.000000</td>\n",
       "      <td>16263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incorrect</th>\n",
       "      <td>2680.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6096.000000</td>\n",
       "      <td>5165.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5165.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>5257.000000</td>\n",
       "      <td>5257.000000</td>\n",
       "      <td>5257.000000</td>\n",
       "      <td>5257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>possible</th>\n",
       "      <td>24813.000000</td>\n",
       "      <td>24813.000000</td>\n",
       "      <td>24813.000000</td>\n",
       "      <td>24813.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "      <td>26685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.702567</td>\n",
       "      <td>0.706221</td>\n",
       "      <td>0.574555</td>\n",
       "      <td>0.609444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.755572</td>\n",
       "      <td>0.759501</td>\n",
       "      <td>0.617902</td>\n",
       "      <td>0.655423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.728106</td>\n",
       "      <td>0.731893</td>\n",
       "      <td>0.595441</td>\n",
       "      <td>0.631597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ent_type       partial        strict         exact\n",
       "correct    18748.000000  16263.000000  15332.000000  16263.000000\n",
       "incorrect   2680.000000      0.000000   6096.000000   5165.000000\n",
       "partial        0.000000   5165.000000      0.000000      0.000000\n",
       "missed      3385.000000   3385.000000   3385.000000   3385.000000\n",
       "spurious    5257.000000   5257.000000   5257.000000   5257.000000\n",
       "possible   24813.000000  24813.000000  24813.000000  24813.000000\n",
       "actual     26685.000000  26685.000000  26685.000000  26685.000000\n",
       "precision      0.702567      0.706221      0.574555      0.609444\n",
       "recall         0.755572      0.759501      0.617902      0.655423\n",
       "f1             0.728106      0.731893      0.595441      0.631597"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "      <th>MISC</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ent_type</th>\n",
       "      <td>{'correct': 145, 'incorrect': 175, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.07863340563991324, 'recall': 0.3460620525059666, 'f1': 0.12814847547503314}</td>\n",
       "      <td>{'correct': 18328, 'incorrect': 2049, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.7975630983463882, 'recall': 0.7923223240532595, 'f1': 0.7949340735600278}</td>\n",
       "      <td>{'correct': 0, 'incorrect': 144, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.0, 'recall': 0.0, 'f1': 0}</td>\n",
       "      <td>{'correct': 275, 'incorrect': 312, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.16016307513104253, 'recall': 0.2728174603174603, 'f1': 0.2018348623853211}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>{'correct': 67, 'incorrect': 0, 'partial': 253, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.1049349240780911, 'recall': 0.4618138424821002, 'f1': 0.171011931064958}</td>\n",
       "      <td>{'correct': 15810, 'incorrect': 0, 'partial': 4567, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.7873585726718886, 'recall': 0.7821848521528618, 'f1': 0.7847631852879945}</td>\n",
       "      <td>{'correct': 15, 'incorrect': 0, 'partial': 129, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.5520833333333334, 'recall': 0.31299212598425197, 'f1': 0.39949748743718594}</td>\n",
       "      <td>{'correct': 371, 'incorrect': 0, 'partial': 216, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.2789749563191613, 'recall': 0.4751984126984127, 'f1': 0.3515596330275229}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>{'correct': 64, 'incorrect': 256, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.03470715835140998, 'recall': 0.15274463007159905, 'f1': 0.05656208572691118}</td>\n",
       "      <td>{'correct': 15039, 'incorrect': 5338, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.6544386422976501, 'recall': 0.6501383365035449, 'f1': 0.6522814018043025}</td>\n",
       "      <td>{'correct': 0, 'incorrect': 144, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.0, 'recall': 0.0, 'f1': 0}</td>\n",
       "      <td>{'correct': 229, 'incorrect': 358, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.1333721607454863, 'recall': 0.22718253968253968, 'f1': 0.16807339449541286}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>{'correct': 67, 'incorrect': 253, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.03633405639913232, 'recall': 0.15990453460620524, 'f1': 0.059213433495360145}</td>\n",
       "      <td>{'correct': 15810, 'incorrect': 4567, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.6879895561357703, 'recall': 0.6834687878263876, 'f1': 0.6857217210270645}</td>\n",
       "      <td>{'correct': 15, 'incorrect': 129, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.10416666666666667, 'recall': 0.05905511811023622, 'f1': 0.07537688442211056}</td>\n",
       "      <td>{'correct': 371, 'incorrect': 216, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.2160745486313337, 'recall': 0.3680555555555556, 'f1': 0.2722935779816514}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                    ORG  \\\n",
       "ent_type   {'correct': 145, 'incorrect': 175, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.07863340563991324, 'recall': 0.3460620525059666, 'f1': 0.12814847547503314}   \n",
       "partial        {'correct': 67, 'incorrect': 0, 'partial': 253, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.1049349240780911, 'recall': 0.4618138424821002, 'f1': 0.171011931064958}   \n",
       "strict     {'correct': 64, 'incorrect': 256, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.03470715835140998, 'recall': 0.15274463007159905, 'f1': 0.05656208572691118}   \n",
       "exact     {'correct': 67, 'incorrect': 253, 'partial': 0, 'missed': 99, 'spurious': 1524, 'possible': 419, 'actual': 1844, 'precision': 0.03633405639913232, 'recall': 0.15990453460620524, 'f1': 0.059213433495360145}   \n",
       "\n",
       "                                                                                                                                                                                                                         PER  \\\n",
       "ent_type  {'correct': 18328, 'incorrect': 2049, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.7975630983463882, 'recall': 0.7923223240532595, 'f1': 0.7949340735600278}   \n",
       "partial   {'correct': 15810, 'incorrect': 0, 'partial': 4567, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.7873585726718886, 'recall': 0.7821848521528618, 'f1': 0.7847631852879945}   \n",
       "strict    {'correct': 15039, 'incorrect': 5338, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.6544386422976501, 'recall': 0.6501383365035449, 'f1': 0.6522814018043025}   \n",
       "exact     {'correct': 15810, 'incorrect': 4567, 'partial': 0, 'missed': 2755, 'spurious': 2603, 'possible': 23132, 'actual': 22980, 'precision': 0.6879895561357703, 'recall': 0.6834687878263876, 'f1': 0.6857217210270645}   \n",
       "\n",
       "                                                                                                                                                                                                               MISC  \\\n",
       "ent_type                                                     {'correct': 0, 'incorrect': 144, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.0, 'recall': 0.0, 'f1': 0}   \n",
       "partial    {'correct': 15, 'incorrect': 0, 'partial': 129, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.5520833333333334, 'recall': 0.31299212598425197, 'f1': 0.39949748743718594}   \n",
       "strict                                                       {'correct': 0, 'incorrect': 144, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.0, 'recall': 0.0, 'f1': 0}   \n",
       "exact     {'correct': 15, 'incorrect': 129, 'partial': 0, 'missed': 110, 'spurious': 0, 'possible': 254, 'actual': 144, 'precision': 0.10416666666666667, 'recall': 0.05905511811023622, 'f1': 0.07537688442211056}   \n",
       "\n",
       "                                                                                                                                                                                                                     LOC  \n",
       "ent_type   {'correct': 275, 'incorrect': 312, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.16016307513104253, 'recall': 0.2728174603174603, 'f1': 0.2018348623853211}  \n",
       "partial     {'correct': 371, 'incorrect': 0, 'partial': 216, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.2789749563191613, 'recall': 0.4751984126984127, 'f1': 0.3515596330275229}  \n",
       "strict    {'correct': 229, 'incorrect': 358, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.1333721607454863, 'recall': 0.22718253968253968, 'f1': 0.16807339449541286}  \n",
       "exact       {'correct': 371, 'incorrect': 216, 'partial': 0, 'missed': 421, 'spurious': 1130, 'possible': 1008, 'actual': 1717, 'precision': 0.2160745486313337, 'recall': 0.3680555555555556, 'f1': 0.2722935779816514}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results_per_tag))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "from modules.preprocessing_protocols import preprocess_text\n",
    "from modules.extract_results import extract_results_to_txt_file, display_results_by_subdistribution,\\\n",
    "                                    display_results_by_named_entity, display_confusion_matrix\n",
    "from contemporary_ner_training.conll_ner_importer import conll_to_ner_labelling  \n",
    "from estnltk import Text\n",
    "from estnltk.taggers import NerTagger\n",
    "from estnltk.taggers import WordLevelNerTagger\n",
    "from estnltk.converters import text_to_json\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.layer_operations import flatten\n",
    "\n",
    "from estnltk.taggers.estner.ner_trainer import NerTrainer\n",
    "from estnltk.taggers.estner.model_storage_util import ModelStorageUtil\n",
    "\n",
    "from estnltk.taggers import VabamorfCorpusTagger\n",
    "vm_corpus_tagger = VabamorfCorpusTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONLL NER test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntexts = []\\nfor file in os.listdir('contemporary_ner_training'):\\n    if file.startswith('estner_split_1'):\\n        texts.append(conll_to_ner_labelling(os.path.join('contemporary_ner_training', file), 'gold_wordner'))               \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "texts = []\n",
    "for file in os.listdir('contemporary_ner_training'):\n",
    "    if file.startswith('estner_split_1'):\n",
    "        texts.append(conll_to_ner_labelling(os.path.join('contemporary_ner_training', file), 'gold_wordner'))               \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vabamorfcorpustagger = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "\n",
    "with open(os.path.join('..', 'data', 'divided_corpus.txt'), 'r', encoding = 'UTF-8') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "for fileName in txt:\n",
    "    file, subdistribution = fileName.split(\":\")\n",
    "    files[file] = subdistribution.rstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_texts(filenames):\n",
    "    print(\"Valmistan ette treenimistekste\")\n",
    "    \n",
    "    # These files don't work because the protocols are written in a different language,\n",
    "    # which the goldstandard didn't recognise, hence have no goldstandard tags.\n",
    "    files_not_working = ['J2rva_Tyri_V22tsa_id22177_1911a.json', \\\n",
    "                         'J2rva_Tyri_V22tsa_id18538_1894a.json', \\\n",
    "                         'J2rva_Tyri_V22tsa_id22155_1911a.json', \\\n",
    "                         'Saare_Kihelkonna_Kotlandi_id18845_1865a.json', \\\n",
    "                         'P2rnu_Halliste_Abja_id257_1844a.json', \\\n",
    "                         'Saare_Kaarma_Loona_id7575_1899a.json', \\\n",
    "                         'J2rva_Tyri_V22tsa_id22266_1913a.json', \\\n",
    "                         'J2rva_Tyri_V22tsa_id22178_1912a.json']\n",
    "    \n",
    "    start = time.time()\n",
    "    training_texts = []\n",
    "    for filename in filenames:\n",
    "        with open(os.path.join('..', 'data', 'vallakohtufailid-json-flattened', filename), 'r', encoding='UTF-8') as file:\n",
    "            if filename in files_not_working:\n",
    "                continue\n",
    "            else:\n",
    "                tagged_text = preprocess_text(json_to_text(file.read()))\n",
    "                if use_vabamorfcorpustagger:\n",
    "                    tagged_text.pop_layer('morph_analysis')\n",
    "                    vm_corpus_tagger.tag([tagged_text])\n",
    "                training_texts.append(tagged_text)\n",
    "    print(f\"Treenimistekstid ette valmistatud {time.time() - start} sekundiga.\")\n",
    "    return training_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nertagger(training_texts, new_model_dir):\n",
    "    print(\"Alustan NerTaggeri treenimist.\")\n",
    "    start = time.time()\n",
    "    \n",
    "    modelUtil = ModelStorageUtil( new_model_dir )\n",
    "    nersettings = modelUtil.load_settings()\n",
    "    trainer = NerTrainer(nersettings)\n",
    "    trainer.train( training_texts, layer='gold_wordner', model_dir=new_model_dir )\n",
    "    print(f\"NerTagger treenitud {time.time() - start} sekundiga.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_and_training_subdistribution(subdistribution):\n",
    "    training = []\n",
    "    for y in [1, 2, 3, 4, 5]:\n",
    "        if y == subdistribution:\n",
    "            testing = y\n",
    "        else:\n",
    "            training.append(y)\n",
    "    return testing, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_files(model_dir, testing_files, nertagger, use_vabamorfcorpustagger):\n",
    "    removed_layers = ['sentences', 'morph_analysis', 'compound_tokens', 'ner', 'words', 'tokens']\n",
    "    \n",
    "    print(\"\\n\\nAlustan failide märgendamist.\")\n",
    "    start = time.time()\n",
    "    \n",
    "    for test_file in testing_files:\n",
    "        with open(find(test_file.replace(\".json\", \".txt\"), os.path.join('..', 'data', 'vallakohtufailid')), 'r', encoding='UTF-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        if test_file == \"Tartu_V6nnu_Ahja_id3502_1882a.json\":\n",
    "            text = text.replace('..', '. .')\n",
    "        text = preprocess_text(Text(text))\n",
    "\n",
    "        if use_vabamorfcorpustagger:\n",
    "            text.pop_layer('morph_analysis')\n",
    "            text = [text]\n",
    "            vm_corpus_tagger.tag( text )\n",
    "            text = text[0]\n",
    "        nertagger.tag(text)\n",
    "        text.add_layer(flatten(text['ner'], 'flat_ner'))\n",
    "\n",
    "        for x in removed_layers:\n",
    "            text.pop_layer(x)\n",
    "\n",
    "        path = os.path.join(model_dir, 'vallakohtufailid-trained-nertagger')\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "            \n",
    "        text_to_json(text, file=os.path.join(model_dir, 'vallakohtufailid-trained-nertagger', test_file))\n",
    "\n",
    "            \n",
    "        print(f'Märgendatud fail {test_file}')\n",
    "    print(f\"Failid märgendatud {time.time() - start} sekundiga.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_directory):\n",
    "    for subdistribution in [1, 2, 3, 4, 5]:\n",
    "        testing, training = get_testing_and_training_subdistribution(subdistribution)\n",
    "        \n",
    "        # Get the filenames to be trained on from the files dictionary\n",
    "        filenames = [key for key, value in files.items() if int(value) in training]\n",
    "\n",
    "        # Create training_texts from the aforementioned filenames\n",
    "        training_texts = create_training_texts(filenames)\n",
    "        \n",
    "        # Set up the trainer and training\n",
    "        new_model_dir = os.path.join('models', model_directory)\n",
    "        train_nertagger(training_texts, new_model_dir)\n",
    "        \n",
    "        # Set up the new trained nertagger and defining layers to be removed later on\n",
    "        tagger = NerTagger(model_dir = new_model_dir)\n",
    "        \n",
    "        # Tag the files using the new nertagger\n",
    "        testing_files = [key for key, value in files.items() if int(value) == testing]\n",
    "        tag_files(new_model_dir, testing_files, tagger, use_vabamorfcorpustagger)\n",
    "            \n",
    "    # Get results of model\n",
    "    extract_results_to_txt_file(model_directory, files)\n",
    "    \n",
    "    print(f\"Mudel {model_directory} treenitud.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model the `model_directory` must contain a `settings.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valmistan ette treenimistekste\n",
      "Treenimistekstid ette valmistatud 114.97801065444946 sekundiga.\n",
      "Alustan NerTaggeri treenimist.\n",
      "(!) Warning: Location of the new \"settings.py\" is the same one as the old one. Model's settings are not copied.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "_change_layer method not implemented in NerGazetteerFeatureTagger",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\estner\\fex.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    571\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                     \u001b[0mfex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NerGazetteerFeatureTagger' object has no attribute 'process'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\estner\\fex.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    574\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                         \u001b[0mfex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m                     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\tagger.py\u001b[0m in \u001b[0;36mtag\u001b[1;34m(self, text, status)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \"\"\"\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\tagger.py\u001b[0m in \u001b[0;36mmake_layer\u001b[1;34m(self, text, layers, status)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\tagger.py\u001b[0m in \u001b[0;36m_make_layer\u001b[1;34m(self, text, layers, status)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'make_layer method not implemented in '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: ('make_layer method not implemented in NerGazetteerFeatureTagger', \"in the 'NerGazetteerFeatureTagger'\")",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-930c77d4b095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m train_model(os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features',\n\u001b[1;32m----> 2\u001b[1;33m                          'model_gaz_loc_variants'))\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-0f515761fb3d>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model_directory)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# Set up the trainer and training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mnew_model_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mtrain_nertagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_model_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Set up the new trained nertagger and defining layers to be removed later on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-8fcedf301e0f>\u001b[0m in \u001b[0;36mtrain_nertagger\u001b[1;34m(training_texts, new_model_dir)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnersettings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_settings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNerTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnersettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtraining_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gold_wordner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_model_dir\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"NerTagger treenitud {time.time() - start} sekundiga.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\estner\\ner_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, texts, labels, layer, model_dir)\u001b[0m\n\u001b[0;32m     77\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of sentence {} in text {} doesn't match length of labels {} in NER-layer {}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\estner\\fex.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    575\u001b[0m                         \u001b[0mfex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m                     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m                         \u001b[0mfex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m         \u001b[1;31m# apply the feature templates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\retagger.py\u001b[0m in \u001b[0;36mretag\u001b[1;34m(self, text, status)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Used change_layer to get the retagged variant of the layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchange_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\retagger.py\u001b[0m in \u001b[0;36mchange_layer\u001b[1;34m(self, text, layers, status)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# Used _change_layer to get the retagged variant of the layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_change_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;31m# Check that the layer exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_layer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py37\\lib\\site-packages\\estnltk\\taggers\\retagger.py\u001b[0m in \u001b[0;36m_change_layer\u001b[1;34m(self, text, layers, status)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_change_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_change_layer method not implemented in '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mchange_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: _change_layer method not implemented in NerGazetteerFeatureTagger"
     ]
    }
   ],
   "source": [
    "train_model(os.path.join('model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features',\n",
    "                         'model_gaz_loc_variants'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

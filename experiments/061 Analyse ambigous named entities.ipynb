{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse ambigous named entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One specific token can have different labels in the context of named entity recognition. This experiment allows to read in all tokens and their labels and change the tokens' labels. E.g. if the token <code>Kiidjerwe</code> has the labels <code>LOC</code> and <code>ORG</code>, we may want to change all `ORG` labels to `LOC` if the token has the `ORG` label more than 95% of the times it's in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "from estnltk import Text\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.converters import text_to_json\n",
    "from modules.results_extraction import extract_results, results_by_subdistribution\n",
    "\n",
    "from estnltk.layer.layer import Layer\n",
    "from estnltk import EnvelopingBaseSpan\n",
    "from estnltk.layer_operations import flatten\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "import pandas as pd\n",
    "\n",
    "from modules.preprocessing_protocols import preprocess_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divided corpus file for filenames and layers to be removed later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_corpus = os.path.join('..', 'data', 'divided_corpus.txt')\n",
    "no_goldstandard_tags_location = os.path.join('..', 'data', 'files_without_goldstandard_annotations.txt')\n",
    "testing_files_location = os.path.join('..', 'data', 'vallakohtufailid-json-flattened')\n",
    "\n",
    "removed_layers = ['compound_tokens', 'tokens', 'words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read files from <code>path_to_read</code> and write files to <code>path_to_write</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_read = os.path.join('models',\n",
    "                    'model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', \n",
    "                    'model_gaz_loc_variants', \n",
    "                    'vallakohtufailid-trained-nertagger')\n",
    "\n",
    "path_to_write = os.path.join('models',\n",
    "                    'model_morph_with_lemmas_and_sentences_and_gazetteer_and_global_features', \n",
    "                    'model_gaz_loc_variants_me', \n",
    "                    'vallakohtufailid-trained-nertagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get files without goldstandard annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(no_goldstandard_tags_location, 'r', encoding='UTF-8') as in_f:\n",
    "    lines = in_f.readlines()\n",
    "\n",
    "no_goldstandard_annotations = [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "\n",
    "with open(divided_corpus, 'r', encoding = 'UTF-8') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "for filename in txt:\n",
    "    file, subdistribution = filename.split(':')\n",
    "    files[file] = subdistribution.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivalued_entity_dict(path, leave_out_O):\n",
    "    me_dict = dict()\n",
    "    texts_dict = dict()\n",
    "    \n",
    "    # Read all filenames from path\n",
    "    for file in os.listdir(path):\n",
    "        with open(os.path.join(path, file), 'r', encoding='UTF-8') as in_f:\n",
    "            texts_dict[file] = json_to_text(in_f.read())\n",
    "    \n",
    "    # Create me_dict, which contains all named entities\n",
    "    for file in texts_dict.keys():\n",
    "        text = texts_dict[file]\n",
    "        \n",
    "        for entity in text.flat_wordner:\n",
    "            named_entity = entity.text\n",
    "            nertag = entity.nertag[0]\n",
    "            labels = dict()\n",
    "            if entity.text in me_dict.keys():\n",
    "                if nertag in me_dict[named_entity]:\n",
    "                    labels = me_dict[named_entity]\n",
    "                    labels[nertag] = labels[nertag] + 1\n",
    "                else:\n",
    "                    labels = me_dict[named_entity]\n",
    "                    labels[nertag] = 1\n",
    "                    me_dict[named_entity] = labels\n",
    "            else:\n",
    "                me_dict[named_entity] = {nertag: 1}\n",
    "\n",
    "    # If leave_out_O == True, leave out all named entites that\n",
    "    # have other labels as well as the 'O' label \n",
    "    delete_keys = set()\n",
    "    for key, value in me_dict.items():\n",
    "        if len(value.items()) == 1:\n",
    "            delete_keys.add(key)\n",
    "        elif leave_out_O and 'O' in value.keys():\n",
    "            delete_keys.add(key)\n",
    "\n",
    "    for key in delete_keys:\n",
    "        del me_dict[key]\n",
    "\n",
    "    for key, value in me_dict.items():\n",
    "        all_counts = 0\n",
    "        for ne, count in value.items():\n",
    "            all_counts += count\n",
    "\n",
    "        for ne, count in value.items():\n",
    "            percentage = round((count / all_counts) * 100, 3)\n",
    "            value[ne] = percentage\n",
    "\n",
    "    return me_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_multivalued_entities_in_file(text, me_dict, threshold, threshold_O = 100):\n",
    "    \n",
    "    for i in range(len(text.flat_wordner)):\n",
    "        entity = text.flat_wordner[i].text\n",
    "        nertag = text.flat_wordner[i].nertag[0]\n",
    "        \n",
    "        # If the named entity is in the dict, check if it needs to be\n",
    "        # changed due to the threshold\n",
    "        \n",
    "        if entity in me_dict:\n",
    "            for key, value in me_dict[entity].items():\n",
    "                before = text.flat_wordner[i].nertag[0]\n",
    "                if key != 'O' and value > threshold and nertag != key:\n",
    "                    text.flat_wordner[i].nertag = key\n",
    "                    print(f'Muudatus sõnes {entity}: {before} -> {key}')\n",
    "                elif key == 'O' and value > threshold_O and nertag != key:\n",
    "                    text.flat_wordner[i].nertag = key\n",
    "                    print(f'Muudatus sõnes {entity}: {before} -> {key}')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `wordner` layer is converted to `ner` layer due to the results extraction being built upon `ner` tags and not `wordner` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wordner_to_ner(text):\n",
    "    snt_labels = [label.nertag[0] for label in text.flat_wordner]\n",
    "    \n",
    "    text.pop_layer('flat_ner')\n",
    "    text = preprocess_text(text)    \n",
    "    nerlayer = Layer(name='ner', attributes=['nertag'], text_object=text, enveloping='words')\n",
    "    \n",
    "    entity_spans = []\n",
    "    entity_type = None\n",
    "    \n",
    "    for span, label in zip(text.words, snt_labels):\n",
    "        if entity_type is None:\n",
    "            entity_type = label[2:]\n",
    "        if label == \"O\":\n",
    "            if entity_spans:\n",
    "                nerlayer.add_annotation(EnvelopingBaseSpan(entity_spans),\n",
    "                                        **{['nertag'][0]: entity_type})\n",
    "                entity_spans = []\n",
    "            continue\n",
    "        if label[0] == \"B\" or entity_type != label[2:]:\n",
    "            if entity_spans:\n",
    "                nerlayer.add_annotation(EnvelopingBaseSpan(entity_spans),\n",
    "                                        **{['nertag'][0]: entity_type})\n",
    "                entity_spans = []\n",
    "        entity_type = label[2:]\n",
    "        entity_spans.append(span.base_span)\n",
    "        \n",
    "    text.add_layer(nerlayer)\n",
    "    \n",
    "    flat_ner = flatten(text['ner'], 'flat_ner')\n",
    "    text.add_layer(flat_ner)\n",
    "    \n",
    "    for layer in removed_layers:\n",
    "        text.pop_layer(layer)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setups = [[True, 85], # Leave out O-s, if majority above 85% -> change\n",
    "          [True, 90], # Leave out O-s, if majority above 90% -> change \n",
    "          [True, 95], # Leave out O-s, if majority above 95% -> change\n",
    "          [False, 85, 95], # Don't leave out O-s, if majority of !O above 85% -> change, also change O if above 95%\n",
    "          [False, 85, 99], # Don't leave out O-s, if majority of !O above 85% -> change, also change O if above 99%\n",
    "          [False, 90, 95], # Don't leave out O-s, if majority of !O above 90% -> change, also change O if above 95%\n",
    "          [False, 90, 99], # Don't leave out O-s, if majority of !O above 90% -> change, also change O if above 99%\n",
    "          [False, 95, 95], # Don't leave out O-s, if majority of !O above 95% -> change, also change O if above 95%\n",
    "          [False, 95, 99]] # Don't leave out O-s, if majority of !O above 95% -> change, also change O if above 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_results = dict()\n",
    "\n",
    "for setup in setups:\n",
    "    leave_out_O = setup[0]\n",
    "    threshold = int(setup[1])\n",
    "    try:\n",
    "        threshold_O = setup[2]\n",
    "    except:\n",
    "        threshold_O = 100\n",
    "        \n",
    "    me_dict = multivalued_entity_dict(path_to_read, leave_out_O)\n",
    "    \n",
    "    for file in os.listdir(path_to_read):\n",
    "        if file.endswith('json'):\n",
    "            with open(os.path.join(path_to_read, file), 'r', encoding='UTF-8') as in_f:\n",
    "                text = json_to_text(in_f.read())\n",
    "            \n",
    "            text = change_multivalued_entities_in_file(text, me_dict, threshold, threshold_O)\n",
    "            text = convert_wordner_to_ner(text)\n",
    "            text_to_json(text, file=os.path.join(path_to_write, file))\n",
    "            \n",
    "    all_results[f'{str(leave_out_O)}, {str(threshold)}, {str(threshold_O)}'] = (extract_results(files, no_goldstandard_annotations, path_to_write, testing_files_location, path_to_write))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict()\n",
    "\n",
    "for key in all_results.keys():\n",
    "    results = results_by_subdistribution(all_results[key][0])\n",
    "    precision = results[0]\n",
    "    recall = results[1]\n",
    "    f1 = results[2]\n",
    "    df[key] = [precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(df, index=['Precision', 'Recall', 'F1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first `boolean` value states if `O` tags are completely left out or not.\n",
    "\n",
    "The second value states the threshold for changing named entity labels from one to another:\n",
    "e.g. if \"Jaan\" is 91% `B-PER` and 9% `I-PER` and if the threshold is `90`, all the `I-PER` tags\n",
    "are also changed to `B-PER`. Should the threshold be for example 92, the named entity label \n",
    "stays unchanged.\n",
    "\n",
    "The third value states the threshold for changing labels from or to `O` based on the threshold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

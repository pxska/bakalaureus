{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekkis probleem reaga EnvelopingSpan(['Peter', 'Barnabas'], [{'nertag': 'PER'}]), mis pärineb failist Harju_Hageri_Kohila_id4010_1890a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Peeter', 'Laas'], [{'nertag': 'PER'}]), mis pärineb failist Harju_Juuru_Juuru_id556_1877a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Toomas', 'Rassohw'], [{'nertag': 'PER'}]), mis pärineb failist Harju_Juuru_Kaiu_id12588_1883a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Mik', 'Lewet'], [{'nertag': 'PER'}]), mis pärineb failist Harju_Kose_Triigi_id9684_1869a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Anni'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id22870_1872a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Anni'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id22870_1872a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Anni'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id22870_1872a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Anni'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id22870_1872a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Hans', 'Sepper'], [{'nertag': 'PER'}]), mis pärineb failist Harju_Kose_Kose-Uuem6isa_id3179_1867a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Hans', 'Härg'], [{'nertag': 'PER'}]), mis pärineb failist Harju_Kose_Palvere_id23525_1887a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Karel', 'Rabbi'], [{'nertag': 'PER'}]), mis pärineb failist P2rnu_P2rnu-Elisabethi_Sauga_id17127_1874a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Karel', 'Rabbi'], [{'nertag': 'PER'}]), mis pärineb failist P2rnu_P2rnu-Elisabethi_Sauga_id17127_1874a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jakob', 'Estaal'], [{'nertag': 'PER'}]), mis pärineb failist P2rnu_P2rnu-Jaagupi_Soosalu_id14294_1870a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Maddis', 'Sarwik'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id20260_1866a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Maddis', 'Sarwik'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id20260_1866a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Maddis', 'Sarwik'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id20260_1866a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Andres', 'Pertma'], [{'nertag': 'PER'}]), mis pärineb failist Viljandi_Paistu_Holstre_id11341_1848a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Lanel'], [{'nertag': 'PER'}]), mis pärineb failist Viljandi_Paistu_Holstre_id11341_1848a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Lanel'], [{'nertag': 'PER'}]), mis pärineb failist Viljandi_Paistu_Holstre_id11341_1848a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Hans', 'Ehrenwerth'], [{'nertag': 'PER'}]), mis pärineb failist J2rva_Tyri_Kirna_id22809_1868a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Saarmann'], [{'nertag': 'PER'}]), mis pärineb failist J2rva_Tyri_Kirna_id24064_1879a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Kreep'], [{'nertag': 'PER'}]), mis pärineb failist J2rva_Tyri_Kirna_id25139_1881a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Hans', 'Simsohn'], [{'nertag': 'PER'}]), mis pärineb failist J2rva_Tyri_Kirna_id25139_1881a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jaan', 'Kreep'], [{'nertag': 'PER'}]), mis pärineb failist J2rva_Tyri_Kirna_id25139_1881a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Hans', 'Manderius'], [{'nertag': 'PER'}]), mis pärineb failist J2rva_Tyri_S2revere_id12373_1877a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jürri', 'Mesner'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Kullamaa_K22nda_id18344_1871a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Jürri', 'Mesner'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Kullamaa_K22nda_id18344_1871a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Juhan', 'Krusert'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Kullamaa_Kuij6e_id15386_1874a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan([':', 'Juhan'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Kullamaa_Kuij6e_id15386_1874a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Kustas', 'Wahartal'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Kullamaa_Piirsalu_id7160_1880a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Kustas', 'Wahartal'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Kullamaa_Piirsalu_id7160_1880a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['K.Koppel', 'abiline'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Martna_Martna_id12491_1883a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Karel', 'Partokowskij'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Martna_Martna_id12491_1883a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Christjan', 'Leiwat'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Pyhalepa_Kassari_id23159_1867a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Christjan', 'Leiwat'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Pyhalepa_Kassari_id23159_1867a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Christjan', 'Leiwat'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Pyhalepa_Kassari_id23159_1867a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Christjan', 'Leiwat'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Pyhalepa_Kassari_id23159_1867a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Christjan', 'Leiwat'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Pyhalepa_Kassari_id23159_1867a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Christjan', 'Leiwat'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Pyhalepa_Kassari_id23159_1867a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Borby', 'Lentsmanni'], [{'nertag': 'PER'}]), mis pärineb failist L22ne_Vormsi_Vormsi_id24524_1888a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Gustav', 'Waddi'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id22058_1871a.txt: see Span juba eksisteerib.\n",
      "Tekkis probleem reaga EnvelopingSpan(['Gustav', 'Waddi'], [{'nertag': 'PER'}]), mis pärineb failist Tartu_Kodavere_Pala_id22058_1871a.txt: see Span juba eksisteerib.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from estnltk import EnvelopingBaseSpan\n",
    "from estnltk import Text, Layer, Annotation, EnvelopingSpan, Span\n",
    "from estnltk.converters import text_to_json\n",
    "\n",
    "# If the annotation contains newline character, then indexes will contain ';' at the linebreak (e.g. 388 393;394 398 )\n",
    "indexes_on_line_split = re.compile(r' (\\d+) (\\d+;\\d+ ){1,}(\\d+)$')\n",
    "\n",
    "def collect_annotations( in_f ):\n",
    "    annotations = []\n",
    "    split_lines_ahead = 0\n",
    "    for line in in_f:\n",
    "        line = line.rstrip('\\n')\n",
    "        items = line.split('\\t')\n",
    "        if split_lines_ahead > 0:\n",
    "            split_lines_ahead -= 1\n",
    "            last_item = annotations[-1]\n",
    "            new_tuple = (last_item[0],last_item[1],last_item[2],last_item[3]+line,last_item[4])\n",
    "            annotations[-1] = new_tuple\n",
    "            continue\n",
    "        if len(items) == 3:\n",
    "            indexes_str = items[1]\n",
    "            if indexes_str.count(';') > 0:\n",
    "                split_lines_ahead += indexes_str.count(';')\n",
    "            indexes_str = indexes_on_line_split.sub(' \\\\1 \\\\3', indexes_str)\n",
    "            tag, start, end = indexes_str.split()\n",
    "            annotations.append( (tag, start, end, items[2], items[0]) )\n",
    "    return annotations\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "directories = [\"vallakohus_esimene\", \"vallakohus_teine\", \"vallakohus_kolmas\", \"vallakohus_neljas\"]\n",
    "for directory in directories:\n",
    "    path = cwd + \"\\\\\" + directory + \"\\\\\"\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(path + file, 'r', encoding=\"utf-8\") as txt, open(path + file.split(\".\")[0] + \".ann\", 'r', encoding=\"utf-8\") as ann:\n",
    "                textfile = txt.read()\n",
    "                \n",
    "                # converting the text form .txt file into an EstNLTK Text object and giving it the \"words\" layer\n",
    "                text = Text(textfile)\n",
    "                text.meta['origin_directory'] = str(directory)\n",
    "                text = text.tag_layer(['words'])\n",
    "                \n",
    "                gold_ner_layer = Layer(name=\"gold_ner\", text_object=text, attributes=['nertag'])\n",
    "                gold_wordner_layer = Layer(name=\"gold_wordner\", text_object=text, attributes=['nertag'], parent=\"words\")\n",
    "                \n",
    "                annotation_dictionary = {}\n",
    "                fixed_annotations = collect_annotations(ann)\n",
    "\n",
    "                for annotation in fixed_annotations:\n",
    "                    trigger = annotation[4]\n",
    "                    location = annotation[0] + \" \" + annotation[1] + \" \" + annotation[2]\n",
    "                    entity = annotation[3]\n",
    "                    annotation_dictionary[trigger] = [location, entity]\n",
    "                    \n",
    "                dictionary_for_wordner = {} #the dictionary for wordner\n",
    "                for key in annotation_dictionary:\n",
    "                    name = []\n",
    "                    value = annotation_dictionary.get(key)\n",
    "                    ner, loc = value[0].split(\" \")[0], (value[0].split(\" \")[1], value[0].split(\" \")[2])\n",
    "                    preceding_newlines = text.text[0:int(loc[0])].count(\"\\n\") #counting preceding newlines to deduct from the indexes\n",
    "\n",
    "                    startIndex = int(loc[0]) - int(preceding_newlines) #starting index form the .ann file\n",
    "                    endIndex = int(loc[1]) - int(preceding_newlines) #ending index from the .ann file\n",
    "\n",
    "                    for i in range(0, len(text.words) - 1): #looping through every word in text.words\n",
    "                        if text.words[i].start == startIndex: #if the startindex is same in the .ann file and in the loop, add an new span \n",
    "                            if text.words[i].end == endIndex:\n",
    "                                base_span = EnvelopingBaseSpan([text.words[i].base_span])\n",
    "                                name = [text.words[i]] #adding the name element(s) to a list to use in the wordner dictionary later on\n",
    "                            else:\n",
    "                                if text.words[i+1].end == endIndex: #if the next word's endindex is the same as the endindex in the .ann file, add a new span\n",
    "                                    name = [text.words[i], text.words[i+1]] \n",
    "                                    base_span = EnvelopingBaseSpan([s.base_span for s in name])\n",
    "                                else:\n",
    "                                    for j in range(len(value[0].split(\" \")) - 1):\n",
    "                                        name.append(text.words[i+j])\n",
    "                                base_span = EnvelopingBaseSpan([s.base_span for s in name])\n",
    "\n",
    "                            new_span = EnvelopingSpan(base_span, layer=gold_ner_layer)\n",
    "\n",
    "                            if ner == \"Isik\":\n",
    "                                new_span.add_annotation(Annotation(new_span, nertag=\"PER\"))\n",
    "                                for k in range(0, len(name)):\n",
    "                                    if k == 0:\n",
    "                                        dictionary_for_wordner[i] = \"B-PER\"\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        dictionary_for_wordner[i+k] = \"I-PER\"\n",
    "                            if ner == \"KO_koht\" or ner == \"KO_org\":\n",
    "                                new_span.add_annotation(Annotation(new_span, nertag=\"LOC_ORG\"))\n",
    "                                for k in range(0, len(name)):\n",
    "                                    if k == 0:\n",
    "                                        dictionary_for_wordner[i] = \"B-LOC_ORG\"\n",
    "                                        continue\n",
    "\n",
    "                                    else:\n",
    "                                        dictionary_for_wordner[i+k] = \"I-LOC_ORG\"\n",
    "                            if ner == \"Koht\":\n",
    "                                new_span.add_annotation(Annotation(new_span, nertag=\"LOC\"))\n",
    "                                for k in range(0, len(name)):\n",
    "                                    if k == 0:\n",
    "                                        dictionary_for_wordner[i] = \"B-LOC\"\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        dictionary_for_wordner[i+k] = \"I-LOC\"\n",
    "                            if ner == \"Org\":\n",
    "                                new_span.add_annotation(Annotation(new_span, nertag=\"ORG\"))\n",
    "                                for k in range(0, len(name)):\n",
    "                                    if k == 0:\n",
    "                                        dictionary_for_wordner[i] = \"B-ORG\"\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        dictionary_for_wordner[i+k] = \"I-ORG\"\n",
    "                            if ner == \"Muu\" or ner == \"Teadmata\" or ner == \"ese\":\n",
    "                                new_span.add_annotation(Annotation(new_span, nertag=\"MISC\"))\n",
    "                                for k in range(0, len(name)):\n",
    "                                    if k == 0:\n",
    "                                        dictionary_for_wordner[i] = \"B-MISC\"\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        dictionary_for_wordner[i+k] = \"I-MISC\"\n",
    "                            try:\n",
    "                                gold_ner_layer.add_span(new_span)\n",
    "                                break\n",
    "                            except:\n",
    "                                print(f\"Tekkis probleem reaga {new_span}, mis pärineb failist {file}: see Span juba eksisteerib.\")\n",
    "                text.add_layer(gold_ner_layer)\n",
    "                \n",
    "                for i in range(0, len(text.words) - 1):\n",
    "                    for key in dictionary_for_wordner.keys():\n",
    "                        new_span = Span(base_span=text.words[i].base_span, layer=gold_wordner_layer)\n",
    "\n",
    "                        if i == key:\n",
    "                            new_span.add_annotation(Annotation(new_span, nertag=str(dictionary_for_wordner.get(key))))\n",
    "                            gold_wordner_layer.add_span(new_span)\n",
    "                            break\n",
    "                        else:\n",
    "                            if i in dictionary_for_wordner.keys():\n",
    "                                continue\n",
    "                            else:\n",
    "                                new_span.add_annotation(Annotation(new_span, nertag=\"O\"))\n",
    "                            gold_wordner_layer.add_span(new_span)\n",
    "                            break\n",
    "\n",
    "                text.add_layer(gold_wordner_layer)\n",
    "                text_to_json(text, file=cwd + \"\\\\vallakohtufailid_json\\\\\" + file.replace(\".txt\", \".json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
